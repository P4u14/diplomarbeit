<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/SegmentationRunner.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/SegmentationRunner.py" />
              <option name="originalContent" value="from atlas.refiner.color_patch_refiner import ColorPatchRefiner&#10;from atlas.selector.bmi_atlas_selector import BmiAtlasSelector&#10;from atlas.selector.similarity_atlas_selector import SimilarityAtlasSelector&#10;from atlas.voter.majority_voter import MajorityVoter&#10;from atlas.voter.weighted_majority_voter import WeightedMajorityVoter&#10;from preprocessing.blue_color_preprocessor import BlueColorPreprocessor&#10;from preprocessing.color_preprocessor import ColorPreprocessor&#10;from preprocessing.dimples_roi_preprocessor import DimplesRoiPreprocessor&#10;from preprocessing.torso_roi_preprocessor import TorsoRoiPreprocessor&#10;from segmenter.atlas_segmenter import AtlasSegmenter&#10;import time&#10;import os&#10;&#10;&#10;class AtlasSegmentationRunner:&#10;    def __init__(self, num_atlases_to_select, atlas_dir, preprocessing_steps, atlas_selector, segmentation_voter, segmentation_refiner, output_dir, target_images_dir):&#10;        self.segmenter = AtlasSegmenter(&#10;            num_atlases_to_select,&#10;            atlas_dir,&#10;            preprocessing_steps,&#10;            atlas_selector,&#10;            segmentation_voter,&#10;            segmentation_refiner,&#10;            output_dir&#10;        )&#10;        self.target_images_dir = target_images_dir&#10;&#10;    def run(self):&#10;        # start timing&#10;        start_time = time.time()&#10;        target_images = self.segmenter.load_target_images(self.target_images_dir)&#10;        segmented_images = self.segmenter.segment_images(target_images)&#10;        self.segmenter.save_segmentation(segmented_images)&#10;        # end timing and compute durations&#10;        end_time = time.time()&#10;        total_seconds = end_time - start_time&#10;        # format total duration h:m:s&#10;        hrs = int(total_seconds // 3600)&#10;        mins = int((total_seconds % 3600) // 60)&#10;        secs = int(total_seconds % 60)&#10;        duration_str = f&quot;{hrs:02d}:{mins:02d}:{secs:02d}&quot;&#10;        # average per image&#10;        num_images = len(target_images)&#10;        if num_images &gt; 0:&#10;            avg_seconds = total_seconds / num_images&#10;            avg_hrs = int(avg_seconds // 3600)&#10;            avg_mins = int((avg_seconds % 3600) // 60)&#10;            avg_secs = int(avg_seconds % 60)&#10;            avg_str = f&quot;{avg_hrs:02d}:{avg_mins:02d}:{avg_secs:02d}&quot;&#10;        else:&#10;            avg_str = &quot;00:00:00&quot;&#10;        # write durations to file in output_dir&#10;        duration_file = os.path.join(self.segmenter.output_dir, &quot;duration.txt&quot;)&#10;        with open(duration_file, &quot;w&quot;) as f:&#10;            f.write(f&quot;Total duration: {duration_str}\n&quot;)&#10;            f.write(f&quot;Average per image: {avg_str}\n&quot;)&#10;&#10;# Beispiel für die Ausführung:&#10;if __name__ == &quot;__main__&quot;:&#10;    # Hier müssen die passenden Objekte und Parameter übergeben werden&#10;    runner = AtlasSegmentationRunner(&#10;        num_atlases_to_select=13,&#10;        atlas_dir=&quot;data/Atlas_Data_BMI_Percentile&quot;,&#10;        # preprocessing_steps=[DimplesRoiPreprocessor(target_ratio=10/7) ,BlueColorPreprocessor()],  # Liste mit Preprocessing-Objekten&#10;        preprocessing_steps=[],  # Liste mit Preprocessing-Objekten&#10;        atlas_selector=BmiAtlasSelector(&quot;data/Info_Sheets/All_Data_Renamed_overview.csv&quot;, &quot;data/Info_Sheets/bmi_table_who.csv&quot;),      # AtlasSelector-Objekt&#10;        segmentation_voter=WeightedMajorityVoter(scheme=&quot;softmax&quot;, temperature=0.02, threshold=0.5),  # SegmentationVoter-Objekt&#10;        segmentation_refiner=ColorPatchRefiner(BlueColorPreprocessor()),&#10;        output_dir=&quot;data/Atlas_Experiment100&quot;,&#10;        target_images_dir=&quot;data/Validation_Data_Small&quot;&#10;    )&#10;    # runner = AtlasSegmentationRunner(&#10;    #     num_atlases_to_select=3,&#10;    #     atlas_dir=&quot;data/Atlas_Data&quot;,&#10;    #     preprocessing_steps=[],  # Liste mit Preprocessing-Objekten&#10;    #     atlas_selector=SimilarityAtlasSelector(),      # AtlasSelector-Objekt&#10;    #     segmentation_voter=MajorityVoter(),  # SegmentationVoter-Objekt&#10;    #     segmentation_refiner=None,&#10;    #     output_dir=&quot;data/Atlas_Experiment01&quot;,&#10;    #     target_images_dir=&quot;data/Validation_Data_Small&quot;&#10;    # )&#10;    runner.run()" />
              <option name="updatedContent" value="from atlas.refiner.color_patch_refiner import ColorPatchRefiner&#10;from atlas.selector.bmi_atlas_selector import BmiAtlasSelector&#10;from atlas.selector.similarity_atlas_selector import SimilarityAtlasSelector&#10;from atlas.voter.majority_voter import MajorityVoter&#10;from atlas.voter.weighted_majority_voter import WeightedMajorityVoter&#10;from preprocessing.blue_color_preprocessor import BlueColorPreprocessor&#10;from preprocessing.color_preprocessor import ColorPreprocessor&#10;from preprocessing.dimples_roi_preprocessor import DimplesRoiPreprocessor&#10;from preprocessing.torso_roi_preprocessor import TorsoRoiPreprocessor&#10;from segmenter.atlas_segmenter import AtlasSegmenter&#10;import time&#10;import os&#10;&#10;&#10;class AtlasSegmentationRunner:&#10;    def __init__(self, num_atlases_to_select, atlas_dir, preprocessing_steps, atlas_selector, segmentation_voter, segmentation_refiner, output_dir, target_images_dir):&#10;        self.segmenter = AtlasSegmenter(&#10;            num_atlases_to_select,&#10;            atlas_dir,&#10;            preprocessing_steps,&#10;            atlas_selector,&#10;            segmentation_voter,&#10;            segmentation_refiner,&#10;            output_dir&#10;        )&#10;        self.target_images_dir = target_images_dir&#10;&#10;    def run(self):&#10;        # start timing&#10;        start_time = time.time()&#10;        target_images = self.segmenter.load_target_images(self.target_images_dir)&#10;        segmented_images = self.segmenter.segment_images(target_images)&#10;        self.segmenter.save_segmentation(segmented_images)&#10;        # end timing and compute durations&#10;        end_time = time.time()&#10;        total_seconds = end_time - start_time&#10;        # format total duration h:m:s&#10;        hrs = int(total_seconds // 3600)&#10;        mins = int((total_seconds % 3600) // 60)&#10;        secs = int(total_seconds % 60)&#10;        duration_str = f&quot;{hrs:02d}:{mins:02d}:{secs:02d}&quot;&#10;        # average per image&#10;        num_images = len(target_images)&#10;        if num_images &gt; 0:&#10;            avg_seconds = total_seconds / num_images&#10;            avg_hrs = int(avg_seconds // 3600)&#10;            avg_mins = int((avg_seconds % 3600) // 60)&#10;            avg_secs = int(avg_seconds % 60)&#10;            avg_str = f&quot;{avg_hrs:02d}:{avg_mins:02d}:{avg_secs:02d}&quot;&#10;        else:&#10;            avg_str = &quot;00:00:00&quot;&#10;        # write durations to file in output_dir&#10;        duration_file = os.path.join(self.segmenter.output_dir, &quot;duration.txt&quot;)&#10;        with open(duration_file, &quot;w&quot;) as f:&#10;            f.write(f&quot;Total duration: {duration_str}\n&quot;)&#10;            f.write(f&quot;Average per image: {avg_str}\n&quot;)&#10;&#10;# Beispiel für die Ausführung:&#10;if __name__ == &quot;__main__&quot;:&#10;    # Hier müssen die passenden Objekte und Parameter übergeben werden&#10;    runner = AtlasSegmentationRunner(&#10;        num_atlases_to_select=13,&#10;        atlas_dir=&quot;data/Atlas_Data_BMI_Percentile&quot;,&#10;        # preprocessing_steps=[DimplesRoiPreprocessor(target_ratio=10/7) ,BlueColorPreprocessor()],  # Liste mit Preprocessing-Objekten&#10;        preprocessing_steps=[],  # Liste mit Preprocessing-Objekten&#10;        atlas_selector=BmiAtlasSelector(&quot;data/Info_Sheets/All_Data_Renamed_overview.csv&quot;, &quot;data/Info_Sheets/bmi_table_who.csv&quot;),      # AtlasSelector-Objekt&#10;        segmentation_voter=WeightedMajorityVoter(scheme=&quot;softmax&quot;, temperature=0.02, threshold=0.5),  # SegmentationVoter-Objekt&#10;        segmentation_refiner=ColorPatchRefiner(BlueColorPreprocessor()),&#10;        output_dir=&quot;data/Atlas_Experiment100&quot;,&#10;        target_images_dir=&quot;data/Validation_Data_Small&quot;&#10;    )&#10;    # runner = AtlasSegmentationRunner(&#10;    #     num_atlases_to_select=3,&#10;    #     atlas_dir=&quot;data/Atlas_Data&quot;,&#10;    #     preprocessing_steps=[],  # Liste mit Preprocessing-Objekten&#10;    #     atlas_selector=SimilarityAtlasSelector(),      # AtlasSelector-Objekt&#10;    #     segmentation_voter=MajorityVoter(),  # SegmentationVoter-Objekt&#10;    #     segmentation_refiner=None,&#10;    #     output_dir=&quot;data/Atlas_Experiment01&quot;,&#10;    #     target_images_dir=&quot;data/Validation_Data_Small&quot;&#10;    # )&#10;    runner.run()" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/visualize.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/visualize.py" />
              <option name="originalContent" value="import os&#10;import pandas as pd&#10;import matplotlib.pyplot as plt&#10;import numpy as np&#10;&#10;# User configuration: specify experiment CSV paths and metrics to plot&#10;EXPERIMENT_FILES = [&#10;    'data/Results/Validation/Atlas_Experiment01_mean.csv',&#10;    'data/Results/Validation/Atlas_Experiment02_mean.csv',&#10;    'data/Results/Validation/Atlas_Experiment03_mean.csv',&#10;    'data/Results/Validation/Atlas_Experiment04_mean.csv',&#10;    'data/Results/Validation/Atlas_Experiment05_mean.csv',&#10;    'data/Results/Validation/Atlas_Experiment06_mean.csv',&#10;    'data/Results/Validation/Atlas_Experiment07_mean.csv',&#10;    'data/Results/Validation/Atlas_Experiment08_mean.csv',&#10;    'data/Results/Validation/Atlas_Experiment09_mean.csv',&#10;    'data/Results/Validation/Atlas_Experiment10_mean.csv',&#10;    'data/Results/Validation/Atlas_Experiment11_mean.csv',&#10;    'data/Results/Validation/Atlas_Experiment12_mean.csv',&#10;]&#10;&#10;METRICS = [&#10;    'Mean Dice',&#10;    'Mean Precision',&#10;    'Mean Recall',&#10;]&#10;&#10;METRIC_GROUPS = [&#10;    ['Mean N GT Segments', 'Mean N Pred Segments']&#10;]&#10;&#10;OUTPUT_DIR = 'data/Results/Plots'&#10;&#10;&#10;def sanitize_filename(name: str) -&gt; str:&#10;    return name.replace(' ', '_').replace('/', '_')&#10;&#10;&#10;def main():&#10;    # Load files from user-defined list&#10;    files = EXPERIMENT_FILES&#10;    if not files:&#10;        print('No experiment files provided')&#10;        return&#10;&#10;    # Load all dataframes keyed by experiment name&#10;    data = {}&#10;    for fp in files:&#10;        exp = os.path.basename(fp).replace('_mean.csv', '')&#10;        df = pd.read_csv(fp)&#10;        data[exp] = df&#10;&#10;    # Determine datasets&#10;    sample_df = next(iter(data.values()))&#10;    datasets = sample_df['Dataset'].tolist()&#10;    # Use user-defined metrics and ensure existence&#10;    metrics = [m for m in METRICS if m in sample_df.columns]&#10;    missing = [m for m in METRICS if m not in sample_df.columns]&#10;    if missing:&#10;        print(f&quot;Warning: The following metrics are not found in data and will be skipped: {missing}&quot;)&#10;&#10;    # Compute global y-limits for individual metrics&#10;    metric_limits = {}&#10;    for metric in metrics:&#10;        vals = []&#10;        for df in data.values():&#10;            vals.extend(df[metric].dropna().tolist())&#10;        if vals:&#10;            metric_limits[metric] = (min(vals), max(vals))&#10;    # Compute global y-limits for metric groups&#10;    group_limits = {}&#10;    for group in METRIC_GROUPS:&#10;        valid = [m for m in group if m in sample_df.columns]&#10;        if not valid:&#10;            continue&#10;        vals = []&#10;        for df in data.values():&#10;            for m in valid:&#10;                vals.extend(df[m].dropna().tolist())&#10;        if vals:&#10;            group_limits[tuple(valid)] = (min(vals), max(vals))&#10;&#10;    # Create output directory&#10;    os.makedirs(OUTPUT_DIR, exist_ok=True)&#10;&#10;    # Generate bar charts&#10;    for dataset in datasets:&#10;        for metric in metrics:&#10;            values = []&#10;            exps = []&#10;            for exp, df in data.items():&#10;                # Get value for this dataset and metric&#10;                row = df.loc[df['Dataset'] == dataset]&#10;                if not row.empty:&#10;                    val = row.iloc[0][metric]&#10;                    values.append(val)&#10;                    exps.append(exp)&#10;            if not values:&#10;                continue&#10;&#10;            # Sortiere Experimente alphabetisch&#10;            pairs = sorted(zip(exps, values), key=lambda x: x[0])&#10;            exps, values = zip(*pairs)&#10;&#10;            plt.figure()&#10;            # Achse bei y=0 zeichnen&#10;            plt.axhline(0, color='black', linewidth=0.8)&#10;            plt.bar(exps, values)&#10;            # apply consistent y-axis scale&#10;            if metric in metric_limits:&#10;                plt.ylim(metric_limits[metric])&#10;            plt.title(f&quot;{metric} for {dataset}&quot;)&#10;            plt.xlabel('Experiment')&#10;            plt.ylabel(metric)&#10;            plt.xticks(rotation=45, ha='right')&#10;            plt.tight_layout()&#10;&#10;            fname = f&quot;{sanitize_filename(dataset)}_{sanitize_filename(metric)}.png&quot;&#10;            plt.savefig(os.path.join(OUTPUT_DIR, fname))&#10;            plt.close()&#10;&#10;    print(f&quot;Individual plots saved in {OUTPUT_DIR}&quot;)&#10;&#10;    # Combined plots for metric groups&#10;    for dataset in datasets:&#10;        for group in METRIC_GROUPS:&#10;            # ensure metrics exist&#10;            valid = [m for m in group if m in sample_df.columns]&#10;            if not valid:&#10;                continue&#10;            exps = []&#10;            vals = {m: [] for m in valid}&#10;            for exp, df in data.items():&#10;                row = df.loc[df['Dataset'] == dataset]&#10;                if not row.empty:&#10;                    exps.append(exp)&#10;                    for m in valid:&#10;                        vals[m].append(row.iloc[0][m])&#10;            if not exps:&#10;                continue&#10;            # Sort experiments alphabetisch&#10;            combined = sorted(zip(exps, *(vals[m] for m in valid)), key=lambda x: x[0])&#10;            exps_sorted = [c[0] for c in combined]&#10;            sorted_vals = [ [c[i] for c in combined] for i in range(1, len(valid)+1) ]&#10;            x = np.arange(len(exps_sorted))&#10;            total_width = 0.8&#10;            width = total_width / len(valid)&#10;            plt.figure()&#10;            plt.axhline(0, color='black', linewidth=0.8)&#10;            for i, m in enumerate(valid):&#10;                plt.bar(x - total_width/2 + width*i + width/2, sorted_vals[i], width, label=m)&#10;            # apply consistent y-axis for this metric group&#10;            key = tuple(valid)&#10;            if key in group_limits:&#10;                plt.ylim(group_limits[key])&#10;            plt.xticks(x, exps_sorted, rotation=45, ha='right')&#10;            plt.title(f&quot;{' &amp; '.join(valid)} for {dataset}&quot;)&#10;            plt.xlabel('Experiment')&#10;            plt.ylabel('Value')&#10;            plt.legend()&#10;            plt.tight_layout()&#10;            fname = f&quot;{sanitize_filename(dataset)}_{sanitize_filename('_'.join(valid))}.png&quot;&#10;            plt.savefig(os.path.join(OUTPUT_DIR, fname))&#10;            plt.close()&#10;    print(f&quot;Combined group plots saved in {OUTPUT_DIR}&quot;)&#10;&#10;    # Subgroup plots: for each experiment, show 'All' and subgroups per metric&#10;    for exp, df in data.items():&#10;        for metric in metrics:&#10;            names = df['Dataset'].tolist()&#10;            values = df[metric].tolist()&#10;            if not values:&#10;                continue&#10;            # reorder to put 'All' first if present&#10;            if 'All' in names:&#10;                idx = names.index('All')&#10;                names.insert(0, names.pop(idx))&#10;                values.insert(0, values.pop(idx))&#10;            # plot&#10;            plt.figure()&#10;            plt.axhline(0, color='black', linewidth=0.8)&#10;            plt.bar(names, values)&#10;            # apply consistent y-axis scale&#10;            if metric in metric_limits:&#10;                plt.ylim(metric_limits[metric])&#10;            plt.title(f&quot;{metric} subgroups for {exp}&quot;)&#10;            plt.xlabel('Dataset Subgroup')&#10;            plt.ylabel(metric)&#10;            plt.xticks(rotation=45, ha='right')&#10;            plt.tight_layout()&#10;            fname = f&quot;{sanitize_filename(exp)}_{sanitize_filename(metric)}_subgroups.png&quot;&#10;            plt.savefig(os.path.join(OUTPUT_DIR, fname))&#10;            plt.close()&#10;&#10;    print(f&quot;Subgroup plots saved in {OUTPUT_DIR}&quot;)&#10;    # All subgroups across all experiments per metric&#10;    for metric in metrics:&#10;        exps = sorted(data.keys())&#10;        plt.figure()&#10;        for dataset in datasets:&#10;            vals = []&#10;            for exp in exps:&#10;                df = data[exp]&#10;                row = df.loc[df['Dataset'] == dataset]&#10;                vals.append(row.iloc[0][metric] if not row.empty else np.nan)&#10;            plt.plot(exps, vals, marker='o', label=dataset)&#10;        # apply consistent y-axis scale&#10;        if metric in metric_limits:&#10;            plt.ylim(metric_limits[metric])&#10;        plt.title(f&quot;{metric} across experiments and subgroups&quot;)&#10;        plt.xlabel('Experiment')&#10;        plt.ylabel(metric)&#10;        plt.xticks(rotation=45, ha='right')&#10;        plt.legend()&#10;        plt.tight_layout()&#10;        fname = f&quot;{sanitize_filename(metric)}_across_experiments_subgroups.png&quot;&#10;        plt.savefig(os.path.join(OUTPUT_DIR, fname))&#10;        plt.close()&#10;&#10;if __name__ == '__main__':&#10;    main()&#10;" />
              <option name="updatedContent" value="import os&#10;import pandas as pd&#10;import matplotlib.pyplot as plt&#10;import numpy as np&#10;&#10;# User configuration: specify experiment CSV paths and metrics to plot&#10;EXPERIMENT_FILES = [&#10;    'data/Results/Validation/Atlas_Experiment01_mean.csv',&#10;    'data/Results/Validation/Atlas_Experiment02_mean.csv',&#10;    'data/Results/Validation/Atlas_Experiment03_mean.csv',&#10;    'data/Results/Validation/Atlas_Experiment04_mean.csv',&#10;    'data/Results/Validation/Atlas_Experiment05_mean.csv',&#10;    'data/Results/Validation/Atlas_Experiment06_mean.csv',&#10;    'data/Results/Validation/Atlas_Experiment07_mean.csv',&#10;    'data/Results/Validation/Atlas_Experiment08_mean.csv',&#10;    'data/Results/Validation/Atlas_Experiment09_mean.csv',&#10;    'data/Results/Validation/Atlas_Experiment10_mean.csv',&#10;    'data/Results/Validation/Atlas_Experiment11_mean.csv',&#10;    'data/Results/Validation/Atlas_Experiment12_mean.csv',&#10;]&#10;&#10;METRICS = [&#10;    'Mean Dice',&#10;    'Mean Precision',&#10;    'Mean Recall',&#10;]&#10;&#10;METRIC_GROUPS = [&#10;    ['Mean N GT Segments', 'Mean N Pred Segments']&#10;]&#10;&#10;OUTPUT_DIR = 'data/Results/Plots'&#10;&#10;&#10;def sanitize_filename(name: str) -&gt; str:&#10;    return name.replace(' ', '_').replace('/', '_')&#10;&#10;&#10;def main():&#10;    # Load files from user-defined list&#10;    files = EXPERIMENT_FILES&#10;    if not files:&#10;        print('No experiment files provided')&#10;        return&#10;&#10;    # Load all dataframes keyed by experiment name&#10;    data = {}&#10;    for fp in files:&#10;        exp = os.path.basename(fp).replace('_mean.csv', '')&#10;        df = pd.read_csv(fp)&#10;        data[exp] = df&#10;&#10;    # Determine datasets&#10;    sample_df = next(iter(data.values()))&#10;    datasets = sample_df['Dataset'].tolist()&#10;    # Use user-defined metrics and ensure existence&#10;    metrics = [m for m in METRICS if m in sample_df.columns]&#10;    missing = [m for m in METRICS if m not in sample_df.columns]&#10;    if missing:&#10;        print(f&quot;Warning: The following metrics are not found in data and will be skipped: {missing}&quot;)&#10;&#10;    # Compute global y-limits for individual metrics&#10;    metric_limits = {}&#10;    for metric in metrics:&#10;        vals = []&#10;        for df in data.values():&#10;            vals.extend(df[metric].dropna().tolist())&#10;        if vals:&#10;            metric_limits[metric] = (min(vals), max(vals))&#10;    # Compute global y-limits for metric groups&#10;    group_limits = {}&#10;    for group in METRIC_GROUPS:&#10;        valid = [m for m in group if m in sample_df.columns]&#10;        if not valid:&#10;            continue&#10;        vals = []&#10;        for df in data.values():&#10;            for m in valid:&#10;                vals.extend(df[m].dropna().tolist())&#10;        if vals:&#10;            group_limits[tuple(valid)] = (min(vals), max(vals))&#10;&#10;    # Create output directory&#10;    os.makedirs(OUTPUT_DIR, exist_ok=True)&#10;&#10;    # Generate bar charts&#10;    for dataset in datasets:&#10;        for metric in metrics:&#10;            values = []&#10;            exps = []&#10;            for exp, df in data.items():&#10;                # Get value for this dataset and metric&#10;                row = df.loc[df['Dataset'] == dataset]&#10;                if not row.empty:&#10;                    val = row.iloc[0][metric]&#10;                    values.append(val)&#10;                    exps.append(exp)&#10;            if not values:&#10;                continue&#10;&#10;            # Sortiere Experimente alphabetisch&#10;            pairs = sorted(zip(exps, values), key=lambda x: x[0])&#10;            exps, values = zip(*pairs)&#10;&#10;            plt.figure()&#10;            # Achse bei y=0 zeichnen&#10;            plt.axhline(0, color='black', linewidth=0.8)&#10;            plt.bar(exps, values)&#10;            # apply consistent y-axis scale&#10;            if metric in metric_limits:&#10;                plt.ylim(metric_limits[metric])&#10;            plt.title(f&quot;{metric} for {dataset}&quot;)&#10;            plt.xlabel('Experiment')&#10;            plt.ylabel(metric)&#10;            plt.xticks(rotation=45, ha='right')&#10;            plt.tight_layout()&#10;&#10;            fname = f&quot;{sanitize_filename(dataset)}_{sanitize_filename(metric)}.png&quot;&#10;            plt.savefig(os.path.join(OUTPUT_DIR, fname))&#10;            plt.close()&#10;&#10;    print(f&quot;Individual plots saved in {OUTPUT_DIR}&quot;)&#10;&#10;    # Combined plots for metric groups&#10;    for dataset in datasets:&#10;        for group in METRIC_GROUPS:&#10;            # ensure metrics exist&#10;            valid = [m for m in group if m in sample_df.columns]&#10;            if not valid:&#10;                continue&#10;            exps = []&#10;            vals = {m: [] for m in valid}&#10;            for exp, df in data.items():&#10;                row = df.loc[df['Dataset'] == dataset]&#10;                if not row.empty:&#10;                    exps.append(exp)&#10;                    for m in valid:&#10;                        vals[m].append(row.iloc[0][m])&#10;            if not exps:&#10;                continue&#10;            # Sort experiments alphabetisch&#10;            combined = sorted(zip(exps, *(vals[m] for m in valid)), key=lambda x: x[0])&#10;            exps_sorted = [c[0] for c in combined]&#10;            sorted_vals = [ [c[i] for c in combined] for i in range(1, len(valid)+1) ]&#10;            x = np.arange(len(exps_sorted))&#10;            total_width = 0.8&#10;            width = total_width / len(valid)&#10;            plt.figure()&#10;            plt.axhline(0, color='black', linewidth=0.8)&#10;            for i, m in enumerate(valid):&#10;                plt.bar(x - total_width/2 + width*i + width/2, sorted_vals[i], width, label=m)&#10;            # apply consistent y-axis for this metric group&#10;            key = tuple(valid)&#10;            if key in group_limits:&#10;                plt.ylim(group_limits[key])&#10;            plt.xticks(x, exps_sorted, rotation=45, ha='right')&#10;            plt.title(f&quot;{' &amp; '.join(valid)} for {dataset}&quot;)&#10;            plt.xlabel('Experiment')&#10;            plt.ylabel('Value')&#10;            plt.legend()&#10;            plt.tight_layout()&#10;            fname = f&quot;{sanitize_filename(dataset)}_{sanitize_filename('_'.join(valid))}.png&quot;&#10;            plt.savefig(os.path.join(OUTPUT_DIR, fname))&#10;            plt.close()&#10;    print(f&quot;Combined group plots saved in {OUTPUT_DIR}&quot;)&#10;&#10;    # Subgroup plots: for each experiment, show 'All' and subgroups per metric&#10;    for exp, df in data.items():&#10;        for metric in metrics:&#10;            names = df['Dataset'].tolist()&#10;            values = df[metric].tolist()&#10;            if not values:&#10;                continue&#10;            # reorder to put 'All' first if present&#10;            if 'All' in names:&#10;                idx = names.index('All')&#10;                names.insert(0, names.pop(idx))&#10;                values.insert(0, values.pop(idx))&#10;            # plot&#10;            plt.figure()&#10;            plt.axhline(0, color='black', linewidth=0.8)&#10;            plt.bar(names, values)&#10;            # apply consistent y-axis scale&#10;            if metric in metric_limits:&#10;                plt.ylim(metric_limits[metric])&#10;            plt.title(f&quot;{metric} subgroups for {exp}&quot;)&#10;            plt.xlabel('Dataset Subgroup')&#10;            plt.ylabel(metric)&#10;            plt.xticks(rotation=45, ha='right')&#10;            plt.tight_layout()&#10;            fname = f&quot;{sanitize_filename(exp)}_{sanitize_filename(metric)}_subgroups.png&quot;&#10;            plt.savefig(os.path.join(OUTPUT_DIR, fname))&#10;            plt.close()&#10;&#10;    print(f&quot;Subgroup plots saved in {OUTPUT_DIR}&quot;)&#10;    # All subgroups across all experiments per metric&#10;    for metric in metrics:&#10;        exps = sorted(data.keys())&#10;        plt.figure()&#10;        for dataset in datasets:&#10;            vals = []&#10;            for exp in exps:&#10;                df = data[exp]&#10;                row = df.loc[df['Dataset'] == dataset]&#10;                vals.append(row.iloc[0][metric] if not row.empty else np.nan)&#10;            plt.plot(exps, vals, marker='o', label=dataset)&#10;        # apply consistent y-axis scale&#10;        if metric in metric_limits:&#10;            plt.ylim(metric_limits[metric])&#10;        plt.title(f&quot;{metric} across experiments and subgroups&quot;)&#10;        plt.xlabel('Experiment')&#10;        plt.ylabel(metric)&#10;        plt.xticks(rotation=45, ha='right')&#10;        plt.legend()&#10;        plt.tight_layout()&#10;        fname = f&quot;{sanitize_filename(metric)}_across_experiments_subgroups.png&quot;&#10;        plt.savefig(os.path.join(OUTPUT_DIR, fname))&#10;        plt.close()&#10;&#10;if __name__ == '__main__':&#10;    main()" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>