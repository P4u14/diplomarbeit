<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/SegmentationRunner.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/SegmentationRunner.py" />
              <option name="originalContent" value="from atlas.refiner.color_patch_refiner import ColorPatchRefiner&#10;from atlas.selector.bmi_atlas_selector import BmiAtlasSelector&#10;from atlas.selector.similarity_atlas_selector import SimilarityAtlasSelector&#10;from atlas.voter.majority_voter import MajorityVoter&#10;from atlas.voter.weighted_majority_voter import WeightedMajorityVoter&#10;from preprocessing.blue_color_preprocessor import BlueColorPreprocessor&#10;from preprocessing.color_preprocessor import ColorPreprocessor&#10;from preprocessing.dimples_roi_preprocessor import DimplesRoiPreprocessor&#10;from preprocessing.torso_roi_preprocessor import TorsoRoiPreprocessor&#10;from segmenter.atlas_segmenter import AtlasSegmenter&#10;import time&#10;import os&#10;&#10;&#10;class AtlasSegmentationRunner:&#10;    def __init__(self, num_atlases_to_select, atlas_dir, preprocessing_steps, atlas_selector, segmentation_voter, segmentation_refiner, output_dir, target_images_dir):&#10;        self.segmenter = AtlasSegmenter(&#10;            num_atlases_to_select,&#10;            atlas_dir,&#10;            preprocessing_steps,&#10;            atlas_selector,&#10;            segmentation_voter,&#10;            segmentation_refiner,&#10;            output_dir&#10;        )&#10;        self.target_images_dir = target_images_dir&#10;&#10;    def run(self):&#10;        # start timing&#10;        start_time = time.time()&#10;        target_images = self.segmenter.load_target_images(self.target_images_dir)&#10;        segmented_images = self.segmenter.segment_images(target_images)&#10;        self.segmenter.save_segmentation(segmented_images)&#10;        # end timing and compute durations&#10;        end_time = time.time()&#10;        total_seconds = end_time - start_time&#10;        # format total duration h:m:s&#10;        hrs = int(total_seconds // 3600)&#10;        mins = int((total_seconds % 3600) // 60)&#10;        secs = int(total_seconds % 60)&#10;        duration_str = f&quot;{hrs:02d}:{mins:02d}:{secs:02d}&quot;&#10;        # average per image&#10;        num_images = len(target_images)&#10;        if num_images &gt; 0:&#10;            avg_seconds = total_seconds / num_images&#10;            avg_hrs = int(avg_seconds // 3600)&#10;            avg_mins = int((avg_seconds % 3600) // 60)&#10;            avg_secs = int(avg_seconds % 60)&#10;            avg_str = f&quot;{avg_hrs:02d}:{avg_mins:02d}:{avg_secs:02d}&quot;&#10;        else:&#10;            avg_str = &quot;00:00:00&quot;&#10;        # write durations to file in output_dir&#10;        duration_file = os.path.join(self.segmenter.output_dir, &quot;duration.txt&quot;)&#10;        with open(duration_file, &quot;w&quot;) as f:&#10;            f.write(f&quot;Total duration: {duration_str}\n&quot;)&#10;            f.write(f&quot;Average per image: {avg_str}\n&quot;)&#10;&#10;# Beispiel für die Ausführung:&#10;if __name__ == &quot;__main__&quot;:&#10;    # Hier müssen die passenden Objekte und Parameter übergeben werden&#10;    runner = AtlasSegmentationRunner(&#10;        num_atlases_to_select=13,&#10;        atlas_dir=&quot;data/Atlas_Data_BMI_Percentile&quot;,&#10;        # preprocessing_steps=[DimplesRoiPreprocessor(target_ratio=10/7) ,BlueColorPreprocessor()],  # Liste mit Preprocessing-Objekten&#10;        preprocessing_steps=[],  # Liste mit Preprocessing-Objekten&#10;        atlas_selector=BmiAtlasSelector(&quot;data/Info_Sheets/All_Data_Renamed_overview.csv&quot;, &quot;data/Info_Sheets/bmi_table_who.csv&quot;),      # AtlasSelector-Objekt&#10;        segmentation_voter=WeightedMajorityVoter(scheme=&quot;softmax&quot;, temperature=0.02, threshold=0.5),  # SegmentationVoter-Objekt&#10;        segmentation_refiner=ColorPatchRefiner(BlueColorPreprocessor()),&#10;        output_dir=&quot;data/Atlas_Experiment100&quot;,&#10;        target_images_dir=&quot;data/Validation_Data_Small&quot;&#10;    )&#10;    # runner = AtlasSegmentationRunner(&#10;    #     num_atlases_to_select=3,&#10;    #     atlas_dir=&quot;data/Atlas_Data&quot;,&#10;    #     preprocessing_steps=[],  # Liste mit Preprocessing-Objekten&#10;    #     atlas_selector=SimilarityAtlasSelector(),      # AtlasSelector-Objekt&#10;    #     segmentation_voter=MajorityVoter(),  # SegmentationVoter-Objekt&#10;    #     segmentation_refiner=None,&#10;    #     output_dir=&quot;data/Atlas_Experiment01&quot;,&#10;    #     target_images_dir=&quot;data/Validation_Data_Small&quot;&#10;    # )&#10;    runner.run()" />
              <option name="updatedContent" value="from atlas.refiner.color_patch_refiner import ColorPatchRefiner&#10;from atlas.selector.bmi_atlas_selector import BmiAtlasSelector&#10;from atlas.selector.similarity_atlas_selector import SimilarityAtlasSelector&#10;from atlas.voter.majority_voter import MajorityVoter&#10;from atlas.voter.weighted_majority_voter import WeightedMajorityVoter&#10;from preprocessing.blue_color_preprocessor import BlueColorPreprocessor&#10;from preprocessing.color_preprocessor import ColorPreprocessor&#10;from preprocessing.dimples_roi_preprocessor import DimplesRoiPreprocessor&#10;from preprocessing.torso_roi_preprocessor import TorsoRoiPreprocessor&#10;from segmenter.atlas_segmenter import AtlasSegmenter&#10;import time&#10;import os&#10;&#10;&#10;class AtlasSegmentationRunner:&#10;    def __init__(self, num_atlases_to_select, atlas_dir, preprocessing_steps, atlas_selector, segmentation_voter, segmentation_refiner, output_dir, target_images_dir):&#10;        self.segmenter = AtlasSegmenter(&#10;            num_atlases_to_select,&#10;            atlas_dir,&#10;            preprocessing_steps,&#10;            atlas_selector,&#10;            segmentation_voter,&#10;            segmentation_refiner,&#10;            output_dir&#10;        )&#10;        self.target_images_dir = target_images_dir&#10;&#10;    def run(self):&#10;        # start timing&#10;        start_time = time.time()&#10;        target_images = self.segmenter.load_target_images(self.target_images_dir)&#10;        segmented_images = self.segmenter.segment_images(target_images)&#10;        self.segmenter.save_segmentation(segmented_images)&#10;        # end timing and compute durations&#10;        end_time = time.time()&#10;        total_seconds = end_time - start_time&#10;        # format total duration h:m:s&#10;        hrs = int(total_seconds // 3600)&#10;        mins = int((total_seconds % 3600) // 60)&#10;        secs = int(total_seconds % 60)&#10;        duration_str = f&quot;{hrs:02d}:{mins:02d}:{secs:02d}&quot;&#10;        # average per image&#10;        num_images = len(target_images)&#10;        if num_images &gt; 0:&#10;            avg_seconds = total_seconds / num_images&#10;            avg_hrs = int(avg_seconds // 3600)&#10;            avg_mins = int((avg_seconds % 3600) // 60)&#10;            avg_secs = int(avg_seconds % 60)&#10;            avg_str = f&quot;{avg_hrs:02d}:{avg_mins:02d}:{avg_secs:02d}&quot;&#10;        else:&#10;            avg_str = &quot;00:00:00&quot;&#10;        # write durations to file in output_dir&#10;        duration_file = os.path.join(self.segmenter.output_dir, &quot;duration.txt&quot;)&#10;        with open(duration_file, &quot;w&quot;) as f:&#10;            f.write(f&quot;Total duration: {duration_str}\n&quot;)&#10;            f.write(f&quot;Average per image: {avg_str}\n&quot;)&#10;&#10;# Beispiel für die Ausführung:&#10;if __name__ == &quot;__main__&quot;:&#10;    # Hier müssen die passenden Objekte und Parameter übergeben werden&#10;    runner = AtlasSegmentationRunner(&#10;        num_atlases_to_select=13,&#10;        atlas_dir=&quot;data/Atlas_Data_BMI_Percentile&quot;,&#10;        # preprocessing_steps=[DimplesRoiPreprocessor(target_ratio=10/7) ,BlueColorPreprocessor()],  # Liste mit Preprocessing-Objekten&#10;        preprocessing_steps=[],  # Liste mit Preprocessing-Objekten&#10;        atlas_selector=BmiAtlasSelector(&quot;data/Info_Sheets/All_Data_Renamed_overview.csv&quot;, &quot;data/Info_Sheets/bmi_table_who.csv&quot;),      # AtlasSelector-Objekt&#10;        segmentation_voter=WeightedMajorityVoter(scheme=&quot;softmax&quot;, temperature=0.02, threshold=0.5),  # SegmentationVoter-Objekt&#10;        segmentation_refiner=ColorPatchRefiner(BlueColorPreprocessor()),&#10;        output_dir=&quot;data/Atlas_Experiment100&quot;,&#10;        target_images_dir=&quot;data/Validation_Data_Small&quot;&#10;    )&#10;    # runner = AtlasSegmentationRunner(&#10;    #     num_atlases_to_select=3,&#10;    #     atlas_dir=&quot;data/Atlas_Data&quot;,&#10;    #     preprocessing_steps=[],  # Liste mit Preprocessing-Objekten&#10;    #     atlas_selector=SimilarityAtlasSelector(),      # AtlasSelector-Objekt&#10;    #     segmentation_voter=MajorityVoter(),  # SegmentationVoter-Objekt&#10;    #     segmentation_refiner=None,&#10;    #     output_dir=&quot;data/Atlas_Experiment01&quot;,&#10;    #     target_images_dir=&quot;data/Validation_Data_Small&quot;&#10;    # )&#10;    runner.run()" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/validation/validator.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/validation/validator.py" />
              <option name="originalContent" value="import csv&#10;import os&#10;import re&#10;from pathlib import Path&#10;from typing import Optional, Tuple&#10;&#10;import matplotlib.pyplot as plt&#10;import numpy as np&#10;from skimage import io&#10;from skimage.measure import label&#10;from tqdm import tqdm&#10;from collections import defaultdict&#10;&#10;from validation.evaluation_metrics import EvaluationMetrics&#10;&#10;&#10;class Validator:&#10;&#10;    def __init__(self, ground_truth_dir, output_dir):&#10;        self.ground_truth_dir = ground_truth_dir&#10;        self.ground_truths = self.load_masks(ground_truth_dir)&#10;        self.output_dir = output_dir&#10;        self.vp_dm_distances = self.load_vp_dm_distances()&#10;&#10;    def validate(self, predictions_dir):&#10;        ground_truths = self.ground_truths&#10;        predictions = self.load_masks(predictions_dir)&#10;&#10;&#10;        # Collect per-file rows and group metrics by dataset&#10;        rows: list[list] = []&#10;        metrics_by_set: dict[str, list[EvaluationMetrics]] = defaultdict(list)&#10;        metrics_by_sick: dict[str, list[EvaluationMetrics]] = defaultdict(list)&#10;&#10;        # load mapping from Patientenindex to Krank value&#10;        sick_map = self.load_patient_sick_map()&#10;&#10;        # iterate over all ground truth files and validate predictions&#10;        for file_name in tqdm(ground_truths.keys(), desc=f'Validating predictions for {predictions_dir}'):&#10;            if file_name not in predictions.keys():&#10;                print(f&quot;Ground truth {file_name} does not have a corresponding prediction.&quot;)&#10;                continue&#10;&#10;            dataset = self.parse_dataset(file_name)&#10;            gt = ground_truths[file_name]&#10;            prediction = predictions[file_name]&#10;&#10;            metrics = self.compute_metrics(file_name, gt, prediction)&#10;&#10;            # determine sick status from patient index&#10;            pat_idx = self.parse_patient_index_from_image_path(file_name)&#10;            sick = sick_map.get(pat_idx)&#10;&#10;            # collect all data in a row&#10;            rows.append([&#10;                dataset, file_name, sick,&#10;                metrics.tp, metrics.fp, metrics.fn,&#10;                metrics.dice, metrics.precision, metrics.recall,&#10;                metrics.n_gt_segments, metrics.n_pred_segments,&#10;                metrics.n_gt_segments_left, metrics.n_pred_segments_left,&#10;                metrics.n_gt_segments_right, metrics.n_pred_segments_right,&#10;                metrics.n_segments_success,&#10;                metrics.center_gt_left, metrics.center_pred_left,&#10;                metrics.center_gt_right, metrics.center_pred_right,&#10;                metrics.center_pred_success,&#10;                metrics.center_diers_left, metrics.center_diers_right,&#10;                metrics.center_diers_success,&#10;                metrics.center_angle_error, metrics.center_angle_error_abs,&#10;                metrics.center_angle_success,&#10;                metrics.center_angle_diers_error, metrics.center_angle_diers_error_abs,&#10;                metrics.center_angle_diers_success&#10;            ])&#10;&#10;            # group by dataset&#10;            metrics_by_set[dataset].append(metrics)&#10;&#10;            # group by sick status: 1.0 sick, 0.0 healthy&#10;            if sick == 1.0:&#10;                metrics_by_sick['Sick'].append(metrics)&#10;            elif sick == 0.0:&#10;                metrics_by_sick['Healthy'].append(metrics)&#10;&#10;        # prepare output directories&#10;        output_dir = Path(self.output_dir)&#10;        output_dir.mkdir(parents=True, exist_ok=True)&#10;        run_name = os.path.basename(predictions_dir)&#10;        all_csv = output_dir / f&quot;{run_name}_all.csv&quot;&#10;        mean_csv = output_dir / f&quot;{run_name}_mean.csv&quot;&#10;&#10;        # write all per-file metrics&#10;        with open(all_csv, 'w', newline='') as csvfile:&#10;            writer = csv.writer(csvfile)&#10;            header = [&#10;                'Dataset', 'File Name', 'Sick',&#10;                'TP', 'FP', 'FN',&#10;                'Dice', 'Precision', 'Recall',&#10;                'N GT Segments', 'N Pred Segments',&#10;                'N GT Segments Left', 'N Pred Segments Left',&#10;                'N GT Segments Right', 'N of Pred Segments Right',&#10;                'N Segments Success',&#10;                'Center GT Left', 'Center Pred Left',&#10;                'Center GT Right', 'Center Pred Right',&#10;                'Center Pred Success',&#10;                'Center Diers Left', 'Center Diers Right',&#10;                'Center Diers Success',&#10;                'Center Angle Error', 'Center Angle Error Abs',&#10;                'Center Angle Success',&#10;                'Center Angle Diers Error', 'Center Angle Diers Error Abs',&#10;                'Center Angle Diers Success'&#10;            ]&#10;            writer.writerow(header)&#10;            writer.writerows(rows)&#10;        print(f&quot;Validation results saved to {all_csv}&quot;)&#10;&#10;        # Read duration metrics&#10;        from pathlib import Path  # ensure Path is imported&#10;        _duration_file = Path(predictions_dir) / 'duration.txt'&#10;        if _duration_file.exists():&#10;            with open(_duration_file, 'r') as _df:&#10;                _lines = _df.readlines()&#10;            if len(_lines) &gt;= 2:&#10;                total_duration = _lines[0].split(':',1)[1].strip()&#10;                avg_image_duration = _lines[1].split(':',1)[1].strip()&#10;            else:&#10;                total_duration = ''&#10;                avg_image_duration = ''&#10;        else:&#10;            total_duration = ''&#10;            avg_image_duration = ''&#10;&#10;        # Write mean metrics grouped by dataset, by sick status and overall&#10;        with open(mean_csv, 'w', newline='') as csvfile:&#10;            writer = csv.writer(csvfile)&#10;            header_mean = [&#10;                'Dataset',&#10;                'TP', 'FP', 'FN',&#10;                'Dice', 'Precision', 'Recall',&#10;                'N GT Segments', 'N Pred Segments',&#10;                'N GT Segments Left', 'N Pred Segments Left',&#10;                'N GT Segments Right', 'N of Pred Segments Right',&#10;                'N Segments Success',&#10;                'Center GT Left', 'Center Pred Left',&#10;                'Center GT Right', 'Center Pred Right',&#10;                'Center Pred Success',&#10;                'Center Diers Left', 'Center Diers Right',&#10;                'Center Diers Success',&#10;                'Center Angle Error', 'Center Angle Error Abs',&#10;                'Center Angle Success',&#10;                'Center Angle Diers Error', 'Center Angle Diers Error Abs',&#10;                'Center Angle Diers Success',&#10;                'Total duration', 'Average duration per image'&#10;            ]&#10;            writer.writerow(header_mean)&#10;            # per-dataset means&#10;            for dataset, mlist in metrics_by_set.items():&#10;                writer.writerow([&#10;                    dataset,&#10;                    _safe_nanmean([m.tp for m in mlist]),&#10;                    _safe_nanmean([m.fp for m in mlist]),&#10;                    _safe_nanmean([m.fn for m in mlist]),&#10;                    _safe_nanmean([m.dice for m in mlist]),&#10;                    _safe_nanmean([m.precision for m in mlist]),&#10;                    _safe_nanmean([m.recall for m in mlist]),&#10;                    _safe_nanmean([m.n_gt_segments for m in mlist]),&#10;                    _safe_nanmean([m.n_pred_segments for m in mlist]),&#10;                    _safe_nanmean([m.n_gt_segments_left for m in mlist]),&#10;                    _safe_nanmean([m.n_pred_segments_left for m in mlist]),&#10;                    _safe_nanmean([m.n_gt_segments_right for m in mlist]),&#10;                    _safe_nanmean([m.n_pred_segments_right for m in mlist]),&#10;                    _safe_nanmean([m.n_segments_success for m in mlist if m.n_segments_success is not None]),&#10;                    (&#10;                        _safe_nanmean([m.center_gt_left[0] for m in mlist if m.center_gt_left is not None]),&#10;                        _safe_nanmean([m.center_gt_left[1] for m in mlist if m.center_gt_left is not None])&#10;                    ),&#10;                    (&#10;                        _safe_nanmean([m.center_pred_left[0] for m in mlist if m.center_pred_left is not None]),&#10;                        _safe_nanmean([m.center_pred_left[1] for m in mlist if m.center_pred_left is not None])&#10;                    ),&#10;                    (&#10;                        _safe_nanmean([m.center_gt_right[0] for m in mlist if m.center_gt_right is not None]),&#10;                        _safe_nanmean([m.center_gt_right[1] for m in mlist if m.center_gt_right is not None])&#10;                    ),&#10;                    (&#10;                        _safe_nanmean([m.center_pred_right[0] for m in mlist if m.center_pred_right is not None]),&#10;                        _safe_nanmean([m.center_pred_right[1] for m in mlist if m.center_pred_right is not None])&#10;                    ),&#10;                    _safe_nanmean([m.center_pred_success for m in mlist if m.center_pred_success is not None]),&#10;                    (&#10;                        _safe_nanmean([m.center_diers_left[0] for m in mlist if m.center_diers_left is not None]),&#10;                        _safe_nanmean([m.center_diers_left[1] for m in mlist if m.center_diers_left is not None])&#10;                    ),&#10;                    (&#10;                        _safe_nanmean([m.center_diers_right[0] for m in mlist if m.center_diers_right is not None]),&#10;                        _safe_nanmean([m.center_diers_right[1] for m in mlist if m.center_diers_right is not None])&#10;                    ),&#10;                    _safe_nanmean([m.center_diers_success for m in mlist if m.center_diers_success is not None]),&#10;                    _safe_nanmean([m.center_angle_error for m in mlist if m.center_angle_error is not None]),&#10;                    _safe_nanmean([m.center_angle_error_abs for m in mlist if m.center_angle_error_abs is not None]),&#10;                    _safe_nanmean([m.center_angle_success for m in mlist if m.center_angle_success is not None]),&#10;                    _safe_nanmean([m.center_angle_diers_error for m in mlist if m.center_angle_diers_error is not None]),&#10;                    _safe_nanmean([m.center_angle_diers_error_abs for m in mlist if m.center_angle_diers_error_abs is not None]),&#10;                    _safe_nanmean([m.center_angle_diers_success for m in mlist if m.center_angle_diers_success is not None]),&#10;                    '', ''&#10;                ])&#10;            # Sick and Healthy means&#10;            for status, mlist in [('Sick', metrics_by_sick['Sick']), ('Healthy', metrics_by_sick['Healthy'])]:&#10;                writer.writerow([&#10;                    status,&#10;                    _safe_nanmean([m.tp for m in mlist]),&#10;                    _safe_nanmean([m.fp for m in mlist]),&#10;                    _safe_nanmean([m.fn for m in mlist]),&#10;                    _safe_nanmean([m.dice for m in mlist]),&#10;                    _safe_nanmean([m.precision for m in mlist]),&#10;                    _safe_nanmean([m.recall for m in mlist]),&#10;                    _safe_nanmean([m.n_gt_segments for m in mlist]),&#10;                    _safe_nanmean([m.n_pred_segments for m in mlist]),&#10;                    _safe_nanmean([m.n_gt_segments_left for m in mlist]),&#10;                    _safe_nanmean([m.n_pred_segments_left for m in mlist]),&#10;                    _safe_nanmean([m.n_gt_segments_right for m in mlist]),&#10;                    _safe_nanmean([m.n_pred_segments_right for m in mlist]),&#10;                    _safe_nanmean([m.n_segments_success for m in mlist if m.n_segments_success is not None]),&#10;                    (&#10;                        _safe_nanmean([m.center_gt_left[0] for m in mlist if m.center_gt_left is not None]),&#10;                        _safe_nanmean([m.center_gt_left[1] for m in mlist if m.center_gt_left is not None])&#10;                    ),&#10;                    (&#10;                        _safe_nanmean([m.center_pred_left[0] for m in mlist if m.center_pred_left is not None]),&#10;                        _safe_nanmean([m.center_pred_left[1] for m in mlist if m.center_pred_left is not None])&#10;                    ),&#10;                    (&#10;                        _safe_nanmean([m.center_gt_right[0] for m in mlist if m.center_gt_right is not None]),&#10;                        _safe_nanmean([m.center_gt_right[1] for m in mlist if m.center_gt_right is not None])&#10;                    ),&#10;                    (&#10;                        _safe_nanmean([m.center_pred_right[0] for m in mlist if m.center_pred_right is not None]),&#10;                        _safe_nanmean([m.center_pred_right[1] for m in mlist if m.center_pred_right is not None])&#10;                    ),&#10;                    _safe_nanmean([m.center_pred_success for m in mlist if m.center_pred_success is not None]),&#10;                    (&#10;                        _safe_nanmean([m.center_diers_left[0] for m in mlist if m.center_diers_left is not None]),&#10;                        _safe_nanmean([m.center_diers_left[1] for m in mlist if m.center_diers_left is not None])&#10;                    ),&#10;                    (&#10;                        _safe_nanmean([m.center_diers_right[0] for m in mlist if m.center_diers_right is not None]),&#10;                        _safe_nanmean([m.center_diers_right[1] for m in mlist if m.center_diers_right is not None])&#10;                    ),&#10;                    _safe_nanmean([m.center_diers_success for m in mlist if m.center_diers_success is not None]),&#10;                    _safe_nanmean([m.center_angle_error for m in mlist if m.center_angle_error is not None]),&#10;                    _safe_nanmean([m.center_angle_error_abs for m in mlist if m.center_angle_error_abs is not None]),&#10;                    _safe_nanmean([m.center_angle_success for m in mlist if m.center_angle_success is not None]),&#10;                    _safe_nanmean([m.center_angle_diers_error for m in mlist if m.center_angle_diers_error is not None]),&#10;                    _safe_nanmean([m.center_angle_diers_error_abs for m in mlist if m.center_angle_diers_error_abs is not None]),&#10;                    _safe_nanmean([m.center_angle_diers_success for m in mlist if m.center_angle_diers_success is not None]),&#10;                    '', ''&#10;                ])&#10;            # overall mean&#10;            all_metrics = [m for lst in metrics_by_set.values() for m in lst]&#10;            writer.writerow([&#10;                'All Datasets',&#10;                _safe_nanmean([m.tp for m in all_metrics]),&#10;                _safe_nanmean([m.fp for m in all_metrics]),&#10;                _safe_nanmean([m.fn for m in all_metrics]),&#10;                _safe_nanmean([m.dice for m in all_metrics]),&#10;                _safe_nanmean([m.precision for m in all_metrics]),&#10;                _safe_nanmean([m.recall for m in all_metrics]),&#10;                _safe_nanmean([m.n_gt_segments for m in all_metrics]),&#10;                _safe_nanmean([m.n_pred_segments for m in all_metrics]),&#10;                _safe_nanmean([m.n_gt_segments_left for m in all_metrics]),&#10;                _safe_nanmean([m.n_pred_segments_left for m in all_metrics]),&#10;                _safe_nanmean([m.n_gt_segments_right for m in all_metrics]),&#10;                _safe_nanmean([m.n_pred_segments_right for m in all_metrics]),&#10;                _safe_nanmean([m.n_segments_success for m in all_metrics if m.n_segments_success is not None]),&#10;                (&#10;                    _safe_nanmean([m.center_gt_left[0] for m in all_metrics if m.center_gt_left is not None]),&#10;                    _safe_nanmean([m.center_gt_left[1] for m in all_metrics if m.center_gt_left is not None])&#10;                ),&#10;                (&#10;                    _safe_nanmean([m.center_pred_left[0] for m in all_metrics if m.center_pred_left is not None]),&#10;                    _safe_nanmean([m.center_pred_left[1] for m in all_metrics if m.center_pred_left is not None])&#10;                ),&#10;                (&#10;                    _safe_nanmean([m.center_gt_right[0] for m in all_metrics if m.center_gt_right is not None]),&#10;                    _safe_nanmean([m.center_gt_right[1] for m in all_metrics if m.center_gt_right is not None])&#10;                ),&#10;                (&#10;                    _safe_nanmean([m.center_pred_right[0] for m in all_metrics if m.center_pred_right is not None]),&#10;                    _safe_nanmean([m.center_pred_right[1] for m in all_metrics if m.center_pred_right is not None])&#10;                ),&#10;                _safe_nanmean([m.center_pred_success for m in all_metrics if m.center_pred_success is not None]),&#10;                (&#10;                    _safe_nanmean([m.center_diers_left[0] for m in all_metrics if m.center_diers_left is not None]),&#10;                    _safe_nanmean([m.center_diers_left[1] for m in all_metrics if m.center_diers_left is not None])&#10;                ),&#10;                (&#10;                    _safe_nanmean([m.center_diers_right[0] for m in all_metrics if m.center_diers_right is not None]),&#10;                    _safe_nanmean([m.center_diers_right[1] for m in all_metrics if m.center_diers_right is not None])&#10;                ),&#10;                _safe_nanmean([m.center_diers_success for m in all_metrics if m.center_diers_success is not None]),&#10;                _safe_nanmean([m.center_angle_error for m in all_metrics if m.center_angle_error is not None]),&#10;                _safe_nanmean([m.center_angle_error_abs for m in all_metrics if m.center_angle_error_abs is not None]),&#10;                _safe_nanmean([m.center_angle_success for m in all_metrics if m.center_angle_success is not None]),&#10;                _safe_nanmean([m.center_angle_diers_error for m in all_metrics if m.center_angle_diers_error is not None]),&#10;                _safe_nanmean([m.center_angle_diers_error_abs for m in all_metrics if m.center_angle_diers_error_abs is not None]),&#10;                _safe_nanmean([m.center_angle_diers_success for m in all_metrics if m.center_angle_diers_success is not None]),&#10;                total_duration, avg_image_duration&#10;            ])&#10;        print(f&quot;Mean validation results saved to {mean_csv}&quot;)&#10;&#10;    @staticmethod&#10;    def parse_dataset(file_name):&#10;        prefix = file_name.split('_')[0]&#10;        return prefix&#10;&#10;&#10;    @staticmethod&#10;    def load_masks(segmentations_dir):&#10;        segmentations = {}&#10;        for file in os.listdir(segmentations_dir):&#10;            if file.endswith(&quot;.png&quot;) and &quot;-mask&quot; in file:&#10;                segmentations[file] = io.imread(os.path.join(segmentations_dir, file))&#10;        return segmentations&#10;&#10;    def compute_metrics(self, file_name, gt, pred):&#10;        # Binary masks&#10;        gt_mask = gt &gt; 0&#10;        pred_mask = pred &gt; 0&#10;&#10;        # Load markers&#10;        vp, dm, dl_diers, dr_diers = self.load_markers(file_name)&#10;&#10;        # Calc pixel ratio in mm&#10;        pat_idx = self.parse_patient_index_from_image_path(file_name)&#10;        pixel_size = self.compute_distance_per_pixel(pat_idx, vp, dm)&#10;&#10;        # Initialize object to hold metrics&#10;        metrics = EvaluationMetrics()&#10;&#10;        # True Positives, False Positives, False Negatives&#10;        metrics.tp = np.logical_and(gt_mask, pred_mask).sum()&#10;        metrics.fp = np.logical_and(~gt_mask, pred_mask).sum()&#10;        metrics.fn = np.logical_and(gt_mask, ~pred_mask).sum()&#10;&#10;        # Dice Coefficient&#10;        metrics.dice = self.compute_dice(gt_mask, pred_mask, metrics)&#10;&#10;        # Precision&#10;        metrics.precision = self.compute_precision(metrics)&#10;&#10;        # Recall&#10;        metrics.recall = self.compute_recall(metrics)&#10;&#10;        # Total number of segments&#10;        metrics.n_gt_segments = int(label(gt_mask).max())&#10;        metrics.n_pred_segments = int(label(pred_mask).max())&#10;        metrics.n_gt_segments_left = self.compute_n_segments(gt_mask, vp, dm, side='left')&#10;        metrics.n_pred_segments_left = self.compute_n_segments(pred_mask, vp, dm, side='left')&#10;        metrics.n_gt_segments_right = self.compute_n_segments(gt_mask, vp, dm, side='right')&#10;        metrics.n_pred_segments_right = self.compute_n_segments(pred_mask, vp, dm, side='right')&#10;        metrics.n_segments_success = self.compute_n_segments_success(gt_mask, pred_mask)&#10;&#10;        # Center of left and right dimples&#10;        metrics.center_gt_left = self.compute_center(gt_mask, vp, dm, side='left')&#10;        metrics.center_pred_left = self.compute_center(pred_mask, vp, dm, side='left')&#10;        metrics.center_gt_right = self.compute_center(gt_mask, vp, dm, side='right')&#10;        metrics.center_pred_right = self.compute_center(pred_mask, vp, dm, side='right')&#10;        metrics.center_pred_success = self.compute_center_pred_success(metrics, pixel_size)&#10;&#10;        # Compute center distance to diers captured data (!not necessarily equal to gt if gt is annotated differently!)&#10;        metrics.center_diers_left = dl_diers&#10;        metrics.center_diers_right = dr_diers&#10;        metrics.center_diers_success = self.compute_center_pred_success(metrics, pixel_size, compare_to_diers=True)&#10;&#10;        # Angle error between center lines&#10;        metrics.center_angle_error = self.compute_center_angle_error(metrics, absolute=False)&#10;        metrics.center_angle_error_abs = self.compute_center_angle_error(metrics, absolute=True)&#10;        metrics.center_angle_success = self.compute_center_angle_success(metrics)&#10;&#10;        # Angle error between center lines to diers captured data (!not necessarily equal to gt if gt is annotated differently!)&#10;        metrics.center_angle_diers_error = self.compute_center_angle_error(metrics, absolute=False, compare_to_diers=True)&#10;        metrics.center_angle_diers_error_abs = self.compute_center_angle_error(metrics, absolute=True, compare_to_diers=True)&#10;        metrics.center_angle_diers_success = self.compute_center_angle_success(metrics, compare_to_diers=True)&#10;&#10;        # # display original mask with splitting line overlay in pink&#10;        # # load original images (same name without '-mask')&#10;        # from pathlib import Path&#10;        # base_name = file_name.replace('-mask', '')&#10;        # orig_gt_path = Path(self.ground_truth_dir) / base_name&#10;        # orig_pred_path = Path(self.current_predictions_dir) / base_name&#10;        # try:&#10;        #     orig_gt_img = io.imread(orig_gt_path)&#10;        #     self.visualize_middle_line(orig_gt_img, vp, dm, f&quot;{file_name} Ground Truth Split on Original&quot;)&#10;        # except Exception:&#10;        #     pass&#10;        # try:&#10;        #     orig_pred_img = io.imread(orig_pred_path)&#10;        #     self.visualize_middle_line(orig_pred_img, vp, dm, f&quot;{file_name} Pred Split on Original&quot;)&#10;        # except Exception:&#10;        #     pass&#10;&#10;        return metrics&#10;&#10;    @staticmethod&#10;    def compute_dice(gt_mask, pred_mask, metrics):&#10;        if gt_mask.sum() + pred_mask.sum() == 0:&#10;            dice = 1.0&#10;        else:&#10;            dice = (2. * metrics.tp) / (gt_mask.sum() + pred_mask.sum())&#10;        return dice&#10;&#10;    @staticmethod&#10;    def compute_precision(metrics):&#10;        if metrics.tp + metrics.fp == 0:&#10;            precision = 1&#10;        else:&#10;            precision = metrics.tp / (metrics.tp + metrics.fp)&#10;        return precision&#10;&#10;    @staticmethod&#10;    def compute_recall(metrics):&#10;        if metrics.tp + metrics.fn == 0:&#10;            recall = 1&#10;        else:&#10;            recall = metrics.tp / (metrics.tp + metrics.fn)&#10;        return recall&#10;&#10;    @staticmethod&#10;    def compute_n_segments_success(gt_mask, pred_mask):&#10;        &quot;&quot;&quot;Return 1 if every GT segment has at least one pixel in the prediction; Also 1 if no GT segments.&quot;&quot;&quot;&#10;        # label ground truth components&#10;        labels_gt = label(gt_mask)&#10;        n = labels_gt.max()&#10;        if n == 0:&#10;            return 1&#10;        # check overlap for each segment&#10;        for seg in range(1, n+1):&#10;            if not np.any(pred_mask[labels_gt == seg]):&#10;                return 0&#10;        return 1&#10;&#10;    def load_markers(self, file_name, markers_file=&quot;data/Info_sheets/Markerpositionen.csv&quot;):&#10;        img_number = self.extract_image_number(file_name)&#10;&#10;        with open(markers_file, 'r', newline='') as csvfile:&#10;            reader = csv.DictReader(csvfile, delimiter=';')&#10;            for row in reader:&#10;                if row.get('BildID', '').startswith(str(img_number)):&#10;                    vp = (int(row['X_VP']) / 10, int(row['Y_VP']) / 10)&#10;                    dm = (int(row['X_DM']) / 10, int(row['Y_DM']) / 10)&#10;                    dl_diers = (int(row['X_DL']) / 10, int(row['Y_DL']) / 10)&#10;                    dr_diers = (int(row['X_DR']) / 10, int(row['Y_DR']) / 10)&#10;                    return vp, dm, dl_diers, dr_diers&#10;&#10;        pat_idx = self.parse_patient_index_from_image_path(file_name)&#10;        with open('data/Info_Sheets/All_Data_Renamed_overview.csv', 'r', newline='') as csvfile:&#10;            reader = csv.DictReader(csvfile)&#10;            for row in reader:&#10;                if row.get('PatientsLikeMe') == pat_idx:&#10;                    measure_id = row['DIERS_Mess-ID']&#10;&#10;        with open(markers_file, 'r', newline='') as csvfile:&#10;            reader = csv.DictReader(csvfile)&#10;            for row in reader:&#10;                if row.get('MessID', '') == measure_id:&#10;                    vp = (int(row['X_VP'] / 10), int(row['Y_VP']) / 10)&#10;                    dm = (int(row['X_DM'] / 10), int(row['Y_DM']) / 10)&#10;                    dl_diers = (int(row['X_DL']) / 10, int(row['Y_DL']) / 10)&#10;                    dr_diers = (int(row['X_DR']) / 10, int(row['Y_DR']) / 10)&#10;                    return vp, dm, dl_diers, dr_diers&#10;&#10;        return None, None, None, None&#10;&#10;    @staticmethod&#10;    def compute_n_segments(mask, vp, dm, side):&#10;        &quot;&quot;&quot;Count labeled segments in the left or right half of a binary mask.&quot;&quot;&quot;&#10;        # prepare 2D binary mask&#10;        m = mask.astype(bool)&#10;        if m.ndim == 3:&#10;            m = m[..., 0]&#10;        h, w = m.shape&#10;        # coordinate grid&#10;        x = np.arange(w)[None, :]&#10;        y = np.arange(h)[:, None]&#10;        # split by marker line or center&#10;        if vp is not None and dm is not None:&#10;            x1, y1 = vp&#10;            x2, y2 = dm&#10;            s = (x - x1) * (y2 - y1) - (y - y1) * (x2 - x1)&#10;            half = (s &lt; 0) if side == 'left' else (s &gt;= 0)&#10;        else:&#10;            mid = w // 2&#10;            half = (x &lt; mid) if side == 'left' else (x &gt;= mid)&#10;        region = m &amp; half&#10;        return int(label(region).max())&#10;&#10;    @staticmethod&#10;    def compute_center(mask, vp, dm, side):&#10;        &quot;&quot;&quot;Compute centroid of mask in left or right half region.&quot;&quot;&quot;&#10;        # prepare binary mask&#10;        m = mask.astype(bool)&#10;        if m.ndim == 3:&#10;            m = m[..., 0]&#10;        h, w = m.shape&#10;        # coordinate grid&#10;        x = np.arange(w)[None, :]&#10;        y = np.arange(h)[:, None]&#10;        # define half by marker line or center&#10;        if vp is not None and dm is not None:&#10;            x1, y1 = vp&#10;            x2, y2 = dm&#10;            s = (x - x1) * (y2 - y1) - (y - y1) * (x2 - x1)&#10;            half = (s &lt; 0) if side == 'left' else (s &gt;= 0)&#10;        else:&#10;            mid = w // 2&#10;            half = (x &lt; mid) if side == 'left' else (x &gt;= mid)&#10;        region = m &amp; half&#10;        # find coordinates of pixels in region&#10;        ys, xs = np.where(region)&#10;        if xs.size == 0:&#10;            return None&#10;        # compute centroid&#10;        x_center = float(xs.mean())&#10;        y_center = float(ys.mean())&#10;        return x_center, y_center&#10;&#10;    @staticmethod&#10;    def parse_patient_index_from_image_path(image_path):&#10;        pattern = re.compile(r'^[^_]+_([^_]+(?:_\d+)+)(?=_\d{9,})')&#10;        match = pattern.search(os.path.basename(image_path))&#10;        if match:&#10;            return match.group(1)&#10;        return None&#10;&#10;    @staticmethod&#10;    def extract_image_number(file_name):&#10;        match = re.search(r'_(\d+)-mask\.Gauss\.png$', file_name)&#10;        if match:&#10;            return match.group(1)&#10;        return None&#10;&#10;    @staticmethod&#10;    def visualize_mask(image: np.ndarray, title: str):&#10;        &quot;&quot;&quot;Display the original mask image without any splitting lines or axes.&quot;&quot;&quot;&#10;        fig, ax = plt.subplots()&#10;        # display mask or full-color image&#10;        if image.ndim == 3 and image.shape[2] &gt;= 3:&#10;            ax.imshow(image, aspect='equal', interpolation='nearest')&#10;        else:&#10;            vis = image[...,0] if image.ndim == 3 else image&#10;            ax.imshow(vis, cmap='gray', aspect='equal', interpolation='nearest')&#10;        ax.axis('off')&#10;        ax.set_title(title)&#10;        plt.show()&#10;&#10;    @staticmethod&#10;    def visualize_middle_line(image: np.ndarray, vp: Optional[Tuple[int, int]], dm: Optional[Tuple[int, int]], title: str):&#10;        &quot;&quot;&quot;Display the mask image with a middle splitting line.&quot;&quot;&quot;&#10;        fig, ax = plt.subplots()&#10;        # if image has 3 or more channels, show in RGB, else grayscale&#10;        if image.ndim == 3 and image.shape[2] &gt;= 3:&#10;            ax.imshow(image, aspect='equal', interpolation='nearest')&#10;        else:&#10;            vis = image[...,0] if image.ndim == 3 else image&#10;            ax.imshow(vis, cmap='gray', aspect='equal', interpolation='nearest')&#10;&#10;        if vp is not None and dm is not None:&#10;            # Draw the splitting line in the middle of the two markers&#10;            xs = [vp[0], dm[0]]&#10;            ys = [vp[1], dm[1]]&#10;            ax.plot(xs, ys, color='magenta', linewidth=2)&#10;&#10;        ax.axis('off')&#10;        ax.set_title(title)&#10;        plt.show()&#10;&#10;    @staticmethod&#10;    def compute_center_angle_error(metrics, absolute=False, compare_to_diers=False):&#10;        &quot;&quot;&quot;Compute signed or absolute angle difference (in degrees) between GT and predicted dimple-center line.&quot;&quot;&quot;&#10;        if compare_to_diers:&#10;            gt_l = metrics.center_diers_left; gt_r = metrics.center_diers_right&#10;            pr_l = metrics.center_pred_left; pr_r = metrics.center_pred_right&#10;        else:&#10;            gt_l = metrics.center_gt_left; gt_r = metrics.center_gt_right&#10;            pr_l = metrics.center_pred_left; pr_r = metrics.center_pred_right&#10;        # ensure all centers are available&#10;        if None in (gt_l, gt_r, pr_l, pr_r):&#10;            return None&#10;        # compute line angles&#10;        dx_gt = gt_r[0] - gt_l[0]; dy_gt = gt_r[1] - gt_l[1]&#10;        dx_pr = pr_r[0] - pr_l[0]; dy_pr = pr_r[1] - pr_l[1]&#10;        angle_gt = np.degrees(np.arctan2(dy_gt, dx_gt))&#10;        angle_pr = np.degrees(np.arctan2(dy_pr, dx_pr))&#10;        # error and normalization to [-180,180]&#10;        err = angle_pr - angle_gt&#10;        err = (err + 180) % 360 - 180&#10;        return abs(err) if absolute else err&#10;&#10;    @staticmethod&#10;    def compute_center_angle_success(metrics, threshold=4.2, compare_to_diers=False):&#10;        &quot;&quot;&quot;Return 1 if absolute angle error is below threshold degrees, else 0.&quot;&quot;&quot;&#10;        if compare_to_diers:&#10;            err = metrics.center_angle_diers_error_abs&#10;        else:&#10;            err = metrics.center_angle_error_abs&#10;        if err is None:&#10;            return None&#10;        return int(err &lt; threshold)&#10;&#10;    @staticmethod&#10;    def compute_center_pred_success(metrics, pixel_size, threshold=3.0, compare_to_diers=False):&#10;        &quot;&quot;&quot;Return 1 if both left and right center predictions are correct (both None or within threshold [mm] of GT).&quot;&quot;&quot;&#10;        if pixel_size is not None:&#10;            threshold = threshold / pixel_size&#10;        if compare_to_diers:&#10;            gl, pl = metrics.center_diers_left, metrics.center_pred_left&#10;            gr, pr = metrics.center_diers_right, metrics.center_pred_right&#10;        else:&#10;            gl, pl = metrics.center_gt_left, metrics.center_pred_left&#10;            gr, pr = metrics.center_gt_right, metrics.center_pred_right&#10;        def ok(gt, pr):&#10;            if gt is None and pr is None:&#10;                return True&#10;            if gt is not None and pr is not None:&#10;                # distance within threshold pixels&#10;                return np.hypot(gt[0] - pr[0], gt[1] - pr[1]) &lt;= threshold&#10;            return False&#10;        return int(ok(gl, pl) and ok(gr, pr))&#10;&#10;    def compute_distance_per_pixel(self, patient_idx, vp, dm):&#10;        &quot;&quot;&quot;&#10;        Compute millimeters per pixel using known physical distance between VP and DM markers.&#10;        &quot;&quot;&quot;&#10;        if vp is None or dm is None:&#10;            return None&#10;        # compute pixel distance between markers&#10;        pixel_dist = np.hypot(dm[0] - vp[0], dm[1] - vp[1])&#10;        if pixel_dist == 0:&#10;            return None&#10;        # get physical distance (mm) for this patient&#10;        mm_dist = self.vp_dm_distances.get(patient_idx)&#10;        if mm_dist is None:&#10;            return None&#10;        # mm per pixel&#10;        return mm_dist / pixel_dist&#10;&#10;    @staticmethod&#10;    def load_patient_sick_map(file_path=&quot;data/Info_Sheets/All_Data_Renamed_overview.csv&quot;):&#10;        &quot;&quot;&quot;Load the mapping from Patientenindex to Krank value.&quot;&quot;&quot;&#10;        sick_map = {}&#10;        with open(file_path, 'r', newline='') as csvfile:&#10;            reader = csv.DictReader(csvfile)&#10;            for row in reader:&#10;                pat_idx = row.get('Patientenindex')&#10;                sick = row.get('Krank')&#10;                if pat_idx and sick:&#10;                    sick_map[pat_idx] = float(sick)&#10;        return sick_map&#10;&#10;    @staticmethod&#10;    def load_vp_dm_distances(file_path=&quot;data/Info_Sheets/All_Data_Renamed_overview.csv&quot;):&#10;        vp_dm_distance_map = {}&#10;        with open(file_path, 'r', newline='') as csvfile:&#10;            reader = csv.DictReader(csvfile)&#10;            for row in reader:&#10;                pat_idx = row.get('Patientenindex')&#10;                dist_str = row.get('Rumpflänge')&#10;                if pat_idx and dist_str:&#10;                    try:&#10;                        dist_mm = float(dist_str)&#10;                        vp_dm_distance_map[pat_idx] = dist_mm&#10;                    except ValueError:&#10;                        continue&#10;        return vp_dm_distance_map&#10;&#10;&#10;def _safe_nanmean(arr):&#10;    if len(arr) == 0:&#10;        return None&#10;    mean_val = np.nanmean(arr)&#10;    return float(mean_val)&#10;" />
              <option name="updatedContent" value="import csv&#10;import os&#10;import re&#10;from pathlib import Path&#10;from typing import Optional, Tuple&#10;&#10;import matplotlib.pyplot as plt&#10;import numpy as np&#10;from skimage import io&#10;from skimage.measure import label&#10;from tqdm import tqdm&#10;from collections import defaultdict&#10;&#10;from validation.evaluation_metrics import EvaluationMetrics&#10;&#10;&#10;class Validator:&#10;&#10;    def __init__(self, ground_truth_dir, output_dir):&#10;        self.ground_truth_dir = ground_truth_dir&#10;        self.ground_truths = self.load_masks(ground_truth_dir)&#10;        self.output_dir = output_dir&#10;        self.vp_dm_distances = self.load_vp_dm_distances()&#10;&#10;    def validate(self, predictions_dir):&#10;        ground_truths = self.ground_truths&#10;        predictions = self.load_masks(predictions_dir)&#10;&#10;&#10;        # Collect per-file rows and group metrics by dataset&#10;        rows: list[list] = []&#10;        metrics_by_set: dict[str, list[EvaluationMetrics]] = defaultdict(list)&#10;        metrics_by_sick: dict[str, list[EvaluationMetrics]] = defaultdict(list)&#10;&#10;        # load mapping from Patientenindex to Krank value&#10;        sick_map = self.load_patient_sick_map()&#10;&#10;        # iterate over all ground truth files and validate predictions&#10;        for file_name in tqdm(ground_truths.keys(), desc=f'Validating predictions for {predictions_dir}'):&#10;            if file_name not in predictions.keys():&#10;                print(f&quot;Ground truth {file_name} does not have a corresponding prediction.&quot;)&#10;                continue&#10;&#10;            dataset = self.parse_dataset(file_name)&#10;            gt = ground_truths[file_name]&#10;            prediction = predictions[file_name]&#10;&#10;            metrics = self.compute_metrics(file_name, gt, prediction)&#10;&#10;            # determine sick status from patient index&#10;            pat_idx = self.parse_patient_index_from_image_path(file_name)&#10;            sick = sick_map.get(pat_idx)&#10;&#10;            # collect all data in a row&#10;            rows.append([&#10;                dataset, file_name, sick,&#10;                metrics.tp, metrics.fp, metrics.fn,&#10;                metrics.dice, metrics.precision, metrics.recall,&#10;                metrics.n_gt_segments, metrics.n_pred_segments,&#10;                metrics.n_gt_segments_left, metrics.n_pred_segments_left,&#10;                metrics.n_gt_segments_right, metrics.n_pred_segments_right,&#10;                metrics.n_segments_success,&#10;                metrics.center_gt_left, metrics.center_pred_left,&#10;                metrics.center_gt_right, metrics.center_pred_right,&#10;                metrics.center_pred_success,&#10;                metrics.center_diers_left, metrics.center_diers_right,&#10;                metrics.center_diers_success,&#10;                metrics.center_angle_error, metrics.center_angle_error_abs,&#10;                metrics.center_angle_success,&#10;                metrics.center_angle_diers_error, metrics.center_angle_diers_error_abs,&#10;                metrics.center_angle_diers_success&#10;            ])&#10;&#10;            # group by dataset&#10;            metrics_by_set[dataset].append(metrics)&#10;&#10;            # group by sick status: 1.0 sick, 0.0 healthy&#10;            if sick == 1.0:&#10;                metrics_by_sick['Sick'].append(metrics)&#10;            elif sick == 0.0:&#10;                metrics_by_sick['Healthy'].append(metrics)&#10;&#10;        # prepare output directories&#10;        output_dir = Path(self.output_dir)&#10;        output_dir.mkdir(parents=True, exist_ok=True)&#10;        run_name = os.path.basename(predictions_dir)&#10;        all_csv = output_dir / f&quot;{run_name}_all.csv&quot;&#10;        mean_csv = output_dir / f&quot;{run_name}_mean.csv&quot;&#10;&#10;        # write all per-file metrics&#10;        with open(all_csv, 'w', newline='') as csvfile:&#10;            writer = csv.writer(csvfile)&#10;            header = [&#10;                'Dataset', 'File Name', 'Sick',&#10;                'TP', 'FP', 'FN',&#10;                'Dice', 'Precision', 'Recall',&#10;                'N GT Segments', 'N Pred Segments',&#10;                'N GT Segments Left', 'N Pred Segments Left',&#10;                'N GT Segments Right', 'N of Pred Segments Right',&#10;                'N Segments Success',&#10;                'Center GT Left', 'Center Pred Left',&#10;                'Center GT Right', 'Center Pred Right',&#10;                'Center Pred Success',&#10;                'Center Diers Left', 'Center Diers Right',&#10;                'Center Diers Success',&#10;                'Center Angle Error', 'Center Angle Error Abs',&#10;                'Center Angle Success',&#10;                'Center Angle Diers Error', 'Center Angle Diers Error Abs',&#10;                'Center Angle Diers Success'&#10;            ]&#10;            writer.writerow(header)&#10;            writer.writerows(rows)&#10;        print(f&quot;Validation results saved to {all_csv}&quot;)&#10;&#10;        # Read duration metrics&#10;        from pathlib import Path  # ensure Path is imported&#10;        _duration_file = Path(predictions_dir) / 'duration.txt'&#10;        if _duration_file.exists():&#10;            with open(_duration_file, 'r') as _df:&#10;                _lines = _df.readlines()&#10;            if len(_lines) &gt;= 2:&#10;                total_duration = _lines[0].split(':',1)[1].strip()&#10;                avg_image_duration = _lines[1].split(':',1)[1].strip()&#10;            else:&#10;                total_duration = ''&#10;                avg_image_duration = ''&#10;        else:&#10;            total_duration = ''&#10;            avg_image_duration = ''&#10;&#10;        # Write mean metrics grouped by dataset, by sick status and overall&#10;        with open(mean_csv, 'w', newline='') as csvfile:&#10;            writer = csv.writer(csvfile)&#10;            header_mean = [&#10;                'Dataset',&#10;                'TP', 'FP', 'FN',&#10;                'Dice', 'Precision', 'Recall',&#10;                'N GT Segments', 'N Pred Segments',&#10;                'N GT Segments Left', 'N Pred Segments Left',&#10;                'N GT Segments Right', 'N of Pred Segments Right',&#10;                'N Segments Success',&#10;                'Center GT Left', 'Center Pred Left',&#10;                'Center GT Right', 'Center Pred Right',&#10;                'Center Pred Success',&#10;                'Center Diers Left', 'Center Diers Right',&#10;                'Center Diers Success',&#10;                'Center Angle Error', 'Center Angle Error Abs',&#10;                'Center Angle Success',&#10;                'Center Angle Diers Error', 'Center Angle Diers Error Abs',&#10;                'Center Angle Diers Success',&#10;                'Total duration', 'Average duration per image'&#10;            ]&#10;            writer.writerow(header_mean)&#10;            # per-dataset means&#10;            for dataset, mlist in metrics_by_set.items():&#10;                writer.writerow([&#10;                    dataset,&#10;                    _safe_nanmean([m.tp for m in mlist]),&#10;                    _safe_nanmean([m.fp for m in mlist]),&#10;                    _safe_nanmean([m.fn for m in mlist]),&#10;                    _safe_nanmean([m.dice for m in mlist]),&#10;                    _safe_nanmean([m.precision for m in mlist]),&#10;                    _safe_nanmean([m.recall for m in mlist]),&#10;                    _safe_nanmean([m.n_gt_segments for m in mlist]),&#10;                    _safe_nanmean([m.n_pred_segments for m in mlist]),&#10;                    _safe_nanmean([m.n_gt_segments_left for m in mlist]),&#10;                    _safe_nanmean([m.n_pred_segments_left for m in mlist]),&#10;                    _safe_nanmean([m.n_gt_segments_right for m in mlist]),&#10;                    _safe_nanmean([m.n_pred_segments_right for m in mlist]),&#10;                    _safe_nanmean([m.n_segments_success for m in mlist if m.n_segments_success is not None]),&#10;                    (&#10;                        _safe_nanmean([m.center_gt_left[0] for m in mlist if m.center_gt_left is not None]),&#10;                        _safe_nanmean([m.center_gt_left[1] for m in mlist if m.center_gt_left is not None])&#10;                    ),&#10;                    (&#10;                        _safe_nanmean([m.center_pred_left[0] for m in mlist if m.center_pred_left is not None]),&#10;                        _safe_nanmean([m.center_pred_left[1] for m in mlist if m.center_pred_left is not None])&#10;                    ),&#10;                    (&#10;                        _safe_nanmean([m.center_gt_right[0] for m in mlist if m.center_gt_right is not None]),&#10;                        _safe_nanmean([m.center_gt_right[1] for m in mlist if m.center_gt_right is not None])&#10;                    ),&#10;                    (&#10;                        _safe_nanmean([m.center_pred_right[0] for m in mlist if m.center_pred_right is not None]),&#10;                        _safe_nanmean([m.center_pred_right[1] for m in mlist if m.center_pred_right is not None])&#10;                    ),&#10;                    _safe_nanmean([m.center_pred_success for m in mlist if m.center_pred_success is not None]),&#10;                    (&#10;                        _safe_nanmean([m.center_diers_left[0] for m in mlist if m.center_diers_left is not None]),&#10;                        _safe_nanmean([m.center_diers_left[1] for m in mlist if m.center_diers_left is not None])&#10;                    ),&#10;                    (&#10;                        _safe_nanmean([m.center_diers_right[0] for m in mlist if m.center_diers_right is not None]),&#10;                        _safe_nanmean([m.center_diers_right[1] for m in mlist if m.center_diers_right is not None])&#10;                    ),&#10;                    _safe_nanmean([m.center_diers_success for m in mlist if m.center_diers_success is not None]),&#10;                    _safe_nanmean([m.center_angle_error for m in mlist if m.center_angle_error is not None]),&#10;                    _safe_nanmean([m.center_angle_error_abs for m in mlist if m.center_angle_error_abs is not None]),&#10;                    _safe_nanmean([m.center_angle_success for m in mlist if m.center_angle_success is not None]),&#10;                    _safe_nanmean([m.center_angle_diers_error for m in mlist if m.center_angle_diers_error is not None]),&#10;                    _safe_nanmean([m.center_angle_diers_error_abs for m in mlist if m.center_angle_diers_error_abs is not None]),&#10;                    _safe_nanmean([m.center_angle_diers_success for m in mlist if m.center_angle_diers_success is not None]),&#10;                    '', ''&#10;                ])&#10;            # Sick and Healthy means&#10;            for status, mlist in [('Sick', metrics_by_sick['Sick']), ('Healthy', metrics_by_sick['Healthy'])]:&#10;                writer.writerow([&#10;                    status,&#10;                    _safe_nanmean([m.tp for m in mlist]),&#10;                    _safe_nanmean([m.fp for m in mlist]),&#10;                    _safe_nanmean([m.fn for m in mlist]),&#10;                    _safe_nanmean([m.dice for m in mlist]),&#10;                    _safe_nanmean([m.precision for m in mlist]),&#10;                    _safe_nanmean([m.recall for m in mlist]),&#10;                    _safe_nanmean([m.n_gt_segments for m in mlist]),&#10;                    _safe_nanmean([m.n_pred_segments for m in mlist]),&#10;                    _safe_nanmean([m.n_gt_segments_left for m in mlist]),&#10;                    _safe_nanmean([m.n_pred_segments_left for m in mlist]),&#10;                    _safe_nanmean([m.n_gt_segments_right for m in mlist]),&#10;                    _safe_nanmean([m.n_pred_segments_right for m in mlist]),&#10;                    _safe_nanmean([m.n_segments_success for m in mlist if m.n_segments_success is not None]),&#10;                    (&#10;                        _safe_nanmean([m.center_gt_left[0] for m in mlist if m.center_gt_left is not None]),&#10;                        _safe_nanmean([m.center_gt_left[1] for m in mlist if m.center_gt_left is not None])&#10;                    ),&#10;                    (&#10;                        _safe_nanmean([m.center_pred_left[0] for m in mlist if m.center_pred_left is not None]),&#10;                        _safe_nanmean([m.center_pred_left[1] for m in mlist if m.center_pred_left is not None])&#10;                    ),&#10;                    (&#10;                        _safe_nanmean([m.center_gt_right[0] for m in mlist if m.center_gt_right is not None]),&#10;                        _safe_nanmean([m.center_gt_right[1] for m in mlist if m.center_gt_right is not None])&#10;                    ),&#10;                    (&#10;                        _safe_nanmean([m.center_pred_right[0] for m in mlist if m.center_pred_right is not None]),&#10;                        _safe_nanmean([m.center_pred_right[1] for m in mlist if m.center_pred_right is not None])&#10;                    ),&#10;                    _safe_nanmean([m.center_pred_success for m in mlist if m.center_pred_success is not None]),&#10;                    (&#10;                        _safe_nanmean([m.center_diers_left[0] for m in mlist if m.center_diers_left is not None]),&#10;                        _safe_nanmean([m.center_diers_left[1] for m in mlist if m.center_diers_left is not None])&#10;                    ),&#10;                    (&#10;                        _safe_nanmean([m.center_diers_right[0] for m in mlist if m.center_diers_right is not None]),&#10;                        _safe_nanmean([m.center_diers_right[1] for m in mlist if m.center_diers_right is not None])&#10;                    ),&#10;                    _safe_nanmean([m.center_diers_success for m in mlist if m.center_diers_success is not None]),&#10;                    _safe_nanmean([m.center_angle_error for m in mlist if m.center_angle_error is not None]),&#10;                    _safe_nanmean([m.center_angle_error_abs for m in mlist if m.center_angle_error_abs is not None]),&#10;                    _safe_nanmean([m.center_angle_success for m in mlist if m.center_angle_success is not None]),&#10;                    _safe_nanmean([m.center_angle_diers_error for m in mlist if m.center_angle_diers_error is not None]),&#10;                    _safe_nanmean([m.center_angle_diers_error_abs for m in mlist if m.center_angle_diers_error_abs is not None]),&#10;                    _safe_nanmean([m.center_angle_diers_success for m in mlist if m.center_angle_diers_success is not None]),&#10;                    '', ''&#10;                ])&#10;            # overall mean&#10;            all_metrics = [m for lst in metrics_by_set.values() for m in lst]&#10;            writer.writerow([&#10;                'All Datasets',&#10;                _safe_nanmean([m.tp for m in all_metrics]),&#10;                _safe_nanmean([m.fp for m in all_metrics]),&#10;                _safe_nanmean([m.fn for m in all_metrics]),&#10;                _safe_nanmean([m.dice for m in all_metrics]),&#10;                _safe_nanmean([m.precision for m in all_metrics]),&#10;                _safe_nanmean([m.recall for m in all_metrics]),&#10;                _safe_nanmean([m.n_gt_segments for m in all_metrics]),&#10;                _safe_nanmean([m.n_pred_segments for m in all_metrics]),&#10;                _safe_nanmean([m.n_gt_segments_left for m in all_metrics]),&#10;                _safe_nanmean([m.n_pred_segments_left for m in all_metrics]),&#10;                _safe_nanmean([m.n_gt_segments_right for m in all_metrics]),&#10;                _safe_nanmean([m.n_pred_segments_right for m in all_metrics]),&#10;                _safe_nanmean([m.n_segments_success for m in all_metrics if m.n_segments_success is not None]),&#10;                (&#10;                    _safe_nanmean([m.center_gt_left[0] for m in all_metrics if m.center_gt_left is not None]),&#10;                    _safe_nanmean([m.center_gt_left[1] for m in all_metrics if m.center_gt_left is not None])&#10;                ),&#10;                (&#10;                    _safe_nanmean([m.center_pred_left[0] for m in all_metrics if m.center_pred_left is not None]),&#10;                    _safe_nanmean([m.center_pred_left[1] for m in all_metrics if m.center_pred_left is not None])&#10;                ),&#10;                (&#10;                    _safe_nanmean([m.center_gt_right[0] for m in all_metrics if m.center_gt_right is not None]),&#10;                    _safe_nanmean([m.center_gt_right[1] for m in all_metrics if m.center_gt_right is not None])&#10;                ),&#10;                (&#10;                    _safe_nanmean([m.center_pred_right[0] for m in all_metrics if m.center_pred_right is not None]),&#10;                    _safe_nanmean([m.center_pred_right[1] for m in all_metrics if m.center_pred_right is not None])&#10;                ),&#10;                _safe_nanmean([m.center_pred_success for m in all_metrics if m.center_pred_success is not None]),&#10;                (&#10;                    _safe_nanmean([m.center_diers_left[0] for m in all_metrics if m.center_diers_left is not None]),&#10;                    _safe_nanmean([m.center_diers_left[1] for m in all_metrics if m.center_diers_left is not None])&#10;                ),&#10;                (&#10;                    _safe_nanmean([m.center_diers_right[0] for m in all_metrics if m.center_diers_right is not None]),&#10;                    _safe_nanmean([m.center_diers_right[1] for m in all_metrics if m.center_diers_right is not None])&#10;                ),&#10;                _safe_nanmean([m.center_diers_success for m in all_metrics if m.center_diers_success is not None]),&#10;                _safe_nanmean([m.center_angle_error for m in all_metrics if m.center_angle_error is not None]),&#10;                _safe_nanmean([m.center_angle_error_abs for m in all_metrics if m.center_angle_error_abs is not None]),&#10;                _safe_nanmean([m.center_angle_success for m in all_metrics if m.center_angle_success is not None]),&#10;                _safe_nanmean([m.center_angle_diers_error for m in all_metrics if m.center_angle_diers_error is not None]),&#10;                _safe_nanmean([m.center_angle_diers_error_abs for m in all_metrics if m.center_angle_diers_error_abs is not None]),&#10;                _safe_nanmean([m.center_angle_diers_success for m in all_metrics if m.center_angle_diers_success is not None]),&#10;                total_duration, avg_image_duration&#10;            ])&#10;        print(f&quot;Mean validation results saved to {mean_csv}&quot;)&#10;&#10;    @staticmethod&#10;    def parse_dataset(file_name):&#10;        prefix = file_name.split('_')[0]&#10;        return prefix&#10;&#10;&#10;    @staticmethod&#10;    def load_masks(segmentations_dir):&#10;        segmentations = {}&#10;        for file in os.listdir(segmentations_dir):&#10;            if file.endswith(&quot;.png&quot;) and &quot;-mask&quot; in file:&#10;                segmentations[file] = io.imread(os.path.join(segmentations_dir, file))&#10;        return segmentations&#10;&#10;    def compute_metrics(self, file_name, gt, pred):&#10;        # Binary masks&#10;        gt_mask = gt &gt; 0&#10;        pred_mask = pred &gt; 0&#10;&#10;        # Load markers&#10;        vp, dm, dl_diers, dr_diers = self.load_markers(file_name)&#10;&#10;        # Calc pixel ratio in mm&#10;        pat_idx = self.parse_patient_index_from_image_path(file_name)&#10;        pixel_size = self.compute_distance_per_pixel(pat_idx, vp, dm)&#10;&#10;        # Initialize object to hold metrics&#10;        metrics = EvaluationMetrics()&#10;&#10;        # True Positives, False Positives, False Negatives&#10;        metrics.tp = np.logical_and(gt_mask, pred_mask).sum()&#10;        metrics.fp = np.logical_and(~gt_mask, pred_mask).sum()&#10;        metrics.fn = np.logical_and(gt_mask, ~pred_mask).sum()&#10;&#10;        # Dice Coefficient&#10;        metrics.dice = self.compute_dice(gt_mask, pred_mask, metrics)&#10;&#10;        # Precision&#10;        metrics.precision = self.compute_precision(metrics)&#10;&#10;        # Recall&#10;        metrics.recall = self.compute_recall(metrics)&#10;&#10;        # Total number of segments&#10;        metrics.n_gt_segments = int(label(gt_mask).max())&#10;        metrics.n_pred_segments = int(label(pred_mask).max())&#10;        metrics.n_gt_segments_left = self.compute_n_segments(gt_mask, vp, dm, side='left')&#10;        metrics.n_pred_segments_left = self.compute_n_segments(pred_mask, vp, dm, side='left')&#10;        metrics.n_gt_segments_right = self.compute_n_segments(gt_mask, vp, dm, side='right')&#10;        metrics.n_pred_segments_right = self.compute_n_segments(pred_mask, vp, dm, side='right')&#10;        metrics.n_segments_success = self.compute_n_segments_success(gt_mask, pred_mask)&#10;&#10;        # Center of left and right dimples&#10;        metrics.center_gt_left = self.compute_center(gt_mask, vp, dm, side='left')&#10;        metrics.center_pred_left = self.compute_center(pred_mask, vp, dm, side='left')&#10;        metrics.center_gt_right = self.compute_center(gt_mask, vp, dm, side='right')&#10;        metrics.center_pred_right = self.compute_center(pred_mask, vp, dm, side='right')&#10;        metrics.center_pred_success = self.compute_center_pred_success(metrics, pixel_size)&#10;&#10;        # Compute center distance to diers captured data (!not necessarily equal to gt if gt is annotated differently!)&#10;        metrics.center_diers_left = dl_diers&#10;        metrics.center_diers_right = dr_diers&#10;        metrics.center_diers_success = self.compute_center_pred_success(metrics, pixel_size, compare_to_diers=True)&#10;&#10;        # Angle error between center lines&#10;        metrics.center_angle_error = self.compute_center_angle_error(metrics, absolute=False)&#10;        metrics.center_angle_error_abs = self.compute_center_angle_error(metrics, absolute=True)&#10;        metrics.center_angle_success = self.compute_center_angle_success(metrics)&#10;&#10;        # Angle error between center lines to diers captured data (!not necessarily equal to gt if gt is annotated differently!)&#10;        metrics.center_angle_diers_error = self.compute_center_angle_error(metrics, absolute=False, compare_to_diers=True)&#10;        metrics.center_angle_diers_error_abs = self.compute_center_angle_error(metrics, absolute=True, compare_to_diers=True)&#10;        metrics.center_angle_diers_success = self.compute_center_angle_success(metrics, compare_to_diers=True)&#10;&#10;        # # display original mask with splitting line overlay in pink&#10;        # # load original images (same name without '-mask')&#10;        # from pathlib import Path&#10;        # base_name = file_name.replace('-mask', '')&#10;        # orig_gt_path = Path(self.ground_truth_dir) / base_name&#10;        # orig_pred_path = Path(self.current_predictions_dir) / base_name&#10;        # try:&#10;        #     orig_gt_img = io.imread(orig_gt_path)&#10;        #     self.visualize_middle_line(orig_gt_img, vp, dm, f&quot;{file_name} Ground Truth Split on Original&quot;)&#10;        # except Exception:&#10;        #     pass&#10;        # try:&#10;        #     orig_pred_img = io.imread(orig_pred_path)&#10;        #     self.visualize_middle_line(orig_pred_img, vp, dm, f&quot;{file_name} Pred Split on Original&quot;)&#10;        # except Exception:&#10;        #     pass&#10;&#10;        return metrics&#10;&#10;    @staticmethod&#10;    def compute_dice(gt_mask, pred_mask, metrics):&#10;        if gt_mask.sum() + pred_mask.sum() == 0:&#10;            dice = 1.0&#10;        else:&#10;            dice = (2. * metrics.tp) / (gt_mask.sum() + pred_mask.sum())&#10;        return dice&#10;&#10;    @staticmethod&#10;    def compute_precision(metrics):&#10;        if metrics.tp + metrics.fp == 0:&#10;            precision = 1&#10;        else:&#10;            precision = metrics.tp / (metrics.tp + metrics.fp)&#10;        return precision&#10;&#10;    @staticmethod&#10;    def compute_recall(metrics):&#10;        if metrics.tp + metrics.fn == 0:&#10;            recall = 1&#10;        else:&#10;            recall = metrics.tp / (metrics.tp + metrics.fn)&#10;        return recall&#10;&#10;    @staticmethod&#10;    def compute_n_segments_success(gt_mask, pred_mask):&#10;        &quot;&quot;&quot;Return 1 if every GT segment has at least one pixel in the prediction; Also 1 if no GT segments.&quot;&quot;&quot;&#10;        # label ground truth components&#10;        labels_gt = label(gt_mask)&#10;        n = labels_gt.max()&#10;        if n == 0:&#10;            return 1&#10;        # check overlap for each segment&#10;        for seg in range(1, n+1):&#10;            if not np.any(pred_mask[labels_gt == seg]):&#10;                return 0&#10;        return 1&#10;&#10;    def load_markers(self, file_name, markers_file=&quot;data/Info_sheets/Markerpositionen.csv&quot;):&#10;        img_number = self.extract_image_number(file_name)&#10;&#10;        with open(markers_file, 'r', newline='') as csvfile:&#10;            reader = csv.DictReader(csvfile, delimiter=';')&#10;            for row in reader:&#10;                if row.get('BildID', '').startswith(str(img_number)):&#10;                    vp = (int(row['X_VP']) / 10, int(row['Y_VP']) / 10)&#10;                    dm = (int(row['X_DM']) / 10, int(row['Y_DM']) / 10)&#10;                    dl_diers = (int(row['X_DL']) / 10, int(row['Y_DL']) / 10)&#10;                    dr_diers = (int(row['X_DR']) / 10, int(row['Y_DR']) / 10)&#10;                    return vp, dm, dl_diers, dr_diers&#10;&#10;        pat_idx = self.parse_patient_index_from_image_path(file_name)&#10;        with open('data/Info_Sheets/All_Data_Renamed_overview.csv', 'r', newline='') as csvfile:&#10;            reader = csv.DictReader(csvfile)&#10;            for row in reader:&#10;                if row.get('PatientsLikeMe') == pat_idx:&#10;                    measure_id = row['DIERS_Mess-ID']&#10;&#10;        with open(markers_file, 'r', newline='') as csvfile:&#10;            reader = csv.DictReader(csvfile)&#10;            for row in reader:&#10;                if row.get('MessID', '') == measure_id:&#10;                    vp = (int(row['X_VP'] / 10), int(row['Y_VP']) / 10)&#10;                    dm = (int(row['X_DM'] / 10), int(row['Y_DM']) / 10)&#10;                    dl_diers = (int(row['X_DL']) / 10, int(row['Y_DL']) / 10)&#10;                    dr_diers = (int(row['X_DR']) / 10, int(row['Y_DR']) / 10)&#10;                    return vp, dm, dl_diers, dr_diers&#10;&#10;        return None, None, None, None&#10;&#10;    @staticmethod&#10;    def compute_n_segments(mask, vp, dm, side):&#10;        &quot;&quot;&quot;Count labeled segments in the left or right half of a binary mask.&quot;&quot;&quot;&#10;        # prepare 2D binary mask&#10;        m = mask.astype(bool)&#10;        if m.ndim == 3:&#10;            m = m[..., 0]&#10;        h, w = m.shape&#10;        # coordinate grid&#10;        x = np.arange(w)[None, :]&#10;        y = np.arange(h)[:, None]&#10;        # split by marker line or center&#10;        if vp is not None and dm is not None:&#10;            x1, y1 = vp&#10;            x2, y2 = dm&#10;            s = (x - x1) * (y2 - y1) - (y - y1) * (x2 - x1)&#10;            half = (s &lt; 0) if side == 'left' else (s &gt;= 0)&#10;        else:&#10;            mid = w // 2&#10;            half = (x &lt; mid) if side == 'left' else (x &gt;= mid)&#10;        region = m &amp; half&#10;        return int(label(region).max())&#10;&#10;    @staticmethod&#10;    def compute_center(mask, vp, dm, side):&#10;        &quot;&quot;&quot;Compute centroid of mask in left or right half region.&quot;&quot;&quot;&#10;        # prepare binary mask&#10;        m = mask.astype(bool)&#10;        if m.ndim == 3:&#10;            m = m[..., 0]&#10;        h, w = m.shape&#10;        # coordinate grid&#10;        x = np.arange(w)[None, :]&#10;        y = np.arange(h)[:, None]&#10;        # define half by marker line or center&#10;        if vp is not None and dm is not None:&#10;            x1, y1 = vp&#10;            x2, y2 = dm&#10;            s = (x - x1) * (y2 - y1) - (y - y1) * (x2 - x1)&#10;            half = (s &lt; 0) if side == 'left' else (s &gt;= 0)&#10;        else:&#10;            mid = w // 2&#10;            half = (x &lt; mid) if side == 'left' else (x &gt;= mid)&#10;        region = m &amp; half&#10;        # find coordinates of pixels in region&#10;        ys, xs = np.where(region)&#10;        if xs.size == 0:&#10;            return None&#10;        # compute centroid&#10;        x_center = float(xs.mean())&#10;        y_center = float(ys.mean())&#10;        return x_center, y_center&#10;&#10;    @staticmethod&#10;    def parse_patient_index_from_image_path(image_path):&#10;        pattern = re.compile(r'^[^_]+_([^_]+(?:_\d+)+)(?=_\d{9,})')&#10;        match = pattern.search(os.path.basename(image_path))&#10;        if match:&#10;            return match.group(1)&#10;        return None&#10;&#10;    @staticmethod&#10;    def extract_image_number(file_name):&#10;        match = re.search(r'_(\d+)-mask\.Gauss\.png$', file_name)&#10;        if match:&#10;            return match.group(1)&#10;        return None&#10;&#10;    @staticmethod&#10;    def visualize_mask(image: np.ndarray, title: str):&#10;        &quot;&quot;&quot;Display the original mask image without any splitting lines or axes.&quot;&quot;&quot;&#10;        fig, ax = plt.subplots()&#10;        # display mask or full-color image&#10;        if image.ndim == 3 and image.shape[2] &gt;= 3:&#10;            ax.imshow(image, aspect='equal', interpolation='nearest')&#10;        else:&#10;            vis = image[...,0] if image.ndim == 3 else image&#10;            ax.imshow(vis, cmap='gray', aspect='equal', interpolation='nearest')&#10;        ax.axis('off')&#10;        ax.set_title(title)&#10;        plt.show()&#10;&#10;    @staticmethod&#10;    def visualize_middle_line(image: np.ndarray, vp: Optional[Tuple[int, int]], dm: Optional[Tuple[int, int]], title: str):&#10;        &quot;&quot;&quot;Display the mask image with a middle splitting line.&quot;&quot;&quot;&#10;        fig, ax = plt.subplots()&#10;        # if image has 3 or more channels, show in RGB, else grayscale&#10;        if image.ndim == 3 and image.shape[2] &gt;= 3:&#10;            ax.imshow(image, aspect='equal', interpolation='nearest')&#10;        else:&#10;            vis = image[...,0] if image.ndim == 3 else image&#10;            ax.imshow(vis, cmap='gray', aspect='equal', interpolation='nearest')&#10;&#10;        if vp is not None and dm is not None:&#10;            # Draw the splitting line in the middle of the two markers&#10;            xs = [vp[0], dm[0]]&#10;            ys = [vp[1], dm[1]]&#10;            ax.plot(xs, ys, color='magenta', linewidth=2)&#10;&#10;        ax.axis('off')&#10;        ax.set_title(title)&#10;        plt.show()&#10;&#10;    @staticmethod&#10;    def compute_center_angle_error(metrics, absolute=False, compare_to_diers=False):&#10;        &quot;&quot;&quot;Compute signed or absolute angle difference (in degrees) between GT and predicted dimple-center line.&quot;&quot;&quot;&#10;        if compare_to_diers:&#10;            gt_l = metrics.center_diers_left; gt_r = metrics.center_diers_right&#10;            pr_l = metrics.center_pred_left; pr_r = metrics.center_pred_right&#10;        else:&#10;            gt_l = metrics.center_gt_left; gt_r = metrics.center_gt_right&#10;            pr_l = metrics.center_pred_left; pr_r = metrics.center_pred_right&#10;        # ensure all centers are available&#10;        if None in (gt_l, gt_r, pr_l, pr_r):&#10;            return None&#10;        # compute line angles&#10;        dx_gt = gt_r[0] - gt_l[0]; dy_gt = gt_r[1] - gt_l[1]&#10;        dx_pr = pr_r[0] - pr_l[0]; dy_pr = pr_r[1] - pr_l[1]&#10;        angle_gt = np.degrees(np.arctan2(dy_gt, dx_gt))&#10;        angle_pr = np.degrees(np.arctan2(dy_pr, dx_pr))&#10;        # error and normalization to [-180,180]&#10;        err = angle_pr - angle_gt&#10;        err = (err + 180) % 360 - 180&#10;        return abs(err) if absolute else err&#10;&#10;    @staticmethod&#10;    def compute_center_angle_success(metrics, threshold=4.2, compare_to_diers=False):&#10;        &quot;&quot;&quot;Return 1 if absolute angle error is below threshold degrees, else 0.&quot;&quot;&quot;&#10;        if compare_to_diers:&#10;            err = metrics.center_angle_diers_error_abs&#10;        else:&#10;            err = metrics.center_angle_error_abs&#10;        if err is None:&#10;            return None&#10;        return int(err &lt; threshold)&#10;&#10;    @staticmethod&#10;    def compute_center_pred_success(metrics, pixel_size, threshold=3.0, compare_to_diers=False):&#10;        &quot;&quot;&quot;Return 1 if both left and right center predictions are correct (both None or within threshold [mm] of GT).&quot;&quot;&quot;&#10;        if pixel_size is not None:&#10;            threshold = threshold / pixel_size&#10;        if compare_to_diers:&#10;            gl, pl = metrics.center_diers_left, metrics.center_pred_left&#10;            gr, pr = metrics.center_diers_right, metrics.center_pred_right&#10;        else:&#10;            gl, pl = metrics.center_gt_left, metrics.center_pred_left&#10;            gr, pr = metrics.center_gt_right, metrics.center_pred_right&#10;        def ok(gt, pr):&#10;            if gt is None and pr is None:&#10;                return True&#10;            if gt is not None and pr is not None:&#10;                # distance within threshold pixels&#10;                return np.hypot(gt[0] - pr[0], gt[1] - pr[1]) &lt;= threshold&#10;            return False&#10;        return int(ok(gl, pl) and ok(gr, pr))&#10;&#10;    def compute_distance_per_pixel(self, patient_idx, vp, dm):&#10;        &quot;&quot;&quot;&#10;        Compute millimeters per pixel using known physical distance between VP and DM markers.&#10;        &quot;&quot;&quot;&#10;        if vp is None or dm is None:&#10;            return None&#10;        # compute pixel distance between markers&#10;        pixel_dist = np.hypot(dm[0] - vp[0], dm[1] - vp[1])&#10;        if pixel_dist == 0:&#10;            return None&#10;        # get physical distance (mm) for this patient&#10;        mm_dist = self.vp_dm_distances.get(patient_idx)&#10;        if mm_dist is None:&#10;            return None&#10;        # mm per pixel&#10;        return mm_dist / pixel_dist&#10;&#10;    @staticmethod&#10;    def load_patient_sick_map(file_path=&quot;data/Info_Sheets/All_Data_Renamed_overview.csv&quot;):&#10;        &quot;&quot;&quot;Load the mapping from Patientenindex to Krank value.&quot;&quot;&quot;&#10;        sick_map = {}&#10;        with open(file_path, 'r', newline='') as csvfile:&#10;            reader = csv.DictReader(csvfile)&#10;            for row in reader:&#10;                pat_idx = row.get('Patientenindex')&#10;                sick = row.get('Krank')&#10;                if pat_idx and sick:&#10;                    sick_map[pat_idx] = float(sick)&#10;        return sick_map&#10;&#10;    @staticmethod&#10;    def load_vp_dm_distances(file_path=&quot;data/Info_Sheets/All_Data_Renamed_overview.csv&quot;):&#10;        vp_dm_distance_map = {}&#10;        with open(file_path, 'r', newline='') as csvfile:&#10;            reader = csv.DictReader(csvfile)&#10;            for row in reader:&#10;                pat_idx = row.get('Patientenindex')&#10;                dist_str = row.get('Rumpflänge')&#10;                if pat_idx and dist_str:&#10;                    try:&#10;                        dist_mm = float(dist_str)&#10;                        vp_dm_distance_map[pat_idx] = dist_mm&#10;                    except ValueError:&#10;                        continue&#10;        return vp_dm_distance_map&#10;&#10;&#10;def _safe_nanmean(arr):&#10;    if len(arr) == 0:&#10;        return None&#10;    mean_val = np.nanmean(arr)&#10;    return float(mean_val)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/visualization/bar_plotter.csv.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/visualization/bar_plotter.csv.py" />
              <option name="originalContent" value="import os&#10;&#10;from matplotlib import pyplot as plt&#10;&#10;from visualization.plotter import Plotter&#10;&#10;&#10;class BarPlotter(Plotter):&#10;    def __init__(self, columns):&#10;        self.columns = columns&#10;&#10;    def plot(self, dfs, exp_names, output_dir):&#10;        for col in self.columns:&#10;            values = []&#10;            for df in dfs:&#10;                if col in df.columns:&#10;                    # Use explicit value from the 'All Datasets' row instead of column mean&#10;                    if 'All Datasets' in df.index:&#10;                        values.append(df.loc['All Datasets', col])&#10;                    else:&#10;                        raise ValueError(f&quot;Row 'All Datasets' not found in DataFrame for experiment.&quot;)&#10;                else:&#10;                    raise ValueError(f&quot;Column '{col}' not found in DataFrame for experiment.&quot;)&#10;            plt.figure()&#10;            plt.bar(exp_names, values)&#10;            plt.title(f&quot;{col} across experiments&quot;)&#10;            plt.ylabel(col)&#10;            plt.xticks(rotation=45, ha='right')&#10;            plt.tight_layout()&#10;            out_path = os.path.join(output_dir, f&quot;{col}_bar_chart.png&quot;)&#10;            plt.savefig(out_path)&#10;            plt.close()&#10;            print(f&quot;Saved bar chart for '{col}' to {out_path}&quot;)" />
              <option name="updatedContent" value="import os&#10;&#10;from matplotlib import pyplot as plt&#10;&#10;from visualization.plotter import Plotter&#10;&#10;&#10;class BarPlotter(Plotter):&#10;    def __init__(self, columns):&#10;        self.columns = columns&#10;&#10;    def plot(self, dfs, exp_names, output_dir):&#10;        for col in self.columns:&#10;            values = []&#10;            for df in dfs:&#10;                if col in df.columns:&#10;                    # Use explicit value from the 'All Datasets' row instead of column mean&#10;                    if 'All Datasets' in df.index:&#10;                        values.append(df.loc['All Datasets', col])&#10;                    else:&#10;                        raise ValueError(f&quot;Row 'All Datasets' not found in DataFrame for experiment.&quot;)&#10;                else:&#10;                    raise ValueError(f&quot;Column '{col}' not found in DataFrame for experiment.&quot;)&#10;            plt.figure()&#10;            plt.bar(exp_names, values)&#10;            plt.title(f&quot;{col} across experiments&quot;)&#10;            plt.ylabel(col)&#10;            plt.xticks(rotation=45, ha='right')&#10;            plt.tight_layout()&#10;            out_path = os.path.join(output_dir, f&quot;{col}_bar_chart.png&quot;)&#10;            plt.savefig(out_path)&#10;            plt.close()&#10;            print(f&quot;Saved bar chart for '{col}' to {out_path}&quot;)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/visualization/bar_plotter.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/visualization/bar_plotter.py" />
              <option name="originalContent" value="import os&#10;from matplotlib import pyplot as plt&#10;from matplotlib.ticker import FuncFormatter&#10;&#10;from visualization.plotter import Plotter&#10;&#10;&#10;class BarPlotter(Plotter):&#10;    def __init__(self, columns, directory='bar_charts'):&#10;        self.columns = columns&#10;        self.directory = directory&#10;&#10;    def plot(self, dfs, exp_names, output_dir):&#10;        for col in self.columns:&#10;            is_duration = 'duration' in col.lower()&#10;            if is_duration:&#10;                # helper to convert h:mm:ss.ms to seconds&#10;                def parse_time(ts: str) -&gt; float:&#10;                    parts = ts.split(':')&#10;                    h = int(parts[0]); m = int(parts[1])&#10;                    if '.' in parts[2]:&#10;                        s_str, ms_str = parts[2].split('.')&#10;                        s = int(s_str); ms = int(ms_str)&#10;                    else:&#10;                        s = int(parts[2]); ms = 0&#10;                    return h*3600 + m*60 + s + ms/1000&#10;                # formatter to display seconds back to h:mm:ss.ms&#10;                def format_sec(x, pos):&#10;                    h = int(x) // 3600&#10;                    m = (int(x) % 3600) // 60&#10;                    s = int(x) % 60&#10;                    ms = int((x - int(x)) * 1000)&#10;                    return f&quot;{h:02}:{m:02}:{s:02}.{ms:03}&quot;&#10;            # skip if column missing in any DataFrame&#10;            if any(col not in df.columns for df in dfs):&#10;                print(f&quot;Warning: Column '{col}' not found in one of the DataFrames. Skipping Bar chart for this column.&quot;)&#10;                continue&#10;            values = []&#10;            for df in dfs:&#10;                # col existence already checked&#10;                # Select value from row where 'Dataset' column equals 'All Datasets'&#10;                if 'Dataset' in df.columns and 'All Datasets' in df['Dataset'].values:&#10;                    row = df.loc[df['Dataset'] == 'All Datasets']&#10;                    raw = row.iloc[0][col]&#10;                    if is_duration:&#10;                        val = parse_time(raw)&#10;                    else:&#10;                        val = raw&#10;                    values.append(val)&#10;                else:&#10;                    raise ValueError(&quot;No row with 'Dataset' == 'All Datasets' found in DataFrame.&quot;)&#10;            plt.figure()&#10;            plt.bar(exp_names, values)&#10;            # if plotting duration, format y-axis ticks&#10;            if is_duration:&#10;                ax = plt.gca()&#10;                ax.yaxis.set_major_formatter(FuncFormatter(format_sec))&#10;            plt.title(f&quot;Mean {col} across experiments&quot;)&#10;            plt.ylabel(col)&#10;            plt.xticks(rotation=45, ha='right')&#10;            plt.ylim(bottom=0)&#10;            plt.tight_layout()&#10;            # Create bar_charts directory if it doesn't exist&#10;            dir_path = os.path.join(output_dir, self.directory)&#10;            os.makedirs(dir_path, exist_ok=True)&#10;            # Replace spaces in column name for filename&#10;            safe_col = col.replace(&quot; &quot;, &quot;_&quot;)&#10;            out_path = os.path.join(dir_path, f&quot;{safe_col}_bar_chart.png&quot;)&#10;            plt.savefig(out_path)&#10;            plt.close()&#10;            print(f&quot;Saved bar chart for '{col}' to {out_path}&quot;)" />
              <option name="updatedContent" value="import os&#10;from matplotlib import pyplot as plt&#10;from matplotlib.ticker import FuncFormatter&#10;&#10;from visualization.plotter import Plotter&#10;&#10;&#10;def _parse_time(ts: str) -&gt; float:&#10;    parts = ts.split(':')&#10;    h = int(parts[0]); m = int(parts[1])&#10;    if '.' in parts[2]:&#10;        s_str, ms_str = parts[2].split('.')&#10;        s = int(s_str); ms = int(ms_str)&#10;    else:&#10;        s = int(parts[2]); ms = 0&#10;    return h*3600 + m*60 + s + ms/1000&#10;&#10;def _format_sec(x, pos):&#10;    h = int(x) // 3600&#10;    m = (int(x) % 3600) // 60&#10;    s = int(x) % 60&#10;    ms = int((x - int(x)) * 1000)&#10;    return f&quot;{h:02}:{m:02}:{s:02}.{ms:03}&quot;&#10;&#10;class BarPlotter(Plotter):&#10;    def __init__(self, columns, directory='bar_charts'):&#10;        self.columns = columns&#10;        self.directory = directory&#10;&#10;    def plot(self, dfs, exp_names, output_dir):&#10;        for col in self.columns:&#10;            is_duration = 'duration' in col.lower()&#10;            # skip if column missing in any DataFrame&#10;            if any(col not in df.columns for df in dfs):&#10;                print(f&quot;Warning: Column '{col}' not found in one of the DataFrames. Skipping Bar chart for this column.&quot;)&#10;                continue&#10;            values = []&#10;            for df in dfs:&#10;                # col existence already checked&#10;                # Select value from row where 'Dataset' column equals 'All Datasets'&#10;                if 'Dataset' in df.columns and 'All Datasets' in df['Dataset'].values:&#10;                    row = df.loc[df['Dataset'] == 'All Datasets']&#10;                    raw = row.iloc[0][col]&#10;                    if is_duration:&#10;                        val = _parse_time(raw)&#10;                    else:&#10;                        val = raw&#10;                    values.append(val)&#10;            plt.figure()&#10;            plt.bar(exp_names, values)&#10;            # if plotting duration, format y-axis ticks&#10;            if is_duration:&#10;                ax = plt.gca()&#10;                ax.yaxis.set_major_formatter(FuncFormatter(_format_sec))&#10;            plt.title(f&quot;Mean {col} across experiments&quot;)&#10;            plt.ylabel(col)&#10;            plt.xticks(rotation=45, ha='right')&#10;            plt.ylim(bottom=0)&#10;            plt.tight_layout()&#10;            # Create bar_charts directory if it doesn't exist&#10;            dir_path = os.path.join(output_dir, self.directory)&#10;            os.makedirs(dir_path, exist_ok=True)&#10;            # Replace spaces in column name for filename&#10;            safe_col = col.replace(&quot; &quot;, &quot;_&quot;)&#10;            out_path = os.path.join(dir_path, f&quot;{safe_col}_bar_chart.png&quot;)&#10;            plt.savefig(out_path)&#10;            plt.close()&#10;            print(f&quot;Saved bar chart for '{col}' to {out_path}&quot;)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/visualization/box_plotter.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/visualization/box_plotter.py" />
              <option name="originalContent" value="import os&#10;&#10;from matplotlib import pyplot as plt&#10;&#10;from visualization.plotter import Plotter&#10;&#10;&#10;class BoxPlotter(Plotter):&#10;    def __init__(self, columns, directory='box_plots'):&#10;        self.columns = columns&#10;        self.directory = directory&#10;&#10;    def plot(self, dfs, exp_names, output_dir):&#10;        for col in self.columns:&#10;            # skip if column missing in any DataFrame&#10;            if any(col not in df.columns for df in dfs):&#10;                print(f&quot;Warning: Column '{col}' not found in one of the DataFrames. Skipping box plot for this column.&quot;)&#10;                continue&#10;            data = []&#10;            for df in dfs:&#10;                data.append(df[col].dropna().values)&#10;            plt.figure()&#10;            plt.boxplot(data, labels=exp_names)&#10;            plt.title(f&quot;{col} distribution across experiments&quot;)&#10;            plt.ylabel(col)&#10;            plt.xticks(rotation=45, ha='right')&#10;            plt.tight_layout()&#10;            plt.ylim(bottom=0)&#10;            # ensure output subdirectory exists&#10;            dir_path = os.path.join(output_dir, self.directory)&#10;            os.makedirs(dir_path, exist_ok=True)&#10;            # sanitize column name for filename&#10;            safe_col = col.replace(&quot; &quot;, &quot;_&quot;)&#10;            out_path = os.path.join(dir_path, f&quot;{safe_col}_box_plot.png&quot;)&#10;            plt.savefig(out_path)&#10;            plt.close()&#10;            print(f&quot;Saved box plot for '{col}' to {out_path}&quot;)" />
              <option name="updatedContent" value="import os&#10;&#10;from matplotlib import pyplot as plt&#10;&#10;from visualization.plotter import Plotter&#10;&#10;&#10;class BoxPlotter(Plotter):&#10;    def __init__(self, columns, directory='box_plots'):&#10;        self.columns = columns&#10;        self.directory = directory&#10;&#10;    def plot(self, dfs, exp_names, output_dir):&#10;        for col in self.columns:&#10;            # skip if column missing in any DataFrame&#10;            if any(col not in df.columns for df in dfs):&#10;                print(f&quot;Warning: Column '{col}' not found in one of the DataFrames. Skipping box plot for this column.&quot;)&#10;                continue&#10;            data = []&#10;            for df in dfs:&#10;                data.append(df[col].dropna().values)&#10;            plt.figure()&#10;            plt.boxplot(data, labels=exp_names)&#10;            plt.title(f&quot;{col} distribution across experiments&quot;)&#10;            plt.ylabel(col)&#10;            plt.xticks(rotation=45, ha='right')&#10;            plt.tight_layout()&#10;            plt.ylim(bottom=0)&#10;            # ensure output subdirectory exists&#10;            dir_path = os.path.join(output_dir, self.directory)&#10;            os.makedirs(dir_path, exist_ok=True)&#10;            # sanitize column name for filename&#10;            safe_col = col.replace(&quot; &quot;, &quot;_&quot;)&#10;            out_path = os.path.join(dir_path, f&quot;{safe_col}_box_plot.png&quot;)&#10;            plt.savefig(out_path)&#10;            plt.close()&#10;            print(f&quot;Saved box plot for '{col}' to {out_path}&quot;)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/visualization/heatmap_plotter.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/visualization/heatmap_plotter.py" />
              <option name="originalContent" value="import os&#10;import pandas as pd&#10;&#10;from matplotlib import pyplot as plt&#10;&#10;from visualization.plotter import Plotter&#10;&#10;&#10;class HeatmapPlotter(Plotter):&#10;    def __init__(self, columns, directory='heatmap_plots', cmap='viridis'):&#10;        self.columns = columns&#10;        self.directory = directory&#10;        self.cmap = cmap&#10;&#10;    def plot(self, dfs, exp_names, output_dir):&#10;        import numpy as np&#10;        # Ensure DataFrame column names have no extra whitespace&#10;        for df in dfs:&#10;            df.columns = df.columns.str.strip()&#10;        # Convert all metric columns to numeric, coercing errors to NaN&#10;        for df in dfs:&#10;            for col in self.columns:&#10;                if col in df.columns:&#10;                    df[col] = df[col].apply(pd.to_numeric, errors='coerce')&#10;        # Collect file names and dataset labels from first DataFrame (exclude aggregate 'All Datasets')&#10;        df0 = dfs[0]&#10;        print(&quot;Debug: columns in first DataFrame:&quot;, df0.columns.tolist())&#10;        if 'Dataset' not in df0.columns or 'File Name' not in df0.columns:&#10;            raise ValueError(&quot;Columns 'Dataset' or 'File Name' not found in DataFrame.&quot;)&#10;        # determine valid entries excluding aggregate&#10;        mask = df0['Dataset'] != 'All Datasets'&#10;        # determine unique datasets sorted alphabetically&#10;        unique_datasets = sorted(df0.loc[mask, 'Dataset'].unique())&#10;        # build file list grouped by dataset and health status&#10;        file_names = []&#10;        dataset_labels = []&#10;        status_labels = []&#10;        # convert Sick column to numeric&#10;        df0['Sick'] = pd.to_numeric(df0['Sick'], errors='coerce')&#10;        for d in unique_datasets:&#10;            df_d = df0[mask &amp; (df0['Dataset'] == d)]&#10;            # healthy if Sick is 0 or -1&#10;            healthy = sorted(df_d.loc[df_d['Sick'].isin([0, -1]), 'File Name'].tolist())&#10;            sick = sorted(df_d.loc[~df_d['Sick'].isin([0, -1]), 'File Name'].tolist())&#10;            for fn in healthy:&#10;                file_names.append(fn); dataset_labels.append(d); status_labels.append('Healthy')&#10;            for fn in sick:&#10;                file_names.append(fn); dataset_labels.append(d); status_labels.append('Sick')&#10;        # ensure output directory exists&#10;        dir_path = os.path.join(output_dir, self.directory)&#10;        os.makedirs(dir_path, exist_ok=True)&#10;        # Plot heatmap for each metric&#10;        for col in self.columns:&#10;            # skip if column missing in any DataFrame&#10;            if any(col not in df.columns for df in dfs):&#10;                print(f&quot;Warning: Column '{col}' not found in one of the DataFrames. Skipping heatmap for this column.&quot;)&#10;                continue&#10;            # build matrix: rows=files, cols=experiments&#10;            matrix = []&#10;            for fname in file_names:&#10;                row_vals = []&#10;                for df in dfs:&#10;                    # assume File Name exists (checked earlier); col existence checked above&#10;                    row = df.loc[df['File Name'] == fname]&#10;                    if row.empty:&#10;                        raise ValueError(f&quot;File '{fname}' not found in DataFrame for experiment.&quot;)&#10;                    row_vals.append(row.iloc[0][col])&#10;                matrix.append(row_vals)&#10;            matrix = np.array(matrix)&#10;            # produce heatmap with auto-scaled color range&#10;            safe_col = col.replace(&quot; &quot;, &quot;_&quot;)&#10;            plt.figure()&#10;            # mask missing values and set mask color to black&#10;            m = np.ma.masked_invalid(matrix)&#10;            cmap = plt.get_cmap(self.cmap).copy()&#10;            cmap.set_bad(color='black')&#10;            # auto-scale color to valid data range&#10;            auto_vmin = np.nanmin(matrix)&#10;            auto_vmax = np.nanmax(matrix)&#10;            im = plt.imshow(m, cmap=cmap, aspect='auto', interpolation='nearest', vmin=auto_vmin, vmax=auto_vmax)&#10;            ax = plt.gca()&#10;            # set major ticks for experiment labels&#10;            ax.set_xticks(range(len(exp_names)))&#10;            # draw white vertical separators between experiments&#10;            for i in range(len(exp_names) - 1):&#10;                ax.axvline(i + 0.5, color='w', linewidth=2)&#10;            # compute separators and y-ticks grouping by health&#10;            status_boundaries = []&#10;            dataset_boundaries = []&#10;            positions = []&#10;            labels = []&#10;            for d in unique_datasets:&#10;                # indices for this dataset block&#10;                idxs = [i for i, dl in enumerate(dataset_labels) if dl == d]&#10;                healthy_idxs = [i for i in idxs if status_labels[i] == 'Healthy']&#10;                sick_idxs = [i for i in idxs if status_labels[i] == 'Sick']&#10;                # separator between healthy and sick rows&#10;                if healthy_idxs and sick_idxs:&#10;                    status_boundaries.append(healthy_idxs[-1] + 0.5)&#10;                # separator after entire dataset block&#10;                dataset_boundaries.append(idxs[-1] + 0.5)&#10;                # tick label positions and labels&#10;                if healthy_idxs:&#10;                    positions.append((healthy_idxs[0] + healthy_idxs[-1]) / 2)&#10;                    labels.append(f&quot;{d} Healthy&quot;)&#10;                if sick_idxs:&#10;                    positions.append((sick_idxs[0] + sick_idxs[-1]) / 2)&#10;                    labels.append(f&quot;{d} Sick&quot;)&#10;            # draw horizontal separators: health status and dataset boundaries&#10;            for b in status_boundaries:&#10;                ax.axhline(b, color='w', linewidth=7)&#10;            for b in dataset_boundaries:&#10;                ax.axhline(b, color='w', linewidth=10)&#10;            plt.colorbar(im)&#10;            plt.xticks(range(len(exp_names)), exp_names, rotation=45, ha='right')&#10;            # set y-axis ticks for status subgroups&#10;            plt.yticks(positions, labels)&#10;            plt.title(f&quot;{col} across experiments per file (auto-scaled)&quot;)&#10;            plt.tight_layout()&#10;            out_path = os.path.join(dir_path, f&quot;{safe_col}_heatmap.png&quot;)&#10;            plt.savefig(out_path)&#10;            plt.close()&#10;            print(f&quot;Saved heatmap for '{col}' to {out_path}&quot;)&#10;" />
              <option name="updatedContent" value="import os&#10;import pandas as pd&#10;&#10;from matplotlib import pyplot as plt&#10;&#10;from visualization.plotter import Plotter&#10;&#10;&#10;class HeatmapPlotter(Plotter):&#10;    def __init__(self, columns, directory='heatmap_plots', cmap='viridis'):&#10;        self.columns = columns&#10;        self.directory = directory&#10;        self.cmap = cmap&#10;&#10;    def plot(self, dfs, exp_names, output_dir):&#10;        import numpy as np&#10;        # Ensure DataFrame column names have no extra whitespace&#10;        for df in dfs:&#10;            df.columns = df.columns.str.strip()&#10;        # Convert all metric columns to numeric, coercing errors to NaN&#10;        for df in dfs:&#10;            for col in self.columns:&#10;                if col in df.columns:&#10;                    df[col] = df[col].apply(pd.to_numeric, errors='coerce')&#10;        # Collect file names and dataset labels from first DataFrame (exclude aggregate 'All Datasets')&#10;        df0 = dfs[0]&#10;        print(&quot;Debug: columns in first DataFrame:&quot;, df0.columns.tolist())&#10;        if 'Dataset' not in df0.columns or 'File Name' not in df0.columns:&#10;            raise ValueError(&quot;Columns 'Dataset' or 'File Name' not found in DataFrame.&quot;)&#10;        # determine valid entries excluding aggregate&#10;        mask = df0['Dataset'] != 'All Datasets'&#10;        # determine unique datasets sorted alphabetically&#10;        unique_datasets = sorted(df0.loc[mask, 'Dataset'].unique())&#10;        # build file list grouped by dataset and health status&#10;        file_names = []&#10;        dataset_labels = []&#10;        status_labels = []&#10;        # convert Sick column to numeric&#10;        df0['Sick'] = pd.to_numeric(df0['Sick'], errors='coerce')&#10;        for d in unique_datasets:&#10;            df_d = df0[mask &amp; (df0['Dataset'] == d)]&#10;            # healthy if Sick is 0 or -1&#10;            healthy = sorted(df_d.loc[df_d['Sick'].isin([0, -1]), 'File Name'].tolist())&#10;            sick = sorted(df_d.loc[~df_d['Sick'].isin([0, -1]), 'File Name'].tolist())&#10;            for fn in healthy:&#10;                file_names.append(fn); dataset_labels.append(d); status_labels.append('Healthy')&#10;            for fn in sick:&#10;                file_names.append(fn); dataset_labels.append(d); status_labels.append('Sick')&#10;        # ensure output directory exists&#10;        dir_path = os.path.join(output_dir, self.directory)&#10;        os.makedirs(dir_path, exist_ok=True)&#10;        # Plot heatmap for each metric&#10;        for col in self.columns:&#10;            # skip if column missing in any DataFrame&#10;            if any(col not in df.columns for df in dfs):&#10;                print(f&quot;Warning: Column '{col}' not found in one of the DataFrames. Skipping heatmap for this column.&quot;)&#10;                continue&#10;            # build matrix: rows=files, cols=experiments&#10;            matrix = []&#10;            for fname in file_names:&#10;                row_vals = []&#10;                for df in dfs:&#10;                    # assume File Name exists (checked earlier); col existence checked above&#10;                    row = df.loc[df['File Name'] == fname]&#10;                    if row.empty:&#10;                        raise ValueError(f&quot;File '{fname}' not found in DataFrame for experiment.&quot;)&#10;                    row_vals.append(row.iloc[0][col])&#10;                matrix.append(row_vals)&#10;            matrix = np.array(matrix)&#10;            # produce heatmap with auto-scaled color range&#10;            safe_col = col.replace(&quot; &quot;, &quot;_&quot;)&#10;            plt.figure()&#10;            # mask missing values and set mask color to black&#10;            m = np.ma.masked_invalid(matrix)&#10;            cmap = plt.get_cmap(self.cmap).copy()&#10;            cmap.set_bad(color='black')&#10;            # auto-scale color to valid data range&#10;            auto_vmin = np.nanmin(matrix)&#10;            auto_vmax = np.nanmax(matrix)&#10;            im = plt.imshow(m, cmap=cmap, aspect='auto', interpolation='nearest', vmin=auto_vmin, vmax=auto_vmax)&#10;            ax = plt.gca()&#10;            # set major ticks for experiment labels&#10;            ax.set_xticks(range(len(exp_names)))&#10;            # draw white vertical separators between experiments&#10;            for i in range(len(exp_names) - 1):&#10;                ax.axvline(i + 0.5, color='w', linewidth=2)&#10;            # compute separators and y-ticks grouping by health&#10;            status_boundaries = []&#10;            dataset_boundaries = []&#10;            positions = []&#10;            labels = []&#10;            for d in unique_datasets:&#10;                # indices for this dataset block&#10;                idxs = [i for i, dl in enumerate(dataset_labels) if dl == d]&#10;                healthy_idxs = [i for i in idxs if status_labels[i] == 'Healthy']&#10;                sick_idxs = [i for i in idxs if status_labels[i] == 'Sick']&#10;                # separator between healthy and sick rows&#10;                if healthy_idxs and sick_idxs:&#10;                    status_boundaries.append(healthy_idxs[-1] + 0.5)&#10;                # separator after entire dataset block&#10;                dataset_boundaries.append(idxs[-1] + 0.5)&#10;                # tick label positions and labels&#10;                if healthy_idxs:&#10;                    positions.append((healthy_idxs[0] + healthy_idxs[-1]) / 2)&#10;                    labels.append(f&quot;{d} Healthy&quot;)&#10;                if sick_idxs:&#10;                    positions.append((sick_idxs[0] + sick_idxs[-1]) / 2)&#10;                    labels.append(f&quot;{d} Sick&quot;)&#10;            # draw horizontal separators: health status and dataset boundaries&#10;            for b in status_boundaries:&#10;                ax.axhline(b, color='w', linewidth=7)&#10;            for b in dataset_boundaries:&#10;                ax.axhline(b, color='w', linewidth=10)&#10;            plt.colorbar(im)&#10;            plt.xticks(range(len(exp_names)), exp_names, rotation=45, ha='right')&#10;            # set y-axis ticks for status subgroups&#10;            plt.yticks(positions, labels)&#10;            plt.title(f&quot;{col} across experiments per file (auto-scaled)&quot;)&#10;            plt.tight_layout()&#10;            out_path = os.path.join(dir_path, f&quot;{safe_col}_heatmap.png&quot;)&#10;            plt.savefig(out_path)&#10;            plt.close()&#10;            print(f&quot;Saved heatmap for '{col}' to {out_path}&quot;)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/visualization/line_plotter.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/visualization/line_plotter.py" />
              <option name="originalContent" value="import os&#10;&#10;from matplotlib import pyplot as plt&#10;&#10;from visualization.plotter import Plotter&#10;&#10;&#10;class LinePlotter(Plotter):&#10;    def __init__(self, columns, directory='line_plots'):&#10;        self.columns = columns&#10;        self.directory = directory&#10;&#10;    def plot(self, dfs, exp_names, output_dir):&#10;        for col in self.columns:&#10;            # skip if column missing in any DataFrame&#10;            if any(col not in df.columns for df in dfs):&#10;                print(f&quot;Warning: Column '{col}' not found in one of the DataFrames. Skipping line plot for this column.&quot;)&#10;                continue&#10;            # Define groups of Dataset categories to plot&#10;            groups = {&#10;                'datasets': ['wip', 'mBrace', 'gkge', 'skolioseKielce', 'All Datasets'],&#10;                'health': ['Sick', 'Healthy', 'All Datasets'],&#10;            }&#10;            # ensure output subdirectory exists&#10;            dir_path = os.path.join(output_dir, self.directory)&#10;            os.makedirs(dir_path, exist_ok=True)&#10;            # sanitize column name for filenames&#10;            safe_col = col.replace(&quot; &quot;, &quot;_&quot;)&#10;            # Generate line plot for each group&#10;            for group_name, items in groups.items():&#10;                plt.figure()&#10;                for item in items:&#10;                    series = []&#10;                    for df in dfs:&#10;                        if 'Dataset' not in df.columns or item not in df['Dataset'].values:&#10;                            raise ValueError(f&quot;No row with 'Dataset' == '{item}' found in DataFrame.&quot;)&#10;                        row = df.loc[df['Dataset'] == item]&#10;                        series.append(row.iloc[0][col])&#10;                    plt.plot(exp_names, series, marker='o', label=item)&#10;                plt.title(f&quot;Mean {col} trend across experiments by {group_name}&quot;)&#10;                plt.ylabel(col)&#10;                plt.xticks(rotation=45, ha='right')&#10;                plt.legend()&#10;                plt.ylim(bottom=0)&#10;                plt.tight_layout()&#10;                safe_group = group_name.replace(&quot; &quot;, &quot;_&quot;)&#10;                out_path = os.path.join(dir_path, f&quot;{safe_col}_{safe_group}_line_plot.png&quot;)&#10;                plt.savefig(out_path)&#10;                plt.close()&#10;                print(f&quot;Saved {group_name} line plot for '{col}' to {out_path}&quot;)&#10;" />
              <option name="updatedContent" value="import os&#10;&#10;from matplotlib import pyplot as plt&#10;&#10;from visualization.plotter import Plotter&#10;&#10;&#10;class LinePlotter(Plotter):&#10;    def __init__(self, columns, directory='line_plots'):&#10;        self.columns = columns&#10;        self.directory = directory&#10;&#10;    def plot(self, dfs, exp_names, output_dir):&#10;        for col in self.columns:&#10;            # skip if column missing in any DataFrame&#10;            if any(col not in df.columns for df in dfs):&#10;                print(f&quot;Warning: Column '{col}' not found in one of the DataFrames. Skipping line plot for this column.&quot;)&#10;                continue&#10;            # Define groups of Dataset categories to plot&#10;            groups = {&#10;                'datasets': ['wip', 'mBrace', 'gkge', 'skolioseKielce', 'All Datasets'],&#10;                'health': ['Sick', 'Healthy', 'All Datasets'],&#10;            }&#10;            # ensure output subdirectory exists&#10;            dir_path = os.path.join(output_dir, self.directory)&#10;            os.makedirs(dir_path, exist_ok=True)&#10;            # sanitize column name for filenames&#10;            safe_col = col.replace(&quot; &quot;, &quot;_&quot;)&#10;            # Generate line plot for each group&#10;            for group_name, items in groups.items():&#10;                plt.figure()&#10;                for item in items:&#10;                    series = []&#10;                    for df in dfs:&#10;                        if 'Dataset' not in df.columns or item not in df['Dataset'].values:&#10;                            raise ValueError(f&quot;No row with 'Dataset' == '{item}' found in DataFrame.&quot;)&#10;                        row = df.loc[df['Dataset'] == item]&#10;                        series.append(row.iloc[0][col])&#10;                    plt.plot(exp_names, series, marker='o', label=item)&#10;                plt.title(f&quot;Mean {col} trend across experiments by {group_name}&quot;)&#10;                plt.ylabel(col)&#10;                plt.xticks(rotation=45, ha='right')&#10;                plt.legend()&#10;                plt.ylim(bottom=0)&#10;                plt.tight_layout()&#10;                safe_group = group_name.replace(&quot; &quot;, &quot;_&quot;)&#10;                out_path = os.path.join(dir_path, f&quot;{safe_col}_{safe_group}_line_plot.png&quot;)&#10;                plt.savefig(out_path)&#10;                plt.close()&#10;                print(f&quot;Saved {group_name} line plot for '{col}' to {out_path}&quot;)" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>