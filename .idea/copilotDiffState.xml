<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/SegmentationRunner.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/SegmentationRunner.py" />
              <option name="originalContent" value="from atlas.refiner.color_patch_refiner import ColorPatchRefiner&#10;from atlas.selector.bmi_atlas_selector import BmiAtlasSelector&#10;from atlas.selector.similarity_atlas_selector import SimilarityAtlasSelector&#10;from atlas.voter.majority_voter import MajorityVoter&#10;from atlas.voter.weighted_majority_voter import WeightedMajorityVoter&#10;from preprocessing.blue_color_preprocessor import BlueColorPreprocessor&#10;from preprocessing.color_preprocessor import ColorPreprocessor&#10;from preprocessing.dimples_roi_preprocessor import DimplesRoiPreprocessor&#10;from preprocessing.torso_roi_preprocessor import TorsoRoiPreprocessor&#10;from segmenter.atlas_segmenter import AtlasSegmenter&#10;import time&#10;import os&#10;&#10;&#10;class AtlasSegmentationRunner:&#10;    def __init__(self, num_atlases_to_select, atlas_dir, preprocessing_steps, atlas_selector, segmentation_voter, segmentation_refiner, output_dir, target_images_dir):&#10;        self.segmenter = AtlasSegmenter(&#10;            num_atlases_to_select,&#10;            atlas_dir,&#10;            preprocessing_steps,&#10;            atlas_selector,&#10;            segmentation_voter,&#10;            segmentation_refiner,&#10;            output_dir&#10;        )&#10;        self.target_images_dir = target_images_dir&#10;&#10;    def run(self):&#10;        # start timing&#10;        start_time = time.time()&#10;        target_images = self.segmenter.load_target_images(self.target_images_dir)&#10;        segmented_images = self.segmenter.segment_images(target_images)&#10;        self.segmenter.save_segmentation(segmented_images)&#10;        # end timing and compute durations&#10;        end_time = time.time()&#10;        total_seconds = end_time - start_time&#10;        # format total duration h:m:s&#10;        hrs = int(total_seconds // 3600)&#10;        mins = int((total_seconds % 3600) // 60)&#10;        secs = int(total_seconds % 60)&#10;        duration_str = f&quot;{hrs:02d}:{mins:02d}:{secs:02d}&quot;&#10;        # average per image&#10;        num_images = len(target_images)&#10;        if num_images &gt; 0:&#10;            avg_seconds = total_seconds / num_images&#10;            avg_hrs = int(avg_seconds // 3600)&#10;            avg_mins = int((avg_seconds % 3600) // 60)&#10;            avg_secs = int(avg_seconds % 60)&#10;            avg_str = f&quot;{avg_hrs:02d}:{avg_mins:02d}:{avg_secs:02d}&quot;&#10;        else:&#10;            avg_str = &quot;00:00:00&quot;&#10;        # write durations to file in output_dir&#10;        duration_file = os.path.join(self.segmenter.output_dir, &quot;duration.txt&quot;)&#10;        with open(duration_file, &quot;w&quot;) as f:&#10;            f.write(f&quot;Total duration: {duration_str}\n&quot;)&#10;            f.write(f&quot;Average per image: {avg_str}\n&quot;)&#10;&#10;# Beispiel für die Ausführung:&#10;if __name__ == &quot;__main__&quot;:&#10;    # Hier müssen die passenden Objekte und Parameter übergeben werden&#10;    runner = AtlasSegmentationRunner(&#10;        num_atlases_to_select=13,&#10;        atlas_dir=&quot;data/Atlas_Data_BMI_Percentile&quot;,&#10;        # preprocessing_steps=[DimplesRoiPreprocessor(target_ratio=10/7) ,BlueColorPreprocessor()],  # Liste mit Preprocessing-Objekten&#10;        preprocessing_steps=[],  # Liste mit Preprocessing-Objekten&#10;        atlas_selector=BmiAtlasSelector(&quot;data/Info_Sheets/All_Data_Renamed_overview.csv&quot;, &quot;data/Info_Sheets/bmi_table_who.csv&quot;),      # AtlasSelector-Objekt&#10;        segmentation_voter=WeightedMajorityVoter(scheme=&quot;softmax&quot;, temperature=0.02, threshold=0.5),  # SegmentationVoter-Objekt&#10;        segmentation_refiner=ColorPatchRefiner(BlueColorPreprocessor()),&#10;        output_dir=&quot;data/Atlas_Experiment100&quot;,&#10;        target_images_dir=&quot;data/Validation_Data_Small&quot;&#10;    )&#10;    # runner = AtlasSegmentationRunner(&#10;    #     num_atlases_to_select=3,&#10;    #     atlas_dir=&quot;data/Atlas_Data&quot;,&#10;    #     preprocessing_steps=[],  # Liste mit Preprocessing-Objekten&#10;    #     atlas_selector=SimilarityAtlasSelector(),      # AtlasSelector-Objekt&#10;    #     segmentation_voter=MajorityVoter(),  # SegmentationVoter-Objekt&#10;    #     segmentation_refiner=None,&#10;    #     output_dir=&quot;data/Atlas_Experiment01&quot;,&#10;    #     target_images_dir=&quot;data/Validation_Data_Small&quot;&#10;    # )&#10;    runner.run()" />
              <option name="updatedContent" value="from atlas.refiner.color_patch_refiner import ColorPatchRefiner&#10;from atlas.selector.bmi_atlas_selector import BmiAtlasSelector&#10;from atlas.selector.similarity_atlas_selector import SimilarityAtlasSelector&#10;from atlas.voter.majority_voter import MajorityVoter&#10;from atlas.voter.weighted_majority_voter import WeightedMajorityVoter&#10;from preprocessing.blue_color_preprocessor import BlueColorPreprocessor&#10;from preprocessing.color_preprocessor import ColorPreprocessor&#10;from preprocessing.dimples_roi_preprocessor import DimplesRoiPreprocessor&#10;from preprocessing.torso_roi_preprocessor import TorsoRoiPreprocessor&#10;from segmenter.atlas_segmenter import AtlasSegmenter&#10;import time&#10;import os&#10;&#10;&#10;class AtlasSegmentationRunner:&#10;    def __init__(self, num_atlases_to_select, atlas_dir, preprocessing_steps, atlas_selector, segmentation_voter, segmentation_refiner, output_dir, target_images_dir):&#10;        self.segmenter = AtlasSegmenter(&#10;            num_atlases_to_select,&#10;            atlas_dir,&#10;            preprocessing_steps,&#10;            atlas_selector,&#10;            segmentation_voter,&#10;            segmentation_refiner,&#10;            output_dir&#10;        )&#10;        self.target_images_dir = target_images_dir&#10;&#10;    def run(self):&#10;        # start timing&#10;        start_time = time.time()&#10;        target_images = self.segmenter.load_target_images(self.target_images_dir)&#10;        segmented_images = self.segmenter.segment_images(target_images)&#10;        self.segmenter.save_segmentation(segmented_images)&#10;        # end timing and compute durations&#10;        end_time = time.time()&#10;        total_seconds = end_time - start_time&#10;        # format total duration h:m:s&#10;        hrs = int(total_seconds // 3600)&#10;        mins = int((total_seconds % 3600) // 60)&#10;        secs = int(total_seconds % 60)&#10;        duration_str = f&quot;{hrs:02d}:{mins:02d}:{secs:02d}&quot;&#10;        # average per image&#10;        num_images = len(target_images)&#10;        if num_images &gt; 0:&#10;            avg_seconds = total_seconds / num_images&#10;            avg_hrs = int(avg_seconds // 3600)&#10;            avg_mins = int((avg_seconds % 3600) // 60)&#10;            avg_secs = int(avg_seconds % 60)&#10;            avg_str = f&quot;{avg_hrs:02d}:{avg_mins:02d}:{avg_secs:02d}&quot;&#10;        else:&#10;            avg_str = &quot;00:00:00&quot;&#10;        # write durations to file in output_dir&#10;        duration_file = os.path.join(self.segmenter.output_dir, &quot;duration.txt&quot;)&#10;        with open(duration_file, &quot;w&quot;) as f:&#10;            f.write(f&quot;Total duration: {duration_str}\n&quot;)&#10;            f.write(f&quot;Average per image: {avg_str}\n&quot;)&#10;&#10;# Beispiel für die Ausführung:&#10;if __name__ == &quot;__main__&quot;:&#10;    # Hier müssen die passenden Objekte und Parameter übergeben werden&#10;    runner = AtlasSegmentationRunner(&#10;        num_atlases_to_select=13,&#10;        atlas_dir=&quot;data/Atlas_Data_BMI_Percentile&quot;,&#10;        # preprocessing_steps=[DimplesRoiPreprocessor(target_ratio=10/7) ,BlueColorPreprocessor()],  # Liste mit Preprocessing-Objekten&#10;        preprocessing_steps=[],  # Liste mit Preprocessing-Objekten&#10;        atlas_selector=BmiAtlasSelector(&quot;data/Info_Sheets/All_Data_Renamed_overview.csv&quot;, &quot;data/Info_Sheets/bmi_table_who.csv&quot;),      # AtlasSelector-Objekt&#10;        segmentation_voter=WeightedMajorityVoter(scheme=&quot;softmax&quot;, temperature=0.02, threshold=0.5),  # SegmentationVoter-Objekt&#10;        segmentation_refiner=ColorPatchRefiner(BlueColorPreprocessor()),&#10;        output_dir=&quot;data/Atlas_Experiment100&quot;,&#10;        target_images_dir=&quot;data/Validation_Data_Small&quot;&#10;    )&#10;    # runner = AtlasSegmentationRunner(&#10;    #     num_atlases_to_select=3,&#10;    #     atlas_dir=&quot;data/Atlas_Data&quot;,&#10;    #     preprocessing_steps=[],  # Liste mit Preprocessing-Objekten&#10;    #     atlas_selector=SimilarityAtlasSelector(),      # AtlasSelector-Objekt&#10;    #     segmentation_voter=MajorityVoter(),  # SegmentationVoter-Objekt&#10;    #     segmentation_refiner=None,&#10;    #     output_dir=&quot;data/Atlas_Experiment01&quot;,&#10;    #     target_images_dir=&quot;data/Validation_Data_Small&quot;&#10;    # )&#10;    runner.run()" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/validation/aggregator.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/validation/aggregator.py" />
              <option name="originalContent" value="import numpy as np&#10;from collections import defaultdict&#10;from validation.evaluation_metrics import EvaluationMetrics&#10;&#10;&#10;def _safe_nanmean(arr):&#10;    if len(arr) == 0:&#10;        return None&#10;    return float(np.nanmean(arr))&#10;&#10;&#10;class MetricsAggregator:&#10;    &quot;&quot;&quot;Aggregate EvaluationMetrics into grouped means dynamically based on selected metrics.&quot;&quot;&quot;&#10;    def __init__(self, metric_names):&#10;        self.metric_names = metric_names&#10;        self.metrics_by_set = defaultdict(list)&#10;        self.metrics_by_sick = {'Sick': [], 'Healthy': []}&#10;        self.all_metrics = []&#10;&#10;    def add(self, dataset: str, sick: float, metrics: EvaluationMetrics):&#10;        self.metrics_by_set[dataset].append(metrics)&#10;        if sick == 1.0:&#10;            self.metrics_by_sick['Sick'].append(metrics)&#10;        elif sick == 0.0:&#10;            self.metrics_by_sick['Healthy'].append(metrics)&#10;        self.all_metrics.append(metrics)&#10;&#10;    def compute_means(self):&#10;        &quot;&quot;&quot;Return list of rows for mean CSV: per dataset, Sick, Healthy, All Datasets&quot;&quot;&quot;&#10;        rows = []&#10;        # per-dataset&#10;        for ds, mlist in self.metrics_by_set.items():&#10;            rows.append(self._make_row(ds, mlist))&#10;        # Sick and Healthy&#10;        for status in ['Sick', 'Healthy']:&#10;            rows.append(self._make_row(status, self.metrics_by_sick.get(status, [])))&#10;        # overall&#10;        rows.append(self._make_row('All Datasets', self.all_metrics))&#10;        return rows&#10;&#10;    def _make_row(self, label, mlist):&#10;        # compute mean per selected metric&#10;        row = [label]&#10;        for name in self.metric_names:&#10;            vals = [getattr(m, name) for m in mlist if getattr(m, name) is not None]&#10;            mean = float(np.nanmean(vals)) if vals else None&#10;            row.append(mean)&#10;        return row" />
              <option name="updatedContent" value="import numpy as np&#10;from collections import defaultdict&#10;from validation.evaluation_metrics import EvaluationMetrics&#10;&#10;&#10;def _safe_nanmean(arr):&#10;    if len(arr) == 0:&#10;        return None&#10;    return float(np.nanmean(arr))&#10;&#10;&#10;class MetricsAggregator:&#10;    &quot;&quot;&quot;Aggregate EvaluationMetrics into grouped means dynamically based on selected metrics.&quot;&quot;&quot;&#10;    def __init__(self, metric_names):&#10;        self.metric_names = metric_names&#10;        self.metrics_by_set = defaultdict(list)&#10;        self.metrics_by_sick = {'Sick': [], 'Healthy': []}&#10;        self.all_metrics = []&#10;&#10;    def add(self, dataset: str, sick: float, metrics: EvaluationMetrics):&#10;        self.metrics_by_set[dataset].append(metrics)&#10;        if sick == 1.0:&#10;            self.metrics_by_sick['Sick'].append(metrics)&#10;        elif sick == 0.0:&#10;            self.metrics_by_sick['Healthy'].append(metrics)&#10;        self.all_metrics.append(metrics)&#10;&#10;    def compute_means(self):&#10;        &quot;&quot;&quot;Return list of rows for mean CSV: per dataset, Sick, Healthy, All Datasets&quot;&quot;&quot;&#10;        rows = []&#10;        # per-dataset&#10;        for ds, mlist in self.metrics_by_set.items():&#10;            rows.append(self._make_row(ds, mlist))&#10;        # Sick and Healthy&#10;        for status in ['Sick', 'Healthy']:&#10;            rows.append(self._make_row(status, self.metrics_by_sick.get(status, [])))&#10;        # overall&#10;        rows.append(self._make_row('All Datasets', self.all_metrics))&#10;        return rows&#10;&#10;    def _make_row(self, label, mlist):&#10;        # compute mean per selected metric&#10;        row = [label]&#10;        for name in self.metric_names:&#10;            vals = [getattr(m, name) for m in mlist if getattr(m, name) is not None]&#10;            mean = float(np.nanmean(vals)) if vals else None&#10;            row.append(mean)&#10;        return row" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/validation/validator.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/validation/validator.py" />
              <option name="originalContent" value="import csv&#10;import os&#10;import re&#10;from collections import defaultdict&#10;from pathlib import Path&#10;from typing import Optional, Tuple&#10;&#10;import matplotlib.pyplot as plt&#10;import numpy as np&#10;from skimage import io&#10;from tqdm import tqdm&#10;&#10;&#10;class Validator:&#10;&#10;    def __init__(self, ground_truth_dir, output_dir, metrics):&#10;        &quot;&quot;&quot;&#10;        Initialize Validator.&#10;        Parameters:&#10;            ground_truth_dir (str): Path to ground truth masks.&#10;            output_dir (str): Directory to save CSV results.&#10;            metrics (list[Metric], optional): List of metric instances to compute. If None, auto-discover.&#10;        &quot;&quot;&quot;&#10;        self.ground_truth_dir = ground_truth_dir&#10;        self.ground_truths = self.load_masks(ground_truth_dir)&#10;        self.output_dir = output_dir&#10;        self.vp_dm_distances = self.load_vp_dm_distances()&#10;        self.metrics = metrics&#10;        self.health_status_dict = self.load_health_status_dict()&#10;&#10;&#10;    def validate(self, predictions_dir):&#10;        # Load ground truth and prediction masks&#10;        ground_truths = self.ground_truths&#10;        predictions = self.load_masks(predictions_dir)&#10;&#10;        # Prepare data structures for computed_metric_results&#10;        metric_scores = []&#10;        metric_scores_by_dataset = defaultdict(list)&#10;        metric_scores_by_health_status = defaultdict(list)&#10;&#10;        # Iterate over all ground truth files and validate predictions&#10;        for file_name in tqdm(ground_truths.keys(), desc=f'Validating predictions for {predictions_dir}'):&#10;            if file_name not in predictions.keys():&#10;                print(f&quot;Ground truth {file_name} does not have a corresponding prediction.&quot;)&#10;                continue&#10;&#10;            # Load ground truth and prediction masks for the current image&#10;            dataset = self.parse_dataset(file_name)&#10;            gt = ground_truths[file_name] &gt; 0  # binary mask&#10;            pred = predictions[file_name] &gt; 0  # binary mask&#10;&#10;            # Compute TP, FP, FN as base metrics&#10;            computed_metric_results = {&#10;                'TP': np.logical_and(gt, pred).sum(),&#10;                'FP': np.logical_and(~gt, pred).sum(),&#10;                'FN': np.logical_and(gt, ~pred).sum()&#10;            }&#10;&#10;            # Compute image metadata&#10;            image_metadata = self.load_image_metadata(file_name)&#10;&#10;            # Compute metrics sequentially, allowing composite metrics to use previous computed_metric_results&#10;            for m in self.metrics:&#10;                computed_metric_results[m.name] = m.compute(gt, pred, computed_metric_results, image_metadata)&#10;            # Collect metric values (keep infinities for per-image output)&#10;            values = [computed_metric_results[m.name] for m in self.metrics]&#10;&#10;            # Determine health status for the patient from the patient index&#10;            pat_idx = self.parse_patient_index_from_image_path(file_name)&#10;            sick = self.health_status_dict.get(pat_idx)&#10;&#10;            # Add metric scores for this file to the overall list&#10;            metric_scores.append([dataset, file_name, sick] + values)&#10;&#10;            # Add metric scores for this file to the dataset-specific list&#10;            metric_scores_by_dataset[dataset].append(values)&#10;&#10;            # Add metric scores for this file to the health status-specific list&#10;            if sick == 1.0:&#10;                metric_scores_by_health_status['Sick'].append(values)&#10;            elif sick == 0.0:&#10;                metric_scores_by_health_status['Healthy'].append(values)&#10;&#10;        # prepare output directories&#10;        all_csv, mean_csv = self.create_output_files(predictions_dir)&#10;        # write all per-file metric_scores&#10;        self.save_per_image_metrics(all_csv, metric_scores)&#10;        # Read duration metric_scores&#10;        avg_image_duration, total_duration = self.read_segmentation_duration(predictions_dir)&#10;        # Write mean metric_scores grouped by dataset, by sick status and overall&#10;        self.save_mean_metrics(avg_image_duration, mean_csv, metric_scores_by_dataset, metric_scores_by_health_status,&#10;                               total_duration)&#10;&#10;&#10;&#10;&#10;    def load_image_metadata(self, file_name):&#10;        # Load markers&#10;        vp, dm, dl_diers, dr_diers = self.load_markers(file_name)&#10;&#10;        # Calc pixel ratio in mm&#10;        pat_idx = self.parse_patient_index_from_image_path(file_name)&#10;        pixel_size = self.compute_distance_per_pixel(pat_idx, vp, dm)&#10;&#10;        return {&#10;            'vp': vp,&#10;            'dm': dm,&#10;            'dl_diers': dl_diers,&#10;            'dr_diers': dr_diers,&#10;            'pixel_size_mm': pixel_size&#10;        }&#10;&#10;&#10;    def load_markers(self, file_name, markers_file=&quot;data/Info_sheets/Markerpositionen.csv&quot;):&#10;        # Check if markers are available for this image&#10;        img_number = self.extract_image_number(file_name)&#10;        with open(markers_file, 'r', newline='') as csvfile:&#10;            reader = csv.DictReader(csvfile, delimiter=';')&#10;            for row in reader:&#10;                if row.get('BildID', '').startswith(str(img_number)):&#10;                    vp = (int(row['X_VP']) / 10, int(row['Y_VP']) / 10)&#10;                    dm = (int(row['X_DM']) / 10, int(row['Y_DM']) / 10)&#10;                    dl_diers = (int(row['X_DL']) / 10, int(row['Y_DL']) / 10)&#10;                    dr_diers = (int(row['X_DR']) / 10, int(row['Y_DR']) / 10)&#10;                    return vp, dm, dl_diers, dr_diers&#10;&#10;        # Check if markers are available for this patient&#10;        pat_idx = self.parse_patient_index_from_image_path(file_name)&#10;        with open('data/Info_Sheets/All_Data_Renamed_overview.csv', 'r', newline='') as csvfile:&#10;            reader = csv.DictReader(csvfile)&#10;            for row in reader:&#10;                if row.get('Patientenindex') == pat_idx:&#10;                    measure_id = row['DIERS_Mess-ID']&#10;        with open(markers_file, 'r', newline='') as csvfile:&#10;            reader = csv.DictReader(csvfile)&#10;            for row in reader:&#10;                if row.get('MessID', '') == measure_id:&#10;                    vp = (int(row['X_VP'] / 10), int(row['Y_VP']) / 10)&#10;                    dm = (int(row['X_DM'] / 10), int(row['Y_DM']) / 10)&#10;                    dl_diers = (int(row['X_DL']) / 10, int(row['Y_DL']) / 10)&#10;                    dr_diers = (int(row['X_DR']) / 10, int(row['Y_DR']) / 10)&#10;                    return vp, dm, dl_diers, dr_diers&#10;&#10;        # If no markers found, return None&#10;        return None, None, None, None&#10;&#10;&#10;    def save_mean_metrics(self, avg_image_duration, mean_csv, metric_scores_by_dataset, metric_scores_by_health_status,&#10;                          total_duration):&#10;        with open(mean_csv, 'w', newline='') as csvfile:&#10;            writer = csv.writer(csvfile)&#10;            header_mean = ['Dataset'] + [m.name for m in self.metrics] + ['Total duration',&#10;                                                                          'Average duration per image']&#10;            writer.writerow(header_mean)&#10;            # per-dataset means&#10;            for ds, lst in metric_scores_by_dataset.items():&#10;                means = [_safe_nanmean([row[i] for row in lst]) for i in range(len(self.metrics))]&#10;                writer.writerow([ds] + means + ['', ''])&#10;            # by sick status&#10;            for label, lst in metric_scores_by_health_status.items():&#10;                means = [_safe_nanmean([row[i] for row in lst]) for i in range(len(self.metrics))]&#10;                writer.writerow([label] + means + ['', ''])&#10;            # overall&#10;            all_vals = [v for lst in metric_scores_by_dataset.values() for v in lst]&#10;            means = [_safe_nanmean([row[i] for row in all_vals]) for i in range(len(self.metrics))]&#10;            writer.writerow(['All Datasets'] + means + [total_duration, avg_image_duration])&#10;        print(f&quot;Mean validation results saved to {mean_csv}&quot;)&#10;&#10;&#10;    @staticmethod&#10;    def read_segmentation_duration(predictions_dir):&#10;        _duration_file = Path(predictions_dir) / 'duration.txt'&#10;        if _duration_file.exists():&#10;            with open(_duration_file, 'r') as _df:&#10;                _lines = _df.readlines()&#10;            if len(_lines) &gt;= 2:&#10;                total_duration = _lines[0].split(':', 1)[1].strip()&#10;                avg_image_duration = _lines[1].split(':', 1)[1].strip()&#10;            else:&#10;                total_duration = ''&#10;                avg_image_duration = ''&#10;        else:&#10;            total_duration = ''&#10;            avg_image_duration = ''&#10;        return avg_image_duration, total_duration&#10;&#10;&#10;    def save_per_image_metrics(self, all_csv, metric_scores):&#10;        with open(all_csv, 'w', newline='') as csvfile:&#10;            writer = csv.writer(csvfile)&#10;            header = ['Dataset', 'File Name', 'Sick'] + [m.name for m in self.metrics]&#10;            writer.writerow(header)&#10;            writer.writerows(metric_scores)&#10;        print(f&quot;Validation results saved to {all_csv}&quot;)&#10;&#10;&#10;    def create_output_files(self, predictions_dir):&#10;        output_dir = Path(self.output_dir)&#10;        output_dir.mkdir(parents=True, exist_ok=True)&#10;        run_name = os.path.basename(predictions_dir)&#10;        all_csv = output_dir / f&quot;{run_name}_all.csv&quot;&#10;        mean_csv = output_dir / f&quot;{run_name}_mean.csv&quot;&#10;        return all_csv, mean_csv&#10;&#10;&#10;    @staticmethod&#10;    def parse_dataset(file_name):&#10;        prefix = file_name.split('_')[0]&#10;        return prefix&#10;&#10;&#10;    @staticmethod&#10;    def load_masks(segmentations_dir):&#10;        segmentations = {}&#10;        for file in os.listdir(segmentations_dir):&#10;            if file.endswith(&quot;.png&quot;) and &quot;-mask&quot; in file:&#10;                img = io.imread(os.path.join(segmentations_dir, file))&#10;                # Falls RGB, in Graustufen umwandeln&#10;                if img.ndim == 3:&#10;                    img = img[..., 0]  # Nur ersten Kanal nehmen (oder np.mean(img, axis=2) für echten Grauwert)&#10;                segmentations[file] = img&#10;        return segmentations&#10;&#10;&#10;    @staticmethod&#10;    def parse_patient_index_from_image_path(image_path):&#10;        pattern = re.compile(r'^[^_]+_([^_]+(?:_\d+)+)(?=_\d{9,})')&#10;        match = pattern.search(os.path.basename(image_path))&#10;        if match:&#10;            return match.group(1)&#10;        return None&#10;&#10;&#10;    @staticmethod&#10;    def extract_image_number(file_name):&#10;        match = re.search(r'_(\d+)-mask\.Gauss\.png$', file_name)&#10;        if match:&#10;            return match.group(1)&#10;        return None&#10;&#10;&#10;    @staticmethod&#10;    def visualize_mask(image: np.ndarray, title: str):&#10;        &quot;&quot;&quot;Display the original mask image without any splitting lines or axes.&quot;&quot;&quot;&#10;        fig, ax = plt.subplots()&#10;        # display mask or full-color image&#10;        if image.ndim == 3 and image.shape[2] &gt;= 3:&#10;            ax.imshow(image, aspect='equal', interpolation='nearest')&#10;        else:&#10;            vis = image[...,0] if image.ndim == 3 else image&#10;            ax.imshow(vis, cmap='gray', aspect='equal', interpolation='nearest')&#10;        ax.axis('off')&#10;        ax.set_title(title)&#10;        plt.show()&#10;&#10;&#10;    @staticmethod&#10;    def visualize_middle_line(image: np.ndarray, vp: Optional[Tuple[int, int]], dm: Optional[Tuple[int, int]], title: str):&#10;        &quot;&quot;&quot;Display the mask image with a middle splitting line.&quot;&quot;&quot;&#10;        fig, ax = plt.subplots()&#10;        # if image has 3 or more channels, show in RGB, else grayscale&#10;        if image.ndim == 3 and image.shape[2] &gt;= 3:&#10;            ax.imshow(image, aspect='equal', interpolation='nearest')&#10;        else:&#10;            vis = image[...,0] if image.ndim == 3 else image&#10;            ax.imshow(vis, cmap='gray', aspect='equal', interpolation='nearest')&#10;&#10;        if vp is not None and dm is not None:&#10;            # Draw the splitting line in the middle of the two markers&#10;            xs = [vp[0], dm[0]]&#10;            ys = [vp[1], dm[1]]&#10;            ax.plot(xs, ys, color='magenta', linewidth=2)&#10;&#10;        ax.axis('off')&#10;        ax.set_title(title)&#10;        plt.show()&#10;&#10;&#10;    def compute_distance_per_pixel(self, patient_idx, vp, dm):&#10;        &quot;&quot;&quot;&#10;        Compute millimeters per pixel using known physical distance between VP and DM markers.&#10;        &quot;&quot;&quot;&#10;        if vp is None or dm is None:&#10;            return None&#10;        pixel_dist = np.hypot(dm[0] - vp[0], dm[1] - vp[1])&#10;        if pixel_dist == 0:&#10;            return None&#10;        mm_dist = self.vp_dm_distances.get(patient_idx)&#10;        if mm_dist is None:&#10;            return None&#10;        return mm_dist / pixel_dist&#10;&#10;&#10;    @staticmethod&#10;    def load_health_status_dict(file_path=&quot;data/Info_Sheets/All_Data_Renamed_overview.csv&quot;):&#10;        &quot;&quot;&quot;Load the mapping from Patientenindex to Krank value.&quot;&quot;&quot;&#10;        health_status_dict = {}&#10;        with open(file_path, 'r', newline='') as csvfile:&#10;            reader = csv.DictReader(csvfile)&#10;            for row in reader:&#10;                pat_idx = row.get('Patientenindex')&#10;                sick = row.get('Krank')&#10;                if pat_idx and sick:&#10;                    health_status_dict[pat_idx] = float(sick)&#10;        return health_status_dict&#10;&#10;&#10;    @staticmethod&#10;    def load_vp_dm_distances(file_path=&quot;data/Info_Sheets/All_Data_Renamed_overview.csv&quot;):&#10;        vp_dm_distance_map = {}&#10;        with open(file_path, 'r', newline='') as csvfile:&#10;            reader = csv.DictReader(csvfile)&#10;            for row in reader:&#10;                pat_idx = row.get('Patientenindex')&#10;                dist_str = row.get('Rumpflänge')&#10;                if pat_idx and dist_str:&#10;                    try:&#10;                        dist_mm = float(dist_str)&#10;                        vp_dm_distance_map[pat_idx] = dist_mm&#10;                    except ValueError:&#10;                        continue&#10;        return vp_dm_distance_map&#10;&#10;&#10;def _safe_nanmean(arr):&#10;    # filter out None, NaN, and infinite values&#10;    clean = [v for v in arr if v is not None and np.isfinite(v)]&#10;    if len(clean) == 0:&#10;        return None&#10;    return float(np.mean(clean))&#10;" />
              <option name="updatedContent" value="import csv&#10;import os&#10;import re&#10;from collections import defaultdict&#10;from pathlib import Path&#10;from typing import Optional, Tuple&#10;&#10;import matplotlib.pyplot as plt&#10;import numpy as np&#10;from skimage import io&#10;from tqdm import tqdm&#10;&#10;&#10;class Validator:&#10;&#10;    def __init__(self, ground_truth_dir, output_dir, metrics):&#10;        &quot;&quot;&quot;&#10;        Initialize Validator.&#10;        Parameters:&#10;            ground_truth_dir (str): Path to ground truth masks.&#10;            output_dir (str): Directory to save CSV results.&#10;            metrics (list[Metric], optional): List of metric instances to compute. If None, auto-discover.&#10;        &quot;&quot;&quot;&#10;        self.ground_truth_dir = ground_truth_dir&#10;        self.ground_truths = self.load_masks(ground_truth_dir)&#10;        self.output_dir = output_dir&#10;        self.vp_dm_distances = self.load_vp_dm_distances()&#10;        self.metrics = metrics&#10;        self.health_status_dict = self.load_health_status_dict()&#10;&#10;&#10;    def validate(self, predictions_dir):&#10;        # Load ground truth and prediction masks&#10;        ground_truths = self.ground_truths&#10;        predictions = self.load_masks(predictions_dir)&#10;&#10;        # Prepare data structures for computed_metric_results&#10;        metric_scores = []&#10;        metric_scores_by_dataset = defaultdict(list)&#10;        metric_scores_by_health_status = defaultdict(list)&#10;&#10;        # Iterate over all ground truth files and validate predictions&#10;        for file_name in tqdm(ground_truths.keys(), desc=f'Validating predictions for {predictions_dir}'):&#10;            if file_name not in predictions.keys():&#10;                print(f&quot;Ground truth {file_name} does not have a corresponding prediction.&quot;)&#10;                continue&#10;&#10;            # Load ground truth and prediction masks for the current image&#10;            dataset = self.parse_dataset(file_name)&#10;            gt = ground_truths[file_name] &gt; 0  # binary mask&#10;            pred = predictions[file_name] &gt; 0  # binary mask&#10;&#10;            # Compute TP, FP, FN as base metrics&#10;            computed_metric_results = {&#10;                'TP': np.logical_and(gt, pred).sum(),&#10;                'FP': np.logical_and(~gt, pred).sum(),&#10;                'FN': np.logical_and(gt, ~pred).sum()&#10;            }&#10;&#10;            # Compute image metadata&#10;            image_metadata = self.load_image_metadata(file_name)&#10;&#10;            # Compute metrics sequentially, allowing composite metrics to use previous computed_metric_results&#10;            for m in self.metrics:&#10;                computed_metric_results[m.name] = m.compute(gt, pred, computed_metric_results, image_metadata)&#10;            # Collect metric values (keep infinities for per-image output)&#10;            values = [computed_metric_results[m.name] for m in self.metrics]&#10;&#10;            # Determine health status for the patient from the patient index&#10;            pat_idx = self.parse_patient_index_from_image_path(file_name)&#10;            sick = self.health_status_dict.get(pat_idx)&#10;&#10;            # Add metric scores for this file to the overall list&#10;            metric_scores.append([dataset, file_name, sick] + values)&#10;&#10;            # Add metric scores for this file to the dataset-specific list&#10;            metric_scores_by_dataset[dataset].append(values)&#10;&#10;            # Add metric scores for this file to the health status-specific list&#10;            if sick == 1.0:&#10;                metric_scores_by_health_status['Sick'].append(values)&#10;            elif sick == 0.0:&#10;                metric_scores_by_health_status['Healthy'].append(values)&#10;&#10;        # prepare output directories&#10;        all_csv, mean_csv = self.create_output_files(predictions_dir)&#10;        # write all per-file metric_scores&#10;        self.save_per_image_metrics(all_csv, metric_scores)&#10;        # Read duration metric_scores&#10;        avg_image_duration, total_duration = self.read_segmentation_duration(predictions_dir)&#10;        # Write mean metric_scores grouped by dataset, by sick status and overall&#10;        self.save_mean_metrics(avg_image_duration, mean_csv, metric_scores_by_dataset, metric_scores_by_health_status,&#10;                               total_duration)&#10;&#10;&#10;&#10;&#10;    def load_image_metadata(self, file_name):&#10;        # Load markers&#10;        vp, dm, dl_diers, dr_diers = self.load_markers(file_name)&#10;&#10;        # Calc pixel ratio in mm&#10;        pat_idx = self.parse_patient_index_from_image_path(file_name)&#10;        pixel_size = self.compute_distance_per_pixel(pat_idx, vp, dm)&#10;&#10;        return {&#10;            'vp': vp,&#10;            'dm': dm,&#10;            'dl_diers': dl_diers,&#10;            'dr_diers': dr_diers,&#10;            'pixel_size_mm': pixel_size&#10;        }&#10;&#10;&#10;    def load_markers(self, file_name, markers_file=&quot;data/Info_sheets/Markerpositionen.csv&quot;):&#10;        # Check if markers are available for this image&#10;        img_number = self.extract_image_number(file_name)&#10;        with open(markers_file, 'r', newline='') as csvfile:&#10;            reader = csv.DictReader(csvfile, delimiter=';')&#10;            for row in reader:&#10;                if row.get('BildID', '').startswith(str(img_number)):&#10;                    vp = (int(row['X_VP']) / 10, int(row['Y_VP']) / 10)&#10;                    dm = (int(row['X_DM']) / 10, int(row['Y_DM']) / 10)&#10;                    dl_diers = (int(row['X_DL']) / 10, int(row['Y_DL']) / 10)&#10;                    dr_diers = (int(row['X_DR']) / 10, int(row['Y_DR']) / 10)&#10;                    return vp, dm, dl_diers, dr_diers&#10;&#10;        # Check if markers are available for this patient&#10;        pat_idx = self.parse_patient_index_from_image_path(file_name)&#10;        with open('data/Info_Sheets/All_Data_Renamed_overview.csv', 'r', newline='') as csvfile:&#10;            reader = csv.DictReader(csvfile)&#10;            for row in reader:&#10;                if row.get('Patientenindex') == pat_idx:&#10;                    measure_id = row['DIERS_Mess-ID']&#10;        with open(markers_file, 'r', newline='') as csvfile:&#10;            reader = csv.DictReader(csvfile)&#10;            for row in reader:&#10;                if row.get('MessID', '') == measure_id:&#10;                    vp = (int(row['X_VP'] / 10), int(row['Y_VP']) / 10)&#10;                    dm = (int(row['X_DM'] / 10), int(row['Y_DM']) / 10)&#10;                    dl_diers = (int(row['X_DL']) / 10, int(row['Y_DL']) / 10)&#10;                    dr_diers = (int(row['X_DR']) / 10, int(row['Y_DR']) / 10)&#10;                    return vp, dm, dl_diers, dr_diers&#10;&#10;        # If no markers found, return None&#10;        return None, None, None, None&#10;&#10;&#10;    def save_mean_metrics(self, avg_image_duration, mean_csv, metric_scores_by_dataset, metric_scores_by_health_status,&#10;                          total_duration):&#10;        with open(mean_csv, 'w', newline='') as csvfile:&#10;            writer = csv.writer(csvfile)&#10;            header_mean = ['Dataset'] + [m.name for m in self.metrics] + ['Total duration',&#10;                                                                          'Average duration per image']&#10;            writer.writerow(header_mean)&#10;            # per-dataset means&#10;            for ds, lst in metric_scores_by_dataset.items():&#10;                means = [_safe_nanmean([row[i] for row in lst]) for i in range(len(self.metrics))]&#10;                writer.writerow([ds] + means + ['', ''])&#10;            # by sick status&#10;            for label, lst in metric_scores_by_health_status.items():&#10;                means = [_safe_nanmean([row[i] for row in lst]) for i in range(len(self.metrics))]&#10;                writer.writerow([label] + means + ['', ''])&#10;            # overall&#10;            all_vals = [v for lst in metric_scores_by_dataset.values() for v in lst]&#10;            means = [_safe_nanmean([row[i] for row in all_vals]) for i in range(len(self.metrics))]&#10;            writer.writerow(['All Datasets'] + means + [total_duration, avg_image_duration])&#10;        print(f&quot;Mean validation results saved to {mean_csv}&quot;)&#10;&#10;&#10;    @staticmethod&#10;    def read_segmentation_duration(predictions_dir):&#10;        _duration_file = Path(predictions_dir) / 'duration.txt'&#10;        if _duration_file.exists():&#10;            with open(_duration_file, 'r') as _df:&#10;                _lines = _df.readlines()&#10;            if len(_lines) &gt;= 2:&#10;                total_duration = _lines[0].split(':', 1)[1].strip()&#10;                avg_image_duration = _lines[1].split(':', 1)[1].strip()&#10;            else:&#10;                total_duration = ''&#10;                avg_image_duration = ''&#10;        else:&#10;            total_duration = ''&#10;            avg_image_duration = ''&#10;        return avg_image_duration, total_duration&#10;&#10;&#10;    def save_per_image_metrics(self, all_csv, metric_scores):&#10;        with open(all_csv, 'w', newline='') as csvfile:&#10;            writer = csv.writer(csvfile)&#10;            header = ['Dataset', 'File Name', 'Sick'] + [m.name for m in self.metrics]&#10;            writer.writerow(header)&#10;            writer.writerows(metric_scores)&#10;        print(f&quot;Validation results saved to {all_csv}&quot;)&#10;&#10;&#10;    def create_output_files(self, predictions_dir):&#10;        output_dir = Path(self.output_dir)&#10;        output_dir.mkdir(parents=True, exist_ok=True)&#10;        run_name = os.path.basename(predictions_dir)&#10;        all_csv = output_dir / f&quot;{run_name}_all.csv&quot;&#10;        mean_csv = output_dir / f&quot;{run_name}_mean.csv&quot;&#10;        return all_csv, mean_csv&#10;&#10;&#10;    @staticmethod&#10;    def parse_dataset(file_name):&#10;        prefix = file_name.split('_')[0]&#10;        return prefix&#10;&#10;&#10;    @staticmethod&#10;    def load_masks(segmentations_dir):&#10;        segmentations = {}&#10;        for file in os.listdir(segmentations_dir):&#10;            if file.endswith(&quot;.png&quot;) and &quot;-mask&quot; in file:&#10;                img = io.imread(os.path.join(segmentations_dir, file))&#10;                # Falls RGB, in Graustufen umwandeln&#10;                if img.ndim == 3:&#10;                    img = img[..., 0]  # Nur ersten Kanal nehmen (oder np.mean(img, axis=2) für echten Grauwert)&#10;                segmentations[file] = img&#10;        return segmentations&#10;&#10;&#10;    @staticmethod&#10;    def parse_patient_index_from_image_path(image_path):&#10;        pattern = re.compile(r'^[^_]+_([^_]+(?:_\d+)+)(?=_\d{9,})')&#10;        match = pattern.search(os.path.basename(image_path))&#10;        if match:&#10;            return match.group(1)&#10;        return None&#10;&#10;&#10;    @staticmethod&#10;    def extract_image_number(file_name):&#10;        match = re.search(r'_(\d+)-mask\.Gauss\.png$', file_name)&#10;        if match:&#10;            return match.group(1)&#10;        return None&#10;&#10;&#10;    @staticmethod&#10;    def visualize_mask(image: np.ndarray, title: str):&#10;        &quot;&quot;&quot;Display the original mask image without any splitting lines or axes.&quot;&quot;&quot;&#10;        fig, ax = plt.subplots()&#10;        # display mask or full-color image&#10;        if image.ndim == 3 and image.shape[2] &gt;= 3:&#10;            ax.imshow(image, aspect='equal', interpolation='nearest')&#10;        else:&#10;            vis = image[...,0] if image.ndim == 3 else image&#10;            ax.imshow(vis, cmap='gray', aspect='equal', interpolation='nearest')&#10;        ax.axis('off')&#10;        ax.set_title(title)&#10;        plt.show()&#10;&#10;&#10;    @staticmethod&#10;    def visualize_middle_line(image: np.ndarray, vp: Optional[Tuple[int, int]], dm: Optional[Tuple[int, int]], title: str):&#10;        &quot;&quot;&quot;Display the mask image with a middle splitting line.&quot;&quot;&quot;&#10;        fig, ax = plt.subplots()&#10;        # if image has 3 or more channels, show in RGB, else grayscale&#10;        if image.ndim == 3 and image.shape[2] &gt;= 3:&#10;            ax.imshow(image, aspect='equal', interpolation='nearest')&#10;        else:&#10;            vis = image[...,0] if image.ndim == 3 else image&#10;            ax.imshow(vis, cmap='gray', aspect='equal', interpolation='nearest')&#10;&#10;        if vp is not None and dm is not None:&#10;            # Draw the splitting line in the middle of the two markers&#10;            xs = [vp[0], dm[0]]&#10;            ys = [vp[1], dm[1]]&#10;            ax.plot(xs, ys, color='magenta', linewidth=2)&#10;&#10;        ax.axis('off')&#10;        ax.set_title(title)&#10;        plt.show()&#10;&#10;&#10;    def compute_distance_per_pixel(self, patient_idx, vp, dm):&#10;        &quot;&quot;&quot;&#10;        Compute millimeters per pixel using known physical distance between VP and DM markers.&#10;        &quot;&quot;&quot;&#10;        if vp is None or dm is None:&#10;            return None&#10;        pixel_dist = np.hypot(dm[0] - vp[0], dm[1] - vp[1])&#10;        if pixel_dist == 0:&#10;            return None&#10;        mm_dist = self.vp_dm_distances.get(patient_idx)&#10;        if mm_dist is None:&#10;            return None&#10;        return mm_dist / pixel_dist&#10;&#10;&#10;    @staticmethod&#10;    def load_health_status_dict(file_path=&quot;data/Info_Sheets/All_Data_Renamed_overview.csv&quot;):&#10;        &quot;&quot;&quot;Load the mapping from Patientenindex to Krank value.&quot;&quot;&quot;&#10;        health_status_dict = {}&#10;        with open(file_path, 'r', newline='') as csvfile:&#10;            reader = csv.DictReader(csvfile)&#10;            for row in reader:&#10;                pat_idx = row.get('Patientenindex')&#10;                sick = row.get('Krank')&#10;                if pat_idx and sick:&#10;                    health_status_dict[pat_idx] = float(sick)&#10;        return health_status_dict&#10;&#10;&#10;    @staticmethod&#10;    def load_vp_dm_distances(file_path=&quot;data/Info_Sheets/All_Data_Renamed_overview.csv&quot;):&#10;        vp_dm_distance_map = {}&#10;        with open(file_path, 'r', newline='') as csvfile:&#10;            reader = csv.DictReader(csvfile)&#10;            for row in reader:&#10;                pat_idx = row.get('Patientenindex')&#10;                dist_str = row.get('Rumpflänge')&#10;                if pat_idx and dist_str:&#10;                    try:&#10;                        dist_mm = float(dist_str)&#10;                        vp_dm_distance_map[pat_idx] = dist_mm&#10;                    except ValueError:&#10;                        continue&#10;        return vp_dm_distance_map&#10;&#10;&#10;def _safe_nanmean(arr):&#10;    # filter out None, NaN, and infinite values&#10;    clean = [v for v in arr if v is not None and np.isfinite(v)]&#10;    if len(clean) == 0:&#10;        return None&#10;    return float(np.mean(clean))" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/visualization/avg_dice_by_nsegments_plotter.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/visualization/avg_dice_by_nsegments_plotter.py" />
              <option name="originalContent" value="import warnings&#10;import numpy as np&#10;from matplotlib import pyplot as plt&#10;&#10;from visualization.base_plotter import BasePlotter&#10;&#10;&#10;class AvgDiceByNSegmentsPlotter(BasePlotter):&#10;    &quot;&quot;&quot;&#10;    Plot average of one metric (e.g., Dice) as a function of another (e.g., N Segments GT) per experiment.&#10;    &quot;&quot;&quot;&#10;    def __init__(self, experiments, metrics, directory='avg_dice_by_nsegments'):  # metrics: [x_metric, y_metric]&#10;        super().__init__(experiments, metrics, directory)&#10;&#10;    def plot(self, data_frames, output_dir):&#10;        if len(self.metrics) != 2:&#10;            warnings.warn('AvgDiceByNSegmentsPlotter needs exactly 2 metrics: [x_metric, y_metric].')&#10;            return&#10;        metric_x, metric_y = self.metrics&#10;        if not data_frames:&#10;            warnings.warn('No data to plot.')&#10;            return&#10;        # collect all unique x values across experiments&#10;        x_vals_all = set()&#10;        for df in data_frames:&#10;            if metric_x in df.columns:&#10;                x_vals_all.update(df[metric_x].dropna().unique())&#10;        if not x_vals_all:&#10;            warnings.warn(f&quot;Metric '{metric_x}' not found in any data.&quot;)&#10;            return&#10;        sorted_x = sorted(x_vals_all)&#10;        # prepare plot&#10;        fig, ax = plt.subplots(figsize=(max(3, int((len(sorted_x)+1)*0.3)), 6))&#10;        # plot per experiment&#10;        for df, name in zip(data_frames, self.experiments):&#10;            if metric_x not in df.columns or metric_y not in df.columns:&#10;                warnings.warn(f&quot;Skipping experiment '{name}': missing '{metric_x}' or '{metric_y}'.&quot;)&#10;                continue&#10;            grouped = df.groupby(metric_x)[metric_y].mean()&#10;            y_vals = [grouped.get(x, np.nan) for x in sorted_x]&#10;            ax.plot(sorted_x, y_vals, marker='o', label=name)&#10;        ax.set_title(f&quot;Average {metric_y} by {metric_x} per experiment&quot;)&#10;        ax.set_xlabel(metric_x)&#10;        ax.set_ylabel(f&quot;Average {metric_y}&quot;)&#10;        ax.set_xticks(sorted_x)&#10;        # place legend below plot with multiple columns like scatter plotter&#10;        ncol = min(len(self.experiments), 3)&#10;        ax.legend(ncol=ncol, loc='upper center', bbox_to_anchor=(0.5, -0.15), fontsize='small', frameon=False)&#10;        ax.xaxis.grid(True, which='major', linestyle='--', alpha=0.5)&#10;        ax.yaxis.grid(True, which='major', linestyle='--', alpha=0.5)&#10;        fig.tight_layout()&#10;        fig.subplots_adjust(bottom=0.3)&#10;        # filename&#10;        fn = f&quot;avg_{metric_y.replace(' ', '_')}_by_{metric_x.replace(' ', '_')}.png&quot;&#10;        self.save_plot(fig, output_dir, filename=fn)&#10;" />
              <option name="updatedContent" value="import warnings&#10;import numpy as np&#10;from matplotlib import pyplot as plt&#10;&#10;from visualization.base_plotter import BasePlotter&#10;&#10;&#10;class AvgDiceByNSegmentsPlotter(BasePlotter):&#10;    &quot;&quot;&quot;&#10;    Plot average of one metric (e.g., Dice) as a function of another (e.g., N Segments GT) per experiment.&#10;    &quot;&quot;&quot;&#10;    def __init__(self, experiments, metrics, directory='avg_dice_by_nsegments'):  # metrics: [x_metric, y_metric]&#10;        super().__init__(experiments, metrics, directory)&#10;&#10;    def plot(self, data_frames, output_dir):&#10;        if len(self.metrics) != 2:&#10;            warnings.warn('AvgDiceByNSegmentsPlotter needs exactly 2 metrics: [x_metric, y_metric].')&#10;            return&#10;        metric_x, metric_y = self.metrics&#10;        if not data_frames:&#10;            warnings.warn('No data to plot.')&#10;            return&#10;        # collect all unique x values across experiments&#10;        x_vals_all = set()&#10;        for df in data_frames:&#10;            if metric_x in df.columns:&#10;                x_vals_all.update(df[metric_x].dropna().unique())&#10;        if not x_vals_all:&#10;            warnings.warn(f&quot;Metric '{metric_x}' not found in any data.&quot;)&#10;            return&#10;        sorted_x = sorted(x_vals_all)&#10;        # prepare plot&#10;        fig, ax = plt.subplots(figsize=(max(3, int((len(sorted_x)+1)*0.3)), 6))&#10;        # plot per experiment&#10;        for df, name in zip(data_frames, self.experiments):&#10;            if metric_x not in df.columns or metric_y not in df.columns:&#10;                warnings.warn(f&quot;Skipping experiment '{name}': missing '{metric_x}' or '{metric_y}'.&quot;)&#10;                continue&#10;            grouped = df.groupby(metric_x)[metric_y].mean()&#10;            y_vals = [grouped.get(x, np.nan) for x in sorted_x]&#10;            ax.plot(sorted_x, y_vals, marker='o', label=name)&#10;        ax.set_title(f&quot;Average {metric_y} by {metric_x} per experiment&quot;)&#10;        ax.set_xlabel(metric_x)&#10;        ax.set_ylabel(f&quot;Average {metric_y}&quot;)&#10;        ax.set_xticks(sorted_x)&#10;        # place legend below plot with multiple columns like scatter plotter&#10;        ncol = min(len(self.experiments), 3)&#10;        ax.legend(ncol=ncol, loc='upper center', bbox_to_anchor=(0.5, -0.15), fontsize='small', frameon=False)&#10;        ax.xaxis.grid(True, which='major', linestyle='--', alpha=0.5)&#10;        ax.yaxis.grid(True, which='major', linestyle='--', alpha=0.5)&#10;        fig.tight_layout()&#10;        fig.subplots_adjust(bottom=0.3)&#10;        # filename&#10;        fn = f&quot;avg_{metric_y.replace(' ', '_')}_by_{metric_x.replace(' ', '_')}.png&quot;&#10;        self.save_plot(fig, output_dir, filename=fn)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/visualization/bar_plotter.csv.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/visualization/bar_plotter.csv.py" />
              <option name="originalContent" value="import os&#10;&#10;from matplotlib import pyplot as plt&#10;&#10;from visualization.plotter import Plotter&#10;&#10;&#10;class BarPlotter(Plotter):&#10;    def __init__(self, columns):&#10;        self.columns = columns&#10;&#10;    def plot(self, dfs, exp_names, output_dir):&#10;        for col in self.columns:&#10;            values = []&#10;            for df in dfs:&#10;                if col in df.columns:&#10;                    # Use explicit value from the 'All Datasets' row instead of column mean&#10;                    if 'All Datasets' in df.index:&#10;                        values.append(df.loc['All Datasets', col])&#10;                    else:&#10;                        raise ValueError(f&quot;Row 'All Datasets' not found in DataFrame for experiment.&quot;)&#10;                else:&#10;                    raise ValueError(f&quot;Column '{col}' not found in DataFrame for experiment.&quot;)&#10;            plt.figure()&#10;            plt.bar(exp_names, values)&#10;            plt.title(f&quot;{col} across experiments&quot;)&#10;            plt.ylabel(col)&#10;            plt.xticks(rotation=45, ha='right')&#10;            plt.tight_layout()&#10;            out_path = os.path.join(output_dir, f&quot;{col}_bar_chart.png&quot;)&#10;            plt.savefig(out_path)&#10;            plt.close()&#10;            print(f&quot;Saved bar chart for '{col}' to {out_path}&quot;)" />
              <option name="updatedContent" value="import os&#10;&#10;from matplotlib import pyplot as plt&#10;&#10;from visualization.plotter import Plotter&#10;&#10;&#10;class BarPlotter(Plotter):&#10;    def __init__(self, columns):&#10;        self.columns = columns&#10;&#10;    def plot(self, dfs, exp_names, output_dir):&#10;        for col in self.columns:&#10;            values = []&#10;            for df in dfs:&#10;                if col in df.columns:&#10;                    # Use explicit value from the 'All Datasets' row instead of column mean&#10;                    if 'All Datasets' in df.index:&#10;                        values.append(df.loc['All Datasets', col])&#10;                    else:&#10;                        raise ValueError(f&quot;Row 'All Datasets' not found in DataFrame for experiment.&quot;)&#10;                else:&#10;                    raise ValueError(f&quot;Column '{col}' not found in DataFrame for experiment.&quot;)&#10;            plt.figure()&#10;            plt.bar(exp_names, values)&#10;            plt.title(f&quot;{col} across experiments&quot;)&#10;            plt.ylabel(col)&#10;            plt.xticks(rotation=45, ha='right')&#10;            plt.tight_layout()&#10;            out_path = os.path.join(output_dir, f&quot;{col}_bar_chart.png&quot;)&#10;            plt.savefig(out_path)&#10;            plt.close()&#10;            print(f&quot;Saved bar chart for '{col}' to {out_path}&quot;)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/visualization/base_plotter.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/visualization/base_plotter.py" />
              <option name="originalContent" value="import os&#10;&#10;from matplotlib import pyplot as plt&#10;&#10;from visualization.iplotter import IPlotter&#10;&#10;&#10;class BasePlotter(IPlotter):&#10;    def __init__(self, experiments, metrics, directory):&#10;        self.experiments = experiments&#10;        self.metrics = metrics&#10;        self.directory = directory&#10;&#10;    def plot(self, data_frames, output_dir):&#10;        raise NotImplementedError(&quot;Subclasses must implement the plot method.&quot;)&#10;&#10;    def save_plot(self, fig, output_dir, filename=None):&#10;        &quot;&quot;&quot;Save figure in the configured directory, using optional filename.&quot;&quot;&quot;&#10;        dir_path = os.path.join(output_dir, self.directory)&#10;        os.makedirs(dir_path, exist_ok=True)&#10;        if filename is None:&#10;            filename = '_'.join([m.replace(' ', '_') for m in self.metrics]) + '.png'&#10;        # remove any path separators from filename to prevent unintended directories&#10;        filename = filename.replace('/', '_').replace('\\', '_')&#10;        out_path = os.path.join(str(dir_path), filename)&#10;        plt.savefig(out_path, bbox_inches='tight')&#10;        plt.close(fig)&#10;        print(f&quot;Saved chart to {out_path}&quot;)&#10;" />
              <option name="updatedContent" value="import os&#10;&#10;from matplotlib import pyplot as plt&#10;&#10;from visualization.iplotter import IPlotter&#10;&#10;&#10;class BasePlotter(IPlotter):&#10;    def __init__(self, experiments, metrics, directory):&#10;        self.experiments = experiments&#10;        self.metrics = metrics&#10;        self.directory = directory&#10;&#10;    def plot(self, data_frames, output_dir):&#10;        raise NotImplementedError(&quot;Subclasses must implement the plot method.&quot;)&#10;&#10;    def save_plot(self, fig, output_dir, filename=None):&#10;        &quot;&quot;&quot;Save figure in the configured directory, using optional filename.&quot;&quot;&quot;&#10;        dir_path = os.path.join(output_dir, self.directory)&#10;        os.makedirs(dir_path, exist_ok=True)&#10;        if filename is None:&#10;            filename = '_'.join([m.replace(' ', '_') for m in self.metrics]) + '.png'&#10;        # remove any path separators from filename to prevent unintended directories&#10;        filename = filename.replace('/', '_').replace('\\', '_')&#10;        out_path = os.path.join(str(dir_path), filename)&#10;        plt.savefig(out_path, bbox_inches='tight')&#10;        plt.close(fig)&#10;        print(f&quot;Saved chart to {out_path}&quot;)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/visualization/line_plotter.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/visualization/line_plotter.py" />
              <option name="originalContent" value="import warnings&#10;&#10;import numpy as np&#10;from matplotlib import pyplot as plt&#10;&#10;from visualization.base_plotter import BasePlotter&#10;&#10;&#10;class LinePlotter(BasePlotter):&#10;    def __init__(self, experiments, metrics, directory='line_plots'):&#10;        super().__init__(experiments, metrics, directory)&#10;&#10;    def plot(self, data_frames, output_dir):&#10;        # number of experiments and metrics&#10;        n_exp = len(self.experiments)&#10;        n_met = len(self.metrics)&#10;        if n_exp == 0 or n_met == 0:&#10;            warnings.warn('No experiments or metrics to plot.')&#10;            return&#10;&#10;       # numeric x positions for experiments&#10;        x = np.arange(len(self.experiments))&#10;&#10;        # derive group labels from first DataFrame&#10;        df0 = data_frames[0]&#10;        all_labels = list(df0['Dataset'].unique())&#10;&#10;        # include All Datasets and dataset names, exclude only status labels&#10;        dataset_groups = [d for d in all_labels if d not in ('Healthy', 'Sick')]&#10;&#10;        # include All Datasets, Healthy, Sick if present&#10;        status_groups = [g for g in ('All Datasets', 'Healthy', 'Sick') if g in all_labels]&#10;&#10;        # iterate metrics&#10;        for metric in self.metrics:&#10;            # prepare and save by-dataset plot&#10;            fig = self.create_by_dataset_plots(data_frames, dataset_groups, metric, n_exp, x)&#10;            filename = f&quot;{metric.replace(' ','_')}_by_dataset_line.png&quot;&#10;            self.save_plot(fig, output_dir, filename=filename)&#10;&#10;            # prepare and save by-health-status plot&#10;            fig = self.create_bay_health_status_plots(data_frames, metric, n_exp, status_groups, x)&#10;            filename = f&quot;{metric.replace(' ','_')}_by_status_line.png&quot;&#10;            self.save_plot(fig, output_dir, filename=filename)&#10;&#10;    def create_by_dataset_plots(self, data_frames, dataset_groups, metric, n_exp, x):&#10;        fig, ax = plt.subplots(figsize=(max(3, int((n_exp + 1) * 0.3)), 6))&#10;        for grp in dataset_groups:&#10;            y = []&#10;            for df in data_frames:&#10;                if metric in df.columns and grp in df['Dataset'].values:&#10;                    val = df.loc[df['Dataset'] == grp, metric].iloc[0]&#10;                else:&#10;                    val = np.nan&#10;                y.append(val)&#10;            ax.plot(x, y, marker='o', label=grp, linestyle='dashed')&#10;        ax.set_title(f&quot;{metric} by dataset&quot;)&#10;        ax.set_ylabel(metric)&#10;        ax.set_xticks(x)&#10;        ax.set_xticklabels(self.experiments, rotation=45, ha='right')&#10;        ax.legend()&#10;        # draw horizontal grid lines at each y-tick for better readability&#10;        ax.yaxis.grid(True, which='major', color='lightgrey', linestyle='-', linewidth=0.5)&#10;        # if ratio metric, add horizontal grid lines every 0.1&#10;        if metric.lower() in ['dice', 'precision', 'recall']:&#10;            ax.set_ylim(0, 1)&#10;            ax.set_yticks(np.arange(0, 1.0001, 0.1))&#10;            ax.yaxis.grid(True, which='major', color='lightgrey', linestyle='-', linewidth=0.5)&#10;        plt.tight_layout()&#10;        return fig&#10;&#10;    def create_bay_health_status_plots(self, data_frames, metric, n_exp, status_groups, x):&#10;        fig, ax = plt.subplots(figsize=(max(3, int((n_exp + 1) * 0.3)), 6))&#10;        for grp in status_groups:&#10;            y = []&#10;            for df in data_frames:&#10;                if metric in df.columns and grp in df['Dataset'].values:&#10;                    val = df.loc[df['Dataset'] == grp, metric].iloc[0]&#10;                else:&#10;                    val = np.nan&#10;                y.append(val)&#10;            ax.plot(x, y, marker='o', label=grp, linestyle='dashed')&#10;        ax.set_title(f&quot;{metric} by health status&quot;)&#10;        ax.set_ylabel(metric)&#10;        ax.set_xticks(x)&#10;        ax.set_xticklabels(self.experiments, rotation=45, ha='right')&#10;        ax.legend()&#10;        # draw horizontal grid lines at each y-tick for better readability&#10;        ax.yaxis.grid(True, which='major', color='lightgrey', linestyle='-', linewidth=0.5)&#10;        # if ratio metric, add horizontal grid lines every 0.1&#10;        if metric.lower() in ['dice', 'precision', 'recall']:&#10;            ax.set_ylim(0, 1)&#10;            ax.set_yticks(np.arange(0, 1.0001, 0.1))&#10;            ax.yaxis.grid(True, which='major', color='lightgrey', linestyle='-', linewidth=0.5)&#10;        plt.tight_layout()&#10;        return fig&#10;" />
              <option name="updatedContent" value="import warnings&#10;&#10;import numpy as np&#10;from matplotlib import pyplot as plt&#10;&#10;from visualization.base_plotter import BasePlotter&#10;&#10;&#10;class LinePlotter(BasePlotter):&#10;    def __init__(self, experiments, metrics, directory='line_plots'):&#10;        super().__init__(experiments, metrics, directory)&#10;&#10;    def plot(self, data_frames, output_dir):&#10;        # number of experiments and metrics&#10;        n_exp = len(self.experiments)&#10;        n_met = len(self.metrics)&#10;        if n_exp == 0 or n_met == 0:&#10;            warnings.warn('No experiments or metrics to plot.')&#10;            return&#10;&#10;       # numeric x positions for experiments&#10;        x = np.arange(len(self.experiments))&#10;&#10;        # derive group labels from first DataFrame&#10;        df0 = data_frames[0]&#10;        all_labels = list(df0['Dataset'].unique())&#10;&#10;        # include All Datasets and dataset names, exclude only status labels&#10;        dataset_groups = [d for d in all_labels if d not in ('Healthy', 'Sick')]&#10;&#10;        # include All Datasets, Healthy, Sick if present&#10;        status_groups = [g for g in ('All Datasets', 'Healthy', 'Sick') if g in all_labels]&#10;&#10;        # iterate metrics&#10;        for metric in self.metrics:&#10;            # prepare and save by-dataset plot&#10;            fig = self.create_by_dataset_plots(data_frames, dataset_groups, metric, n_exp, x)&#10;            filename = f&quot;{metric.replace(' ','_')}_by_dataset_line.png&quot;&#10;            self.save_plot(fig, output_dir, filename=filename)&#10;&#10;            # prepare and save by-health-status plot&#10;            fig = self.create_bay_health_status_plots(data_frames, metric, n_exp, status_groups, x)&#10;            filename = f&quot;{metric.replace(' ','_')}_by_status_line.png&quot;&#10;            self.save_plot(fig, output_dir, filename=filename)&#10;&#10;    def create_by_dataset_plots(self, data_frames, dataset_groups, metric, n_exp, x):&#10;        fig, ax = plt.subplots(figsize=(max(3, int((n_exp + 1) * 0.3)), 6))&#10;        for grp in dataset_groups:&#10;            y = []&#10;            for df in data_frames:&#10;                if metric in df.columns and grp in df['Dataset'].values:&#10;                    val = df.loc[df['Dataset'] == grp, metric].iloc[0]&#10;                else:&#10;                    val = np.nan&#10;                y.append(val)&#10;            ax.plot(x, y, marker='o', label=grp, linestyle='dashed')&#10;        ax.set_title(f&quot;{metric} by dataset&quot;)&#10;        ax.set_ylabel(metric)&#10;        ax.set_xticks(x)&#10;        ax.set_xticklabels(self.experiments, rotation=45, ha='right')&#10;        ax.legend()&#10;        # draw horizontal grid lines at each y-tick for better readability&#10;        ax.yaxis.grid(True, which='major', color='lightgrey', linestyle='-', linewidth=0.5)&#10;        # if ratio metric, add horizontal grid lines every 0.1&#10;        if metric.lower() in ['dice', 'precision', 'recall']:&#10;            ax.set_ylim(0, 1)&#10;            ax.set_yticks(np.arange(0, 1.0001, 0.1))&#10;            ax.yaxis.grid(True, which='major', color='lightgrey', linestyle='-', linewidth=0.5)&#10;        plt.tight_layout()&#10;        return fig&#10;&#10;    def create_bay_health_status_plots(self, data_frames, metric, n_exp, status_groups, x):&#10;        fig, ax = plt.subplots(figsize=(max(3, int((n_exp + 1) * 0.3)), 6))&#10;        for grp in status_groups:&#10;            y = []&#10;            for df in data_frames:&#10;                if metric in df.columns and grp in df['Dataset'].values:&#10;                    val = df.loc[df['Dataset'] == grp, metric].iloc[0]&#10;                else:&#10;                    val = np.nan&#10;                y.append(val)&#10;            ax.plot(x, y, marker='o', label=grp, linestyle='dashed')&#10;        ax.set_title(f&quot;{metric} by health status&quot;)&#10;        ax.set_ylabel(metric)&#10;        ax.set_xticks(x)&#10;        ax.set_xticklabels(self.experiments, rotation=45, ha='right')&#10;        ax.legend()&#10;        # draw horizontal grid lines at each y-tick for better readability&#10;        ax.yaxis.grid(True, which='major', color='lightgrey', linestyle='-', linewidth=0.5)&#10;        # if ratio metric, add horizontal grid lines every 0.1&#10;        if metric.lower() in ['dice', 'precision', 'recall']:&#10;            ax.set_ylim(0, 1)&#10;            ax.set_yticks(np.arange(0, 1.0001, 0.1))&#10;            ax.yaxis.grid(True, which='major', color='lightgrey', linestyle='-', linewidth=0.5)&#10;        plt.tight_layout()&#10;        return fig" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/visualization/metric_count_line_plotter.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/visualization/metric_count_line_plotter.py" />
              <option name="originalContent" value="import warnings&#10;from matplotlib import pyplot as plt&#10;&#10;from visualization.base_plotter import BasePlotter&#10;&#10;&#10;class MetricCountLinePlotter(BasePlotter):&#10;    def __init__(self, experiments, metrics, directory='metric_count_line_plots'):&#10;        super().__init__(experiments, metrics, directory)&#10;&#10;    def plot(self, data_frames, output_dir):&#10;        # expect a single experiment's full data ('_all.csv')&#10;        if not data_frames:&#10;            warnings.warn('No data to plot.')&#10;            return&#10;        df = data_frames[0]&#10;        # determine health status based on 'Sick' flag column&#10;        if 'Sick' not in df.columns:&#10;            warnings.warn(&quot;Column 'Sick' not found. Cannot group by health status.&quot;)&#10;            return&#10;        healthy_df = df[df['Sick'] == 0]&#10;        sick_df = df[df['Sick'] == 1]&#10;        status_data = [('Healthy', healthy_df), ('Sick', sick_df)]&#10;        for metric in self.metrics:&#10;            if metric not in df.columns:&#10;                warnings.warn(f&quot;Column '{metric}' not found. Skipping MetricCountLinePlotter for this column.&quot;)&#10;                continue&#10;            # determine sorted unique metric values&#10;            all_vals = df[metric].dropna().unique()&#10;            sorted_vals = sorted(all_vals)&#10;            # prepare figure&#10;            width = max(3, int(len(sorted_vals) * 0.3))&#10;            fig, ax = plt.subplots(figsize=(width, 6))&#10;            # plot counts per status&#10;            for status, sub_df in status_data:&#10;                vals_status = sub_df[metric].dropna()&#10;                counts = vals_status.value_counts().reindex(sorted_vals, fill_value=0)&#10;                ax.plot(sorted_vals, counts.values, marker='o', label=status)&#10;            ax.set_title(f&quot;Count of images by {metric} and health status&quot;)&#10;            ax.set_xlabel(metric)&#10;            ax.set_ylabel('Count of images')&#10;            ax.legend()&#10;            plt.xticks(rotation=45, ha='right')&#10;            plt.tight_layout()&#10;            filename = f&quot;{metric.replace(' ', '_')}_count_line.png&quot;&#10;            self.save_plot(fig, output_dir, filename=filename)&#10;" />
              <option name="updatedContent" value="import warnings&#10;from matplotlib import pyplot as plt&#10;&#10;from visualization.base_plotter import BasePlotter&#10;&#10;&#10;class MetricCountLinePlotter(BasePlotter):&#10;    def __init__(self, experiments, metrics, directory='metric_count_line_plots'):&#10;        super().__init__(experiments, metrics, directory)&#10;&#10;    def plot(self, data_frames, output_dir):&#10;        # expect a single experiment's full data ('_all.csv')&#10;        if not data_frames:&#10;            warnings.warn('No data to plot.')&#10;            return&#10;        df = data_frames[0]&#10;        # determine health status based on 'Sick' flag column&#10;        if 'Sick' not in df.columns:&#10;            warnings.warn(&quot;Column 'Sick' not found. Cannot group by health status.&quot;)&#10;            return&#10;        healthy_df = df[df['Sick'] == 0]&#10;        sick_df = df[df['Sick'] == 1]&#10;        status_data = [('Healthy', healthy_df), ('Sick', sick_df)]&#10;        for metric in self.metrics:&#10;            if metric not in df.columns:&#10;                warnings.warn(f&quot;Column '{metric}' not found. Skipping MetricCountLinePlotter for this column.&quot;)&#10;                continue&#10;            # determine sorted unique metric values&#10;            all_vals = df[metric].dropna().unique()&#10;            sorted_vals = sorted(all_vals)&#10;            # prepare figure&#10;            width = max(3, int(len(sorted_vals) * 0.3))&#10;            fig, ax = plt.subplots(figsize=(width, 6))&#10;            # plot counts per status&#10;            for status, sub_df in status_data:&#10;                vals_status = sub_df[metric].dropna()&#10;                counts = vals_status.value_counts().reindex(sorted_vals, fill_value=0)&#10;                ax.plot(sorted_vals, counts.values, marker='o', label=status)&#10;            ax.set_title(f&quot;Count of images by {metric} and health status&quot;)&#10;            ax.set_xlabel(metric)&#10;            ax.set_ylabel('Count of images')&#10;            ax.legend()&#10;            plt.xticks(rotation=45, ha='right')&#10;            plt.tight_layout()&#10;            filename = f&quot;{metric.replace(' ', '_')}_count_line.png&quot;&#10;            self.save_plot(fig, output_dir, filename=filename)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/visualization/visualizer.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/visualization/visualizer.py" />
              <option name="originalContent" value="import os&#10;&#10;from pandas import read_csv&#10;&#10;from visualization.box_plotter import BoxPlotter&#10;from visualization.heatmap_plotter import HeatmapPlotter&#10;from visualization.scatter_plotter import ScatterPlotter&#10;from visualization.metric_count_bar_plotter import MetricCountBarPlotter&#10;from visualization.bubble_plotter import BubblePlotter&#10;from visualization.avg_dice_by_nsegments_plotter import AvgDiceByNSegmentsPlotter&#10;from visualization.box_dice_by_nsegments_plotter import BoxDiceByNSegmentsPlotter&#10;&#10;&#10;class Visualizer:&#10;    def __init__(self, base_validation_path, plotters, output_dir):&#10;        self.base_validation_path = base_validation_path&#10;        self.plotters = plotters&#10;        self.output_dir = output_dir&#10;&#10;    def visualize(self):&#10;        os.makedirs(self.output_dir, exist_ok=True)&#10;        for plotter in self.plotters:&#10;            if isinstance(plotter, (BoxPlotter, HeatmapPlotter, ScatterPlotter, MetricCountBarPlotter, BubblePlotter, AvgDiceByNSegmentsPlotter, BoxDiceByNSegmentsPlotter)):&#10;                suffix = '_all.csv'&#10;            else:&#10;                suffix = '_mean.csv'&#10;            paths = [os.path.join(self.base_validation_path, name + suffix) for name in plotter.experiments]&#10;            dfs = [read_csv(str(p)) for p in paths]&#10;            # use experiment_names as labels&#10;            plotter.plot(dfs, self.output_dir)" />
              <option name="updatedContent" value="import os&#10;&#10;from pandas import read_csv&#10;&#10;from visualization.box_plotter import BoxPlotter&#10;from visualization.heatmap_plotter import HeatmapPlotter&#10;from visualization.scatter_plotter import ScatterPlotter&#10;from visualization.metric_count_bar_plotter import MetricCountBarPlotter&#10;from visualization.bubble_plotter import BubblePlotter&#10;from visualization.avg_dice_by_nsegments_plotter import AvgDiceByNSegmentsPlotter&#10;from visualization.box_dice_by_nsegments_plotter import BoxDiceByNSegmentsPlotter&#10;&#10;&#10;class Visualizer:&#10;    def __init__(self, base_validation_path, plotters, output_dir):&#10;        self.base_validation_path = base_validation_path&#10;        self.plotters = plotters&#10;        self.output_dir = output_dir&#10;&#10;    def visualize(self):&#10;        os.makedirs(self.output_dir, exist_ok=True)&#10;        for plotter in self.plotters:&#10;            if isinstance(plotter, (BoxPlotter, HeatmapPlotter, ScatterPlotter, MetricCountBarPlotter, BubblePlotter, AvgDiceByNSegmentsPlotter, BoxDiceByNSegmentsPlotter)):&#10;                suffix = '_all.csv'&#10;            else:&#10;                suffix = '_mean.csv'&#10;            paths = [os.path.join(self.base_validation_path, name + suffix) for name in plotter.experiments]&#10;            dfs = [read_csv(str(p)) for p in paths]&#10;            # use experiment_names as labels&#10;            plotter.plot(dfs, self.output_dir)" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>